# UC2 DOM Recovery Agent ê°œë°œ ë§ˆìŠ¤í„°í”Œëœ (HITL ë°©ì‹)

**ì‘ì„±ì¼**: 2025-11-03
**ë²„ì „**: 1.0
**ëª©ì **: UC2 ê°œë°œ ì „ì²´ ë¡œë“œë§µ ì‘ì„± (Human-in-the-Loop ì˜ì‚¬ê²°ì • í¬ì¸íŠ¸ í¬í•¨)
**ì‘ì—… ë””ë ‰í† ë¦¬**: `/Users/charlee/Desktop/Intern/crawlagent`

---

## ëª©ì°¨

1. [ì „ì²´ ì•„í‚¤í…ì²˜ ê°œìš”](#ì „ì²´-ì•„í‚¤í…ì²˜-ê°œìš”)
2. [Phaseë³„ ê°œë°œ ê³„íš](#phaseë³„-ê°œë°œ-ê³„íš)
3. [HITL ì˜ì‚¬ê²°ì • í¬ì¸íŠ¸ ìš”ì•½](#hitl-ì˜ì‚¬ê²°ì •-í¬ì¸íŠ¸-ìš”ì•½)
4. [êµ¬í˜„ ìˆœì„œ ë° íƒ€ì„ë¼ì¸](#êµ¬í˜„-ìˆœì„œ-ë°-íƒ€ì„ë¼ì¸)
5. [í…ŒìŠ¤íŠ¸ ì „ëµ](#í…ŒìŠ¤íŠ¸-ì „ëµ)
6. [ë¦¬ìŠ¤í¬ ë° ëŒ€ì‘](#ë¦¬ìŠ¤í¬-ë°-ëŒ€ì‘)

---

## ì „ì²´ ì•„í‚¤í…ì²˜ ê°œìš”

### UC2 ì›Œí¬í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     UC1 Validation                          â”‚
â”‚  (quality_score < 80 OR title=None OR body=None)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  UC2 Recovery ì‹œì‘     â”‚
         â”‚  (LangGraph ë¼ìš°íŒ…)    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  1. Fetch Raw HTML     â”‚
         â”‚  (Scrapy ì „ì²´ HTML)    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  2. GPT-4o Analyzer                       â”‚
         â”‚  - HTML ì „ì²˜ë¦¬ (BeautifulSoup)            â”‚
         â”‚  - Structured Output (3ê°œ í›„ë³´)           â”‚
         â”‚  - {title_sel, body_sel, date_sel}        â”‚
         â”‚  - confidence: 0.0 ~ 1.0                  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  3. Gemini Validator                      â”‚
         â”‚  - ê° í›„ë³´ë¡œ 10ê°œ ìƒ˜í”Œ ì¶”ì¶œ                â”‚
         â”‚  - ë‰´ìŠ¤ íŒ¨í„´ ê²€ì¦ (í•œêµ­ì–´/ì˜ë¬¸)            â”‚
         â”‚  - valid: true/false                      â”‚
         â”‚  - validation_score: 0-100                â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  4. Consensus Check    â”‚
         â”‚  - GPT conf â‰¥ 0.7?    â”‚
         â”‚  - Gemini valid=true? â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                 â”‚
         í•©ì˜ ì„±ê³µ          í•©ì˜ ì‹¤íŒ¨
            â”‚                 â”‚
            â–¼                 â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ 5. DB ì—…ë°ì´íŠ¸  â”‚   â”‚ 6. ì¬ì‹œë„     â”‚
   â”‚ - selectors    â”‚   â”‚ (retry_count) â”‚
   â”‚ - decision_logsâ”‚   â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
            â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
            â”‚           â”‚              â”‚
            â”‚      retry < 3      retry â‰¥ 3
            â”‚           â”‚              â”‚
            â”‚           â–¼              â–¼
            â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚     â”‚ ì¬ì‹œë„   â”‚   â”‚ HITL ê°œì…    â”‚
            â”‚     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â”‚ (ìˆ˜ë™ ê²€í† )  â”‚
            â”‚          â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚          â””â”€â”€â”€â”€â–º GPT Analyzer
            â”‚
            â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ 7. ì¬í¬ë¡¤ë§     â”‚
   â”‚ (ìƒˆ Selector)  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ UC1 ê²€ì¦        â”‚
   â”‚ (í’ˆì§ˆ ì¬í‰ê°€)   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ì£¼ìš” ì»´í¬ë„ŒíŠ¸

| ì»´í¬ë„ŒíŠ¸ | íŒŒì¼ ê²½ë¡œ | ì—­í•  | ì˜ì¡´ì„± |
|----------|----------|------|--------|
| **UC2 StateGraph** | `src/workflow/uc2_recovery.py` | ì „ì²´ ì›Œí¬í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ | LangGraph, UC1 |
| **GPT-4o Analyzer** | `src/agents/gpt_analyzer.py` | HTML â†’ CSS Selector ìƒì„± (3ê°œ í›„ë³´) | OpenAI API |
| **Gemini Validator** | `src/agents/gemini_validator.py` | Selector ê²€ì¦ (10ê°œ ìƒ˜í”Œ) | Google Gemini API |
| **Consensus Logic** | `src/workflow/uc2_recovery.py` (ë‚´ë¶€ í•¨ìˆ˜) | 2-Agent í•©ì˜ íŒë‹¨ | - |
| **HITL Interface** | `src/ui/app.py` (ì‹ ê·œ íƒ­) | ìˆ˜ë™ ê²€í†  UI | Gradio |
| **State í™•ì¥** | `src/workflow/uc2_recovery.py` | UC2 State ì •ì˜ | TypedDict |

---

## Phaseë³„ ê°œë°œ ê³„íš

### Phase 1: State ì •ì˜ ë° GPT-4o Analyzer (3-4ì‹œê°„)

#### 1.1 State í™•ì¥ ì„¤ê³„ (30ë¶„)

**í˜„ì¬ UC1 State** (`src/workflow/uc1_validation.py`):
```python
class ValidationState(TypedDict):
    url: str
    site_name: str
    title: Optional[str]
    body: Optional[str]
    date: Optional[str]
    quality_score: int
    missing_fields: List[str]
    next_action: Literal["save", "heal", "new_site"]
```

**UC2 State í™•ì¥** (`src/workflow/uc2_recovery.py`):
```python
class RecoveryState(TypedDict):
    # UC1ì—ì„œ ì „ë‹¬ë°›ëŠ” ê¸°ë³¸ í•„ë“œ
    url: str
    site_name: str
    title: Optional[str]
    body: Optional[str]
    date: Optional[str]
    quality_score: int
    missing_fields: List[str]
    
    # UC2 ì „ìš© í•„ë“œ
    raw_html: str  # ì „ì²´ HTML (GPT/Gemini ë¶„ì„ìš©)
    
    # GPT-4o Analyzer ê²°ê³¼
    gpt_candidates: List[Dict[str, Any]]  # 3ê°œ í›„ë³´
    # ì˜ˆ: [
    #   {
    #     "title_selector": "h1.article-title",
    #     "body_selector": "div.article-body",
    #     "date_selector": "time.published-date",
    #     "confidence": 0.85,
    #     "reasoning": "ëª…í™•í•œ ì‹œë©˜í‹± íƒœê·¸ ì‚¬ìš©"
    #   },
    #   {...}, {...}
    # ]
    
    # Gemini Validator ê²°ê³¼
    gemini_validation: Dict[str, Any]
    # ì˜ˆ: {
    #   "candidate_index": 0,  # ê²€ì¦ í†µê³¼í•œ í›„ë³´ ì¸ë±ìŠ¤
    #   "valid": True,
    #   "validation_score": 92,
    #   "samples": ["ìƒ˜í”Œ1", "ìƒ˜í”Œ2", ...],
    #   "failure_reason": None
    # }
    
    # í•©ì˜ ë° ì¬ì‹œë„ ê´€ë¦¬
    consensus_reached: bool
    retry_count: int
    max_retries: int
    
    # ìµœì¢… ì„ íƒëœ Selector
    selected_selector: Optional[Dict[str, str]]
    
    # ì—ëŸ¬ ë¡œê·¸ (ë””ë²„ê¹…ìš©)
    error_log: List[str]
```

**ğŸ¤” HITL ì˜ì‚¬ê²°ì • í¬ì¸íŠ¸ #1: raw_html ì €ì¥ ë°©ì‹**

**ì§ˆë¬¸**: raw_htmlì„ Stateì— í¬í•¨í• ì§€, ë³„ë„ íŒŒì¼ë¡œ ì €ì¥í• ì§€?

**ì˜µì…˜ A: Stateì— í¬í•¨**
- ì¥ì :
  - êµ¬í˜„ ê°„ë‹¨ (ì¶”ê°€ íŒŒì¼ I/O ë¶ˆí•„ìš”)
  - LangGraph Stateì—ì„œ ì§ì ‘ ì ‘ê·¼ ê°€ëŠ¥
  - ì¬ì‹œë„ ì‹œ ì¬ìˆ˜ì§‘ ë¶ˆí•„ìš”
- ë‹¨ì :
  - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€ (HTML í‰ê·  200-500KB)
  - State ì§ë ¬í™” ì‹œ ì˜¤ë²„í—¤ë“œ
  - LangGraph checkpointer ë¶€ë‹´

**ì˜µì…˜ B: ì„ì‹œ íŒŒì¼ ì €ì¥**
- ì¥ì :
  - ë©”ëª¨ë¦¬ íš¨ìœ¨ì 
  - ëŒ€ìš©ëŸ‰ HTML ì²˜ë¦¬ ê°€ëŠ¥
- ë‹¨ì :
  - íŒŒì¼ I/O ì¶”ê°€ (ë³µì¡ë„ ì¦ê°€)
  - ì„ì‹œ íŒŒì¼ ê´€ë¦¬ í•„ìš” (ì •ë¦¬ ë¡œì§)
  - ë©€í‹° í”„ë¡œì„¸ìŠ¤ í™˜ê²½ì—ì„œ ê²½í•© ê°€ëŠ¥

**ê¶Œì¥ ê²°ì •**: **ì˜µì…˜ A (Stateì— í¬í•¨)**
- ê·¼ê±°:
  - PoC ë‹¨ê³„, ê°„ë‹¨í•œ êµ¬í˜„ ìš°ì„ 
  - 3ê°œ ì‚¬ì´íŠ¸ HTML í¬ê¸° ê²€ì¦ ê²°ê³¼ (2025-10-29):
    - ì—°í•©ë‰´ìŠ¤: ~150KB
    - ë„¤ì´ë²„: ~250KB
    - BBC: ~320KB
  - LangGraphëŠ” 100MBê¹Œì§€ State ì§€ì› (ê³µì‹ ë¬¸ì„œ)
  - Productionì—ì„œ ì˜µì…˜ Bë¡œ ì „í™˜ ê°€ëŠ¥ (ì ì§„ì  ê°œì„ )

**êµ¬í˜„**:
```python
# src/workflow/uc2_recovery.py

def fetch_raw_html(state: RecoveryState) -> dict:
    """
    Node 1: ì „ì²´ HTML ìˆ˜ì§‘
    """
    import requests
    from bs4 import BeautifulSoup
    
    url = state["url"]
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        
        # BeautifulSoupìœ¼ë¡œ íŒŒì‹± (GPTì—ê²Œ ì¤„ ë•Œ prettify)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        return {
            "raw_html": str(soup),  # prettified HTML
            "error_log": state.get("error_log", [])
        }
    except Exception as e:
        error_msg = f"[fetch_raw_html] {e}"
        return {
            "raw_html": "",
            "error_log": state.get("error_log", []) + [error_msg]
        }
```

---

#### 1.2 GPT-4o Analyzer êµ¬í˜„ (2ì‹œê°„)

**ğŸ¤” HITL ì˜ì‚¬ê²°ì • í¬ì¸íŠ¸ #2: HTML ì „ì²˜ë¦¬ ë°©ì‹**

**ì§ˆë¬¸**: GPT-4oì—ê²Œ ì „ì²´ HTMLì„ ì¤„ì§€, ì¶•ì•½ëœ HTMLì„ ì¤„ì§€?

**ì˜µì…˜ A: ì „ì²´ HTML**
- ì¥ì :
  - GPTê°€ ëª¨ë“  ë¬¸ë§¥ íŒŒì•… ê°€ëŠ¥
  - ì •í™•ë„ ë†’ìŒ
- ë‹¨ì :
  - í† í° ë¹„ìš© ë†’ìŒ (300KB HTML â‰ˆ 75K í† í°)
  - GPT-4o context window (128K) ì´ˆê³¼ ê°€ëŠ¥
  - ì‘ë‹µ ì‹œê°„ ëŠë¦¼ (5-10ì´ˆ)

**ì˜µì…˜ B: BeautifulSoupìœ¼ë¡œ ì£¼ìš” íƒœê·¸ë§Œ ì¶”ì¶œ**
- ì¥ì :
  - í† í° ì ˆê° (50-80%)
  - ë¹ ë¥¸ ì‘ë‹µ (2-3ì´ˆ)
  - ë¹„ìš© ì ˆê°
- ë‹¨ì :
  - ì¤‘ìš” ì •ë³´ ëˆ„ë½ ê°€ëŠ¥
  - ì „ì²˜ë¦¬ ë¡œì§ í•„ìš”

**ê¶Œì¥ ê²°ì •**: **ì˜µì…˜ B (ì£¼ìš” íƒœê·¸ë§Œ ì¶”ì¶œ)**
- ê·¼ê±°:
  - ë‰´ìŠ¤ ì‚¬ì´íŠ¸ëŠ” ì‹œë©˜í‹± íƒœê·¸ ì‚¬ìš© (article, main, header)
  - GPT-4o ì…ë ¥ ë¹„ìš©: $2.50 / 1M tokens
  - ì „ì²´ HTML vs ì¶•ì•½ HTML ë¹„ìš© ì°¨ì´: ì•½ 5ë°°
  - Phase 5 í…ŒìŠ¤íŠ¸ì—ì„œ ì •í™•ë„ ê²€ì¦ ê°€ëŠ¥

**HTML ì „ì²˜ë¦¬ í•¨ìˆ˜**:
```python
# src/utils/html_cleaner.py

from bs4 import BeautifulSoup
from typing import Optional

def extract_article_content(html: str) -> str:
    """
    ë‰´ìŠ¤ ê¸°ì‚¬ ì£¼ìš” ì½˜í…ì¸ ë§Œ ì¶”ì¶œ
    
    ìš°ì„ ìˆœìœ„:
    1. <article> íƒœê·¸ ì „ì²´
    2. <main> íƒœê·¸ ë‚´ë¶€
    3. <div id="content"> ë˜ëŠ” <div class="content">
    4. ì—†ìœ¼ë©´ ì „ì²´ <body>
    """
    soup = BeautifulSoup(html, 'html.parser')
    
    # ìš°ì„ ìˆœìœ„ 1: article íƒœê·¸
    article = soup.find('article')
    if article:
        return str(article.prettify())
    
    # ìš°ì„ ìˆœìœ„ 2: main íƒœê·¸
    main = soup.find('main')
    if main:
        return str(main.prettify())
    
    # ìš°ì„ ìˆœìœ„ 3: content í´ë˜ìŠ¤/ID
    content_div = soup.find('div', {'id': 'content'}) or soup.find('div', {'class': 'content'})
    if content_div:
        return str(content_div.prettify())
    
    # ìš°ì„ ìˆœìœ„ 4: body ì „ì²´ (fallback)
    body = soup.find('body')
    if body:
        # ë¶ˆí•„ìš”í•œ íƒœê·¸ ì œê±°
        for tag in body.find_all(['script', 'style', 'nav', 'footer', 'aside']):
            tag.decompose()
        return str(body.prettify())
    
    # ìµœí›„ì˜ ìˆ˜ë‹¨: ì „ì²´ HTML
    return html
```

**ğŸ¤” HITL ì˜ì‚¬ê²°ì • í¬ì¸íŠ¸ #3: Selector í›„ë³´ ê°œìˆ˜**

**ì§ˆë¬¸**: GPT-4oê°€ ìƒì„±í•  Selector í›„ë³´ëŠ” ëª‡ ê°œ?

**ì˜µì…˜ A: 1ê°œ**
- ì¥ì : ë¹ ë¦„, ê°„ë‹¨
- ë‹¨ì : ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ í•„ìš”

**ì˜µì…˜ B: 3ê°œ (PRD ê¸°ì¤€)**
- ì¥ì : ì„ íƒì§€ ë§ìŒ, ì¬ì‹œë„ ê°ì†Œ
- ë‹¨ì : GPT ì‘ë‹µ ì‹œê°„ ì¦ê°€

**ì˜µì…˜ C: 5ê°œ**
- ì¥ì : ìµœëŒ€ ì„ íƒì§€
- ë‹¨ì : ê³¼ë„í•œ ê²€ì¦ ì‹œê°„

**ê¶Œì¥ ê²°ì •**: **ì˜µì…˜ B (3ê°œ)** - PRD ì¤€ìˆ˜
- ê·¼ê±°:
  - PRD-2-TECHNICAL-SPEC.md ëª…ì‹œ (3ê°œ í›„ë³´)
  - Gemini ê²€ì¦ ì‹œê°„ ê³ ë ¤ (3ê°œ Ã— 10 ìƒ˜í”Œ = 30ê°œ ê²€ì¦)
  - ì‹¤íŒ¨ìœ¨ ê³„ì‚°: 3ê°œ ëª¨ë‘ ì‹¤íŒ¨ í™•ë¥  = 0.3^3 = 2.7%

**ğŸ¤” HITL ì˜ì‚¬ê²°ì • í¬ì¸íŠ¸ #4: GPT ëª¨ë¸ ì„ íƒ**

**ì§ˆë¬¸**: ì–´ë–¤ GPT-4o ëª¨ë¸ì„ ì‚¬ìš©?

**ì˜µì…˜ A: `gpt-4o` (ìµœì‹ )**
- ê°€ê²©: $2.50 / 1M input tokens, $10.00 / 1M output tokens
- ì„±ëŠ¥: ìµœê³ 
- context window: 128K

**ì˜µì…˜ B: `gpt-4o-mini`**
- ê°€ê²©: $0.15 / 1M input tokens, $0.60 / 1M output tokens
- ì„±ëŠ¥: ì•½ê°„ ë‚®ìŒ
- context window: 128K

**ê¶Œì¥ ê²°ì •**: **ì˜µì…˜ A (`gpt-4o`)**
- ê·¼ê±°:
  - ì •í™•ë„ ìš°ì„  (PoC í•µì‹¬ ê²€ì¦)
  - CSS Selector ìƒì„±ì€ ê³ ë‚œì´ë„ ì‘ì—…
  - ë¹„ìš© ì°¨ì´ ë¯¸ë¯¸ (URLë‹¹ $0.01 vs $0.0006)
  - Productionì—ì„œ gpt-4o-mini ì „í™˜ ê°€ëŠ¥

**GPT-4o Analyzer êµ¬í˜„**:
```python
# src/agents/gpt_analyzer.py

from openai import OpenAI
from pydantic import BaseModel, Field
from typing import List, Optional
import os

# Structured Output ìŠ¤í‚¤ë§ˆ
class SelectorCandidate(BaseModel):
    """
    CSS Selector í›„ë³´
    """
    title_selector: str = Field(description="ì œëª© ì¶”ì¶œ CSS Selector")
    body_selector: str = Field(description="ë³¸ë¬¸ ì¶”ì¶œ CSS Selector")
    date_selector: str = Field(description="ë‚ ì§œ ì¶”ì¶œ CSS Selector")
    confidence: float = Field(ge=0.0, le=1.0, description="ì‹ ë¢°ë„ (0.0 ~ 1.0)")
    reasoning: str = Field(description="ì„ íƒ ê·¼ê±° ì„¤ëª…")

class SelectorAnalysis(BaseModel):
    """
    GPT-4o ë¶„ì„ ê²°ê³¼
    """
    candidates: List[SelectorCandidate] = Field(min_items=3, max_items=3, description="3ê°œ í›„ë³´")

# Prompt Template
GPT_SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ HTML êµ¬ì¡° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ HTMLì—ì„œ ë‰´ìŠ¤ ê¸°ì‚¬ì˜ **title**, **body**, **date**ë¥¼ ì¶”ì¶œí•  CSS Selectorë¥¼ ìƒì„±í•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­**:
1. 3ê°œì˜ í›„ë³´ Selectorë¥¼ ì œì•ˆí•˜ì„¸ìš” (ì‹ ë¢°ë„ ë†’ì€ ìˆœì„œ).
2. ê° í›„ë³´ëŠ” title_selector, body_selector, date_selectorë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
3. CSS SelectorëŠ” BeautifulSoupì˜ `select_one()` ë©”ì„œë“œë¡œ ì‚¬ìš© ê°€ëŠ¥í•´ì•¼ í•©ë‹ˆë‹¤.
4. ì‹ ë¢°ë„(confidence)ëŠ” 0.0 ~ 1.0 ë²”ìœ„ë¡œ í‰ê°€í•˜ì„¸ìš”.
5. reasoningì— ì„ íƒ ê·¼ê±°ë¥¼ ëª…í™•íˆ ì„¤ëª…í•˜ì„¸ìš”.

**Good Examples**:
- title_selector: "article h1.headline"
- body_selector: "article div.article-body"
- date_selector: "article time[datetime]"

**Bad Examples** (í”¼í•  ê²ƒ):
- "div > div > div > p:nth-child(3)"  # ë„ˆë¬´ ì·¨ì•½í•œ êµ¬ì¡°
- "#content123"  # ë™ì  ID
- ".ad-container"  # ê´‘ê³  ì˜ì—­

**ë‰´ìŠ¤ ê¸°ì‚¬ íŠ¹ì§•**:
- í•œêµ­ì–´/ì˜ë¬¸ ë‰´ìŠ¤ ì‚¬ì´íŠ¸ ë¶„ì„
- ì‹œë©˜í‹± HTML (article, header, time íƒœê·¸ ìš°ì„ )
- ë³¸ë¬¸ì€ ìµœì†Œ 500ì ì´ìƒ (ê´‘ê³  ì œì™¸)
- ë‚ ì§œëŠ” ISO 8601 í˜•ì‹ ë˜ëŠ” í•œêµ­ì–´ ë‚ ì§œ í¬ë§·
"""

def analyze_html_with_gpt(html: str, site_name: str) -> dict:
    """
    GPT-4oë¡œ HTML ë¶„ì„ ë° CSS Selector ìƒì„±
    
    Args:
        html: ì „ì²˜ë¦¬ëœ HTML (extract_article_content ì ìš©)
        site_name: ì‚¬ì´íŠ¸ ì´ë¦„ (ë””ë²„ê¹…ìš©)
    
    Returns:
        {
            "candidates": [
                {
                    "title_selector": "...",
                    "body_selector": "...",
                    "date_selector": "...",
                    "confidence": 0.85,
                    "reasoning": "..."
                },
                {...}, {...}
            ],
            "error": None
        }
    """
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    try:
        response = client.beta.chat.completions.parse(
            model="gpt-4o-2024-08-06",
            messages=[
                {"role": "system", "content": GPT_SYSTEM_PROMPT},
                {
                    "role": "user",
                    "content": f"ì‚¬ì´íŠ¸ ì´ë¦„: {site_name}\n\nHTML:\n{html}"
                }
            ],
            response_format=SelectorAnalysis,
            temperature=0.3,  # ì¼ê´€ì„± ìœ„í•´ ë‚®ì€ temperature
            max_tokens=1500
        )
        
        # Pydantic ëª¨ë¸ â†’ dict
        result = response.choices[0].message.parsed
        return {
            "candidates": [c.model_dump() for c in result.candidates],
            "error": None
        }
    
    except Exception as e:
        return {
            "candidates": [],
            "error": str(e)
        }

# LangGraph Node
def gpt_analyzer_node(state: dict) -> dict:
    """
    LangGraph Node: GPT-4o Analyzer
    """
    from src.utils.html_cleaner import extract_article_content
    
    raw_html = state["raw_html"]
    site_name = state["site_name"]
    
    # HTML ì „ì²˜ë¦¬
    cleaned_html = extract_article_content(raw_html)
    
    # GPT-4o ë¶„ì„
    result = analyze_html_with_gpt(cleaned_html, site_name)
    
    if result["error"]:
        return {
            "gpt_candidates": [],
            "error_log": state.get("error_log", []) + [f"[GPT Error] {result['error']}"]
        }
    
    return {
        "gpt_candidates": result["candidates"],
        "error_log": state.get("error_log", [])
    }
```

**ë‹¨ìœ„ í…ŒìŠ¤íŠ¸**:
```python
# tests/test_gpt_analyzer.py

import pytest
from src.agents.gpt_analyzer import analyze_html_with_gpt
from src.utils.html_cleaner import extract_article_content

def test_gpt_analyzer_yonhap():
    """ì—°í•©ë‰´ìŠ¤ HTML ë¶„ì„ í…ŒìŠ¤íŠ¸"""
    # ì‹¤ì œ HTML ë¡œë“œ
    with open("tests/fixtures/yonhap_sample.html", "r", encoding="utf-8") as f:
        html = f.read()
    
    cleaned = extract_article_content(html)
    result = analyze_html_with_gpt(cleaned, "yonhap")
    
    assert result["error"] is None
    assert len(result["candidates"]) == 3
    
    # ì²« ë²ˆì§¸ í›„ë³´ ê²€ì¦
    first = result["candidates"][0]
    assert "title_selector" in first
    assert "body_selector" in first
    assert "date_selector" in first
    assert 0.0 <= first["confidence"] <= 1.0
    assert len(first["reasoning"]) > 10  # ì„¤ëª… ì¡´ì¬
```

---

### Phase 2: Gemini Validator (2-3ì‹œê°„)

#### 2.1 Validator ë¡œì§ ì„¤ê³„ (1ì‹œê°„)

**ğŸ¤” HITL ì˜ì‚¬ê²°ì • í¬ì¸íŠ¸ #5: Gemini ê²€ì¦ ë°©ì‹**

**ì§ˆë¬¸**: Geminiê°€ ì–´ë–»ê²Œ Selectorë¥¼ ê²€ì¦í•  ê²ƒì¸ê°€?

**ì˜µì…˜ A: GPT Selectorë¡œ ìƒ˜í”Œ 10ê°œ ì¶”ì¶œ â†’ Geminiê°€ í’ˆì§ˆ íŒë‹¨ (PRD ë°©ì‹)**
- ì¥ì :
  - ë…ë¦½ì  ê²€ì¦ (2-Agent í•©ì˜)
  - Geminiê°€ GPT ê²°ê³¼ë¥¼ ê²€ì¦ (í¸í–¥ ë°©ì§€)
- ë‹¨ì :
  - Geminiì—ê²Œ ìƒ˜í”Œ í…ìŠ¤íŠ¸ë§Œ ì „ë‹¬ (HTML êµ¬ì¡° ëª» ë´„)
  - GPT Selectorê°€ ì™„ì „ ì‹¤íŒ¨ ì‹œ ê²€ì¦ ë¶ˆê°€

**ì˜µì…˜ B: Geminiê°€ ë…ë¦½ì ìœ¼ë¡œ HTML ë¶„ì„ â†’ GPT ê²°ê³¼ì™€ ë¹„êµ**
- ì¥ì :
  - ì™„ì „ ë…ë¦½ ë¶„ì„
  - GPT ì‹¤íŒ¨í•´ë„ Geminië¡œ ë³µêµ¬ ê°€ëŠ¥
- ë‹¨ì :
  - ë¹„ìš© 2ë°°
  - ì‹œê°„ 2ë°°
  - êµ¬í˜„ ë³µì¡ë„ ì¦ê°€

**ê¶Œì¥ ê²°ì •**: **ì˜µì…˜ A (PRD ë°©ì‹)**
- ê·¼ê±°:
  - PRD-2-TECHNICAL-SPEC.md ëª…ì‹œ (137-140ì¤„)
  - 2-Agent í•©ì˜ = GPT ìƒì„± + Gemini ê²€ì¦
  - ë¹„ìš©/ì‹œê°„ íš¨ìœ¨ì 
  - GeminiëŠ” "Validator" ì—­í•  (Analyzer ì•„ë‹˜)

**ê²€ì¦ í”„ë¡œì„¸ìŠ¤**:
```python
# Pseudocode

for candidate in gpt_candidates:
    # 1. BeautifulSoupìœ¼ë¡œ Selector í…ŒìŠ¤íŠ¸
    soup = BeautifulSoup(raw_html, 'html.parser')
    
    title = soup.select_one(candidate["title_selector"])
    body_elements = soup.select(candidate["body_selector"])[:10]  # ìµœëŒ€ 10ê°œ
    date = soup.select_one(candidate["date_selector"])
    
    # 2. ìƒ˜í”Œ ì¶”ì¶œ
    samples = {
        "title": title.text if title else None,
        "body_snippets": [el.text[:100] for el in body_elements],  # ê° 100ì
        "date": date.text if date else None
    }
    
    # 3. Geminiì—ê²Œ ìƒ˜í”Œ í’ˆì§ˆ í‰ê°€ ìš”ì²­
    gemini_result = validate_samples_with_gemini(samples, candidate)
    
    if gemini_result["valid"]:
        return candidate  # ì²« ë²ˆì§¸ í†µê³¼í•œ í›„ë³´ ì„ íƒ
```

**ğŸ¤” HITL ì˜ì‚¬ê²°ì • í¬ì¸íŠ¸ #6: Gemini ê²€ì¦ ì‹¤íŒ¨ ê¸°ì¤€**

**ì§ˆë¬¸**: Geminiê°€ "ì‹¤íŒ¨"ë¡œ íŒë‹¨í•˜ëŠ” ê¸°ì¤€ì€?

**ì˜µì…˜ A: 10ê°œ ìƒ˜í”Œ ì¤‘ 8ê°œ ì´ìƒ ì„±ê³µ (80%)**
- ì—„ê²©ë„: ë³´í†µ
- ìœ„í—˜: DOM ë³€ê²½ì— ì·¨ì•½í•  ìˆ˜ ìˆìŒ

**ì˜µì…˜ B: 10ê°œ ìƒ˜í”Œ ì¤‘ 9ê°œ ì´ìƒ ì„±ê³µ (90%)**
- ì—„ê²©ë„: ë†’ìŒ
- ìœ„í—˜: ê³¼ë„í•œ ì¬ì‹œë„ ë°œìƒ ê°€ëŠ¥

**ì˜µì…˜ C: ê·œì¹™ ê¸°ë°˜ ê²€ì¦**
- Title: 10ì ì´ìƒ, 500ì ì´í•˜
- Body: ê° snippet 50ì ì´ìƒ
- Date: ìˆ«ì í¬í•¨ (ë‚ ì§œ íŒ¨í„´ ì •ê·œí‘œí˜„ì‹)

**ê¶Œì¥ ê²°ì •**: **ì˜µì…˜ A (80%) + ì˜µì…˜ C (ê·œì¹™ ê¸°ë°˜) ì¡°í•©**
- ê·¼ê±°:
  - ì •ëŸ‰ì  ê¸°ì¤€ (80%) + ì •ì„±ì  ê¸°ì¤€ (ê·œì¹™)
  - ë‰´ìŠ¤ ì‚¬ì´íŠ¸ íŠ¹ì„± ê³ ë ¤ (í•œêµ­ì–´/ì˜ë¬¸ í˜¼ì¬)
  - False positive ë°©ì§€ (ê´‘ê³  í…ìŠ¤íŠ¸ ê²€ì¶œ)

**ê²€ì¦ ê·œì¹™**:
```python
# src/agents/gemini_validator.py (ì¼ë¶€)

def validate_sample_quality(samples: dict) -> tuple[bool, int, str]:
    """
    ìƒ˜í”Œ í’ˆì§ˆ ê²€ì¦ (ê·œì¹™ ê¸°ë°˜)
    
    Returns:
        (valid, score, failure_reason)
    """
    score = 0
    max_score = 100
    
    # Title ê²€ì¦ (30ì )
    title = samples.get("title", "")
    if title and 10 <= len(title) <= 500:
        score += 30
    elif not title:
        return False, 0, "Title missing"
    elif len(title) < 10:
        return False, score, "Title too short (<10 chars)"
    
    # Body ê²€ì¦ (60ì )
    body_snippets = samples.get("body_snippets", [])
    if len(body_snippets) < 8:  # 10ê°œ ì¤‘ 8ê°œ ì´ìƒ í•„ìˆ˜ (80%)
        return False, score, f"Insufficient body samples ({len(body_snippets)}/10)"
    
    # ê° snippet 50ì ì´ìƒ
    valid_snippets = [s for s in body_snippets if len(s) >= 50]
    if len(valid_snippets) < 8:
        return False, score, f"Too many short snippets ({len(valid_snippets)}/10)"
    
    score += 60
    
    # Date ê²€ì¦ (10ì )
    date = samples.get("date", "")
    if date and any(char.isdigit() for char in date):
        score += 10
    # DateëŠ” ì„ íƒ ì‚¬í•­ (ì—†ì–´ë„ í†µê³¼)
    
    return True, score, None
```

**ğŸ¤” HITL ì˜ì‚¬ê²°ì • í¬ì¸íŠ¸ #7: Gemini ëª¨ë¸ ì„ íƒ**

**ì§ˆë¬¸**: ì–´ë–¤ Gemini ëª¨ë¸ì„ ì‚¬ìš©?

**ì˜µì…˜ A: `gemini-2.0-flash-exp` (ìµœì‹  ì‹¤í—˜)**
- ê°€ê²©: ë¬´ë£Œ (2025-11 ê¸°ì¤€)
- ì„±ëŠ¥: ë¹ ë¦„
- ì•ˆì •ì„±: ì‹¤í—˜ ë²„ì „

**ì˜µì…˜ B: `gemini-1.5-flash`**
- ê°€ê²©: $0.075 / 1M input tokens
- ì„±ëŠ¥: ë¹ ë¦„
- ì•ˆì •ì„±: ì•ˆì • ë²„ì „

**ì˜µì…˜ C: `gemini-1.5-pro`**
- ê°€ê²©: $1.25 / 1M input tokens
- ì„±ëŠ¥: ìµœê³ 
- ì•ˆì •ì„±: ì•ˆì • ë²„ì „

**ê¶Œì¥ ê²°ì •**: **ì˜µì…˜ A (`gemini-2.0-flash-exp`)**
- ê·¼ê±°:
  - PRD-2-TECHNICAL-SPEC.md ëª…ì‹œ (19ì¤„: "Gemini 2.5 Flash")
  - ë¬´ë£Œ (PoC ë¹„ìš© ì ˆê°)
  - ê²€ì¦ ì‘ì—…ì€ ê°„ë‹¨ (ìƒì„± ì‘ì—… ì•„ë‹˜)
  - Productionì—ì„œ 1.5-flashë¡œ ì „í™˜ ê°€ëŠ¥

**Gemini Validator êµ¬í˜„**:
```python
# src/agents/gemini_validator.py

import google.generativeai as genai
from bs4 import BeautifulSoup
from typing import Dict, List, Optional
import os

genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

# Prompt Template
GEMINI_VALIDATION_PROMPT = """
ë‹¹ì‹ ì€ ë‰´ìŠ¤ ê¸°ì‚¬ í’ˆì§ˆ ê²€ì¦ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹¤ìŒ ìƒ˜í”Œì´ ë‰´ìŠ¤ ê¸°ì‚¬ì—ì„œ ì¶”ì¶œëœ ì˜¬ë°”ë¥¸ ì½˜í…ì¸ ì¸ì§€ ê²€ì¦í•˜ì„¸ìš”.

**ìƒ˜í”Œ**:
- Title: "{title}"
- Body Snippets (10ê°œ):
{body_snippets}
- Date: "{date}"

**ê²€ì¦ ê¸°ì¤€**:
1. Title: ë‰´ìŠ¤ ì œëª©ì²˜ëŸ¼ ë³´ì´ëŠ”ê°€? (ê´‘ê³ /ë²„íŠ¼ í…ìŠ¤íŠ¸ ì•„ë‹˜)
2. Body: ë‰´ìŠ¤ ë³¸ë¬¸ì²˜ëŸ¼ ë³´ì´ëŠ”ê°€? (ìµœì†Œ 8ê°œ snippetì´ 50ì ì´ìƒ)
3. Date: ë‚ ì§œ í˜•ì‹ì´ ë§ëŠ”ê°€? (ì„ íƒ ì‚¬í•­)

**íŒì •**:
- "VALID": ëª¨ë“  ê¸°ì¤€ í†µê³¼
- "INVALID": í•˜ë‚˜ë¼ë„ ì‹¤íŒ¨

**ì‘ë‹µ í˜•ì‹** (JSON):
{{
  "verdict": "VALID" or "INVALID",
  "confidence": 0.85,
  "reasoning": "ê²€ì¦ ê·¼ê±° ì„¤ëª…"
}}
"""

def validate_selector_with_gemini(
    raw_html: str,
    candidate: Dict[str, str]
) -> Dict[str, any]:
    """
    Geminië¡œ Selector ê²€ì¦
    
    Args:
        raw_html: ì „ì²´ HTML
        candidate: GPTê°€ ì œì•ˆí•œ Selector í›„ë³´
    
    Returns:
        {
            "valid": True/False,
            "validation_score": 0-100,
            "samples": [...],
            "failure_reason": None or str,
            "gemini_reasoning": str
        }
    """
    soup = BeautifulSoup(raw_html, 'html.parser')
    
    # 1. Selectorë¡œ ìƒ˜í”Œ ì¶”ì¶œ
    title_el = soup.select_one(candidate["title_selector"])
    body_els = soup.select(candidate["body_selector"])[:10]
    date_el = soup.select_one(candidate["date_selector"])
    
    samples = {
        "title": title_el.get_text(strip=True) if title_el else None,
        "body_snippets": [el.get_text(strip=True)[:100] for el in body_els],
        "date": date_el.get_text(strip=True) if date_el else None
    }
    
    # 2. ê·œì¹™ ê¸°ë°˜ 1ì°¨ ê²€ì¦
    rule_valid, rule_score, rule_reason = validate_sample_quality(samples)
    if not rule_valid:
        return {
            "valid": False,
            "validation_score": rule_score,
            "samples": samples,
            "failure_reason": rule_reason,
            "gemini_reasoning": None
        }
    
    # 3. Gemini 2ì°¨ ê²€ì¦
    try:
        model = genai.GenerativeModel('gemini-2.0-flash-exp')
        
        prompt = GEMINI_VALIDATION_PROMPT.format(
            title=samples["title"],
            body_snippets="\n".join([f"{i+1}. {s}" for i, s in enumerate(samples["body_snippets"])]),
            date=samples["date"]
        )
        
        response = model.generate_content(
            prompt,
            generation_config=genai.GenerationConfig(
                temperature=0.1,
                response_mime_type="application/json"
            )
        )
        
        # JSON íŒŒì‹±
        import json
        gemini_result = json.loads(response.text)
        
        is_valid = gemini_result["verdict"] == "VALID"
        
        return {
            "valid": is_valid,
            "validation_score": rule_score if is_valid else 0,
            "samples": samples,
            "failure_reason": None if is_valid else "Gemini rejected",
            "gemini_reasoning": gemini_result["reasoning"]
        }
    
    except Exception as e:
        # Gemini ì‹¤íŒ¨ ì‹œ ê·œì¹™ ê¸°ë°˜ ê²°ê³¼ ì‚¬ìš©
        return {
            "valid": rule_valid,
            "validation_score": rule_score,
            "samples": samples,
            "failure_reason": f"Gemini API error: {e}",
            "gemini_reasoning": None
        }

def validate_sample_quality(samples: dict) -> tuple[bool, int, str]:
    """
    ê·œì¹™ ê¸°ë°˜ ìƒ˜í”Œ í’ˆì§ˆ ê²€ì¦ (ìœ„ì—ì„œ ì •ì˜í•œ í•¨ìˆ˜)
    """
    # ... (ìœ„ ì½”ë“œ ì°¸ì¡°)
    pass

# LangGraph Node
def gemini_validator_node(state: dict) -> dict:
    """
    LangGraph Node: Gemini Validator
    
    3ê°œ í›„ë³´ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ê²€ì¦, ì²« ë²ˆì§¸ í†µê³¼í•œ í›„ë³´ ì„ íƒ
    """
    raw_html = state["raw_html"]
    candidates = state["gpt_candidates"]
    
    if not candidates:
        return {
            "gemini_validation": {"valid": False, "failure_reason": "No GPT candidates"},
            "consensus_reached": False
        }
    
    # 3ê°œ í›„ë³´ ìˆœì°¨ ê²€ì¦ (confidence ë†’ì€ ìˆœì„œ)
    sorted_candidates = sorted(candidates, key=lambda x: x["confidence"], reverse=True)
    
    for idx, candidate in enumerate(sorted_candidates):
        validation = validate_selector_with_gemini(raw_html, candidate)
        
        if validation["valid"]:
            return {
                "gemini_validation": {
                    **validation,
                    "candidate_index": idx
                },
                "selected_selector": {
                    "title_selector": candidate["title_selector"],
                    "body_selector": candidate["body_selector"],
                    "date_selector": candidate["date_selector"]
                },
                "consensus_reached": True  # ê²€ì¦ í†µê³¼ = í•©ì˜ ì„±ê³µ
            }
    
    # 3ê°œ ëª¨ë‘ ì‹¤íŒ¨
    return {
        "gemini_validation": {"valid": False, "failure_reason": "All candidates rejected"},
        "consensus_reached": False
    }
```

---

### Phase 3: Consensus Logic ë° ì¬ì‹œë„ (2ì‹œê°„)

#### 3.1 í•©ì˜ ì²´í¬ ë¡œì§ (1ì‹œê°„)

**ğŸ¤” HITL ì˜ì‚¬ê²°ì • í¬ì¸íŠ¸ #8: í•©ì˜ ì„±ê³µ ì¡°ê±´**

**ì§ˆë¬¸**: 2-Agent í•©ì˜ê°€ ì„±ê³µí–ˆë‹¤ê³  íŒë‹¨í•˜ëŠ” ì •í™•í•œ ì¡°ê±´ì€?

**PRD ê¸°ì¤€** (142ì¤„):
```
GPT confidence â‰¥ 0.7 AND Gemini valid=true
```

**ë¬¸ì œì **: Geminiê°€ 3ê°œ í›„ë³´ ì¤‘ ì–´ë–¤ ê²ƒì„ ì„ íƒ?

**ì˜µì…˜ A: Geminiê°€ 3ê°œ ëª¨ë‘ ê²€ì¦ â†’ ê°€ì¥ ì¢‹ì€ ê²ƒ ì„ íƒ**
- ì¥ì : í’ˆì§ˆ ìµœìš°ì„ 
- ë‹¨ì : Gemini API í˜¸ì¶œ 3ë²ˆ (ë¹„ìš©/ì‹œê°„ ì¦ê°€)

**ì˜µì…˜ B: GPT confidence ìˆœìœ¼ë¡œ ìˆœì°¨ ê²€ì¦ â†’ ì²« ë²ˆì§¸ valid ì„ íƒ**
- ì¥ì : íš¨ìœ¨ì  (í‰ê·  1.5íšŒ í˜¸ì¶œ)
- ë‹¨ì : ìµœì„ ì˜ í›„ë³´ê°€ ì•„ë‹ ìˆ˜ ìˆìŒ

**ê¶Œì¥ ê²°ì •**: **ì˜µì…˜ B (ìˆœì°¨ ê²€ì¦)**
- ê·¼ê±°:
  - GPT confidenceê°€ ì´ë¯¸ ìˆœìœ„ë¥¼ ë§¤ê¹€
  - ì²« ë²ˆì§¸ í›„ë³´ í†µê³¼ í™•ë¥  ~70%
  - ë¹„ìš©/ì‹œê°„ íš¨ìœ¨ì 
  - Phase 2.1ì—ì„œ ì´ë¯¸ êµ¬í˜„ë¨ (gemini_validator_node)

**í•©ì˜ ì¡°ê±´ ëª…í™•í™”**:
```python
def check_consensus(state: dict) -> bool:
    """
    í•©ì˜ ì„±ê³µ ì¡°ê±´ ì²´í¬
    
    ì¡°ê±´:
    1. gemini_validation["valid"] == True
    2. selected_selectorê°€ ì¡´ì¬
    3. selected_selectorì˜ ì›ë³¸ í›„ë³´ confidence â‰¥ 0.7
    """
    gemini_valid = state.get("gemini_validation", {}).get("valid", False)
    if not gemini_valid:
        return False
    
    selected = state.get("selected_selector")
    if not selected:
        return False
    
    # ì„ íƒëœ í›„ë³´ì˜ confidence í™•ì¸
    candidate_idx = state["gemini_validation"].get("candidate_index", -1)
    if candidate_idx < 0:
        return False
    
    candidates = state.get("gpt_candidates", [])
    if candidate_idx >= len(candidates):
        return False
    
    selected_candidate = candidates[candidate_idx]
    if selected_candidate["confidence"] < 0.7:
        return False
    
    return True
```

**Conditional Edge ì„¤ê³„**:
```python
# src/workflow/uc2_recovery.py

def route_after_consensus(state: dict) -> str:
    """
    í•©ì˜ ì²´í¬ í›„ ë¼ìš°íŒ…
    
    ë°˜í™˜:
    - "save_selector": í•©ì˜ ì„±ê³µ â†’ DB ì—…ë°ì´íŠ¸
    - "retry": í•©ì˜ ì‹¤íŒ¨ + retry_count < max_retries
    - "human_intervention": í•©ì˜ ì‹¤íŒ¨ + retry_count â‰¥ max_retries
    """
    consensus = state.get("consensus_reached", False)
    retry_count = state.get("retry_count", 0)
    max_retries = state.get("max_retries", 3)
    
    if consensus:
        return "save_selector"
    elif retry_count < max_retries:
        return "retry"
    else:
        return "human_intervention"
```

#### 3.2 ì¬ì‹œë„ ë¡œì§ (1ì‹œê°„)

**ğŸ¤” HITL ì˜ì‚¬ê²°ì • í¬ì¸íŠ¸ #9: ì¬ì‹œë„ ì‹œ ê°œì„  ë°©ë²•**

**ì§ˆë¬¸**: ì¬ì‹œë„í•  ë•Œ ë‹¨ìˆœ ë°˜ë³µì¸ê°€, ì•„ë‹ˆë©´ í”„ë¡¬í”„íŠ¸ ê°œì„ ì¸ê°€?

**ì˜µì…˜ A: ë‹¨ìˆœ ì¬ì‹œë„ (ê°™ì€ Prompt)**
- ì¥ì : êµ¬í˜„ ê°„ë‹¨
- ë‹¨ì : ê°™ì€ ì‹¤íŒ¨ ë°˜ë³µ ê°€ëŠ¥

**ì˜µì…˜ B: Promptì— ì´ì „ ì‹¤íŒ¨ ì´ìœ  ì¶”ê°€**
- ì¥ì : í•™ìŠµ íš¨ê³¼, ì„±ê³µë¥  ì¦ê°€
- ë‹¨ì : Prompt ë³µì¡ë„ ì¦ê°€

**ì˜µì…˜ C: Temperature ì¡°ì • (0.3 â†’ 0.7 â†’ 0.9)**
- ì¥ì : ë‹¤ì–‘í•œ ì‹œë„
- ë‹¨ì : ì¼ê´€ì„± ì €í•˜

**ê¶Œì¥ ê²°ì •**: **ì˜µì…˜ B (ì‹¤íŒ¨ ì´ìœ  ì¶”ê°€) + Exponential Backoff**
- ê·¼ê±°:
  - GPT-4oëŠ” ë¬¸ë§¥ í•™ìŠµ ëŠ¥ë ¥ ë›°ì–´ë‚¨
  - ì‹¤íŒ¨ ì´ìœ  = Geminiì˜ rejection reasoning
  - Backoffë¡œ API rate limit íšŒí”¼

**ì¬ì‹œë„ Node**:
```python
# src/workflow/uc2_recovery.py

def retry_node(state: dict) -> dict:
    """
    ì¬ì‹œë„ ì „ State ì—…ë°ì´íŠ¸
    """
    import time
    
    retry_count = state.get("retry_count", 0)
    new_count = retry_count + 1
    
    # Exponential Backoff
    sleep_time = 2 ** retry_count  # 1ì´ˆ, 2ì´ˆ, 4ì´ˆ
    time.sleep(sleep_time)
    
    # ì‹¤íŒ¨ ì´ìœ  ìˆ˜ì§‘
    failure_reason = state.get("gemini_validation", {}).get("failure_reason", "Unknown")
    error_log = state.get("error_log", [])
    error_log.append(f"[Retry {new_count}] Previous failure: {failure_reason}")
    
    return {
        "retry_count": new_count,
        "error_log": error_log,
        "consensus_reached": False,  # ë¦¬ì…‹
        "gpt_candidates": [],  # GPT ì¬ì‹¤í–‰ ìœ„í•´ ì´ˆê¸°í™”
        "gemini_validation": {},
        "selected_selector": None
    }
```

**ê°œì„ ëœ GPT Prompt (ì¬ì‹œë„ ì‹œ)**:
```python
# src/agents/gpt_analyzer.py ìˆ˜ì •

def build_gpt_prompt_with_feedback(site_name: str, error_log: List[str]) -> str:
    """
    ì¬ì‹œë„ ì‹œ ì´ì „ ì‹¤íŒ¨ ì´ìœ ë¥¼ ë°˜ì˜í•œ Prompt ìƒì„±
    """
    base_prompt = GPT_SYSTEM_PROMPT
    
    if error_log:
        recent_errors = error_log[-3:]  # ìµœê·¼ 3ê°œ ì—ëŸ¬ë§Œ
        feedback = "\n\n**ì´ì „ ì‹œë„ ì‹¤íŒ¨ ì´ìœ **:\n" + "\n".join(recent_errors)
        feedback += "\n\nìœ„ ì‹¤íŒ¨ë¥¼ í”¼í•˜ê³ , ë” ê²¬ê³ í•œ CSS Selectorë¥¼ ìƒì„±í•˜ì„¸ìš”."
        return base_prompt + feedback
    
    return base_prompt
```

---

### Phase 4: Selector ì—…ë°ì´íŠ¸ ë° ì¬í¬ë¡¤ë§ (1ì‹œê°„)

#### 4.1 DB ì—…ë°ì´íŠ¸ ì „ëµ (30ë¶„)

**ğŸ¤” HITL ì˜ì‚¬ê²°ì • í¬ì¸íŠ¸ #10: Selector ì—…ë°ì´íŠ¸ ì‹œ ì´ì „ ë²„ì „ ë³´ê´€**

**ì§ˆë¬¸**: ìƒˆ Selectorë¡œ ì—…ë°ì´íŠ¸í•  ë•Œ ì´ì „ ë²„ì „ì„ ë³´ê´€í•  ê²ƒì¸ê°€?

**ì˜µì…˜ A: ë®ì–´ì“°ê¸° (ê°„ë‹¨)**
- ì¥ì : êµ¬í˜„ ê°„ë‹¨
- ë‹¨ì : ë¡¤ë°± ë¶ˆê°€

**ì˜µì…˜ B: ë²„ì „ ê´€ë¦¬ (decision_logs í™œìš©)**
- ì¥ì : ë¡¤ë°± ê°€ëŠ¥, ë³€ê²½ ì´ë ¥ ì¶”ì 
- ë‹¨ì : ë³µì¡ë„ ì¦ê°€

**ê¶Œì¥ ê²°ì •**: **ì˜µì…˜ A (ë®ì–´ì“°ê¸°) + decision_logs ë³´ê´€**
- ê·¼ê±°:
  - PoC ë‹¨ê³„, ê°„ë‹¨í•œ êµ¬í˜„
  - decision_logs í…Œì´ë¸”ì— ì´ë¯¸ GPT/Gemini ê²°ê³¼ ì €ì¥ë¨
  - ë¡¤ë°± í•„ìš” ì‹œ decision_logsì—ì„œ ë³µêµ¬ ê°€ëŠ¥
  - Production Phase 2ì—ì„œ selectors í…Œì´ë¸”ì— version ì»¬ëŸ¼ ì¶”ê°€ ê°€ëŠ¥

**êµ¬í˜„**:
```python
# src/workflow/uc2_recovery.py

def save_selector_node(state: dict) -> dict:
    """
    LangGraph Node: DB ì—…ë°ì´íŠ¸
    
    1. selectors í…Œì´ë¸” ì—…ë°ì´íŠ¸
    2. decision_logs í…Œì´ë¸” ì‚½ì…
    3. selectors.success_count ì´ˆê¸°í™” (ìƒˆ Selectorì´ë¯€ë¡œ)
    """
    from src.storage.database import get_db
    from src.storage.models import Selector, DecisionLog
    from datetime import datetime, timezone
    
    site_name = state["site_name"]
    url = state["url"]
    selected = state["selected_selector"]
    
    # JSONB ë°ì´í„° ì¤€ë¹„
    gpt_analysis = {
        "candidates": state.get("gpt_candidates", []),
        "selected_index": state.get("gemini_validation", {}).get("candidate_index", 0)
    }
    
    gemini_validation = state.get("gemini_validation", {})
    
    db = next(get_db())
    try:
        # 1. selectors í…Œì´ë¸” ì—…ë°ì´íŠ¸
        selector = db.query(Selector).filter_by(site_name=site_name).first()
        
        if selector:
            # ê¸°ì¡´ Selector ì—…ë°ì´íŠ¸
            selector.title_selector = selected["title_selector"]
            selector.body_selector = selected["body_selector"]
            selector.date_selector = selected["date_selector"]
            selector.updated_at = datetime.now(timezone.utc)
            selector.success_count = 0  # ë¦¬ì…‹ (ê²€ì¦ í•„ìš”)
            selector.failure_count = 0
        else:
            # ì‹ ê·œ Selector ìƒì„± (UC3)
            selector = Selector(
                site_name=site_name,
                title_selector=selected["title_selector"],
                body_selector=selected["body_selector"],
                date_selector=selected["date_selector"],
                site_type="ssr",  # ê¸°ë³¸ê°’
                success_count=0,
                failure_count=0
            )
            db.add(selector)
        
        # 2. decision_logs í…Œì´ë¸” ì‚½ì…
        decision_log = DecisionLog(
            url=url,
            site_name=site_name,
            gpt_analysis=gpt_analysis,
            gemini_validation=gemini_validation,
            consensus_reached=True,
            retry_count=state.get("retry_count", 0)
        )
        db.add(decision_log)
        
        db.commit()
        
        return {
            "error_log": state.get("error_log", []) + ["[DB] Selector updated successfully"]
        }
    
    except Exception as e:
        db.rollback()
        return {
            "error_log": state.get("error_log", []) + [f"[DB Error] {e}"]
        }
    finally:
        db.close()
```

**decision_logs í™œìš©í•œ ë¡¤ë°±**:
```sql
-- ìˆ˜ë™ ë¡¤ë°± ë°©ë²•

-- 1. ì´ì „ Selector ì¡°íšŒ
SELECT 
    gpt_analysis->'candidates'->0 as previous_selector,
    created_at
FROM decision_logs
WHERE site_name = 'yonhap'
  AND consensus_reached = true
ORDER BY created_at DESC
LIMIT 2;  -- ìµœì‹  2ê°œ (í˜„ì¬ + ì´ì „)

-- 2. ìˆ˜ë™ ë³µì›
UPDATE selectors
SET 
    title_selector = '[ì´ì „ê°’]',
    body_selector = '[ì´ì „ê°’]',
    date_selector = '[ì´ì „ê°’]',
    updated_at = CURRENT_TIMESTAMP
WHERE site_name = 'yonhap';
```

#### 4.2 UC1 ì¬ì‹¤í–‰ (30ë¶„)

**ğŸ¤” HITL ì˜ì‚¬ê²°ì • í¬ì¸íŠ¸ #11: Selector ì—…ë°ì´íŠ¸ í›„ UC1 ìë™ ì¬ì‹¤í–‰**

**ì§ˆë¬¸**: ìƒˆ Selectorë¡œ ì—…ë°ì´íŠ¸í•œ í›„ ë°”ë¡œ ì¬í¬ë¡¤ë§ì„ ì‹¤í–‰í•  ê²ƒì¸ê°€?

**ì˜µì…˜ A: ìë™ ì¬ì‹¤í–‰ (ì™„ì „ ìë™í™”)**
- ì¥ì : ì‚¬ìš©ì ê°œì… ë¶ˆí•„ìš”
- ë‹¨ì : ìƒˆ Selectorê°€ ì˜ëª»ë˜ë©´ ì˜ëª»ëœ ë°ì´í„° ì €ì¥

**ì˜µì…˜ B: ì‚¬ìš©ì í™•ì¸ í›„ ì¬ì‹¤í–‰ (HITL)**
- ì¥ì : ì•ˆì „, í’ˆì§ˆ ë³´ì¥
- ë‹¨ì : ìë™í™” íš¨ê³¼ ê°ì†Œ

**ê¶Œì¥ ê²°ì •**: **ì˜µì…˜ A (ìë™ ì¬ì‹¤í–‰) + í’ˆì§ˆ ì ìˆ˜ ê²€ì¦**
- ê·¼ê±°:
  - Self-Healingì˜ ëª©í‘œ = ìë™í™”
  - UC1 í’ˆì§ˆ ê²€ì¦ (quality_score â‰¥ 80)ìœ¼ë¡œ ì•ˆì „ ì¥ì¹˜
  - ì‹¤íŒ¨ ì‹œ HITLë¡œ escalate

**êµ¬í˜„**:
```python
# src/workflow/uc2_recovery.py

def re_crawl_node(state: dict) -> dict:
    """
    LangGraph Node: ìƒˆ Selectorë¡œ ì¬í¬ë¡¤ë§
    
    UC1 Validation Agent ì¬í˜¸ì¶œ
    """
    from src.workflow.uc1_validation import create_uc1_validation_agent
    
    url = state["url"]
    site_name = state["site_name"]
    
    # UC1 Graph ìƒì„±
    uc1_graph = create_uc1_validation_agent()
    
    # ì¬í¬ë¡¤ë§ (ìƒˆ SelectorëŠ” ì´ë¯¸ DBì— ì—…ë°ì´íŠ¸ë¨)
    # TODO: Scrapy Spider í˜¸ì¶œ ë¡œì§ (src/crawlers/spiders/)
    # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ì‹œë®¬ë ˆì´ì…˜
    
    # ì‹¤ì œ êµ¬í˜„ ì‹œ:
    # 1. Scrapy Spider ì‹¤í–‰
    # 2. í¬ë¡¤ë§ ê²°ê³¼ ì¶”ì¶œ
    # 3. UC1 ì…ë ¥ìœ¼ë¡œ ì „ë‹¬
    
    uc1_input = {
        "url": url,
        "site_name": site_name,
        "title": "[ì¬í¬ë¡¤ë§ ê²°ê³¼ Title]",  # Scrapy ê²°ê³¼
        "body": "[ì¬í¬ë¡¤ë§ ê²°ê³¼ Body]",    # Scrapy ê²°ê³¼
        "date": "[ì¬í¬ë¡¤ë§ ê²°ê³¼ Date]",    # Scrapy ê²°ê³¼
        "quality_score": 0,
        "missing_fields": [],
        "next_action": "save"
    }
    
    uc1_result = uc1_graph.invoke(uc1_input)
    
    return {
        "uc1_result": uc1_result,
        "error_log": state.get("error_log", []) + ["[Re-crawl] Completed"]
    }
```

---

### Phase 5: Human-in-the-Loop ì¸í„°í˜ì´ìŠ¤ (1-2ì‹œê°„)

#### 5.1 HITL íŠ¸ë¦¬ê±° ì¡°ê±´ (30ë¶„)

**HITL í•„ìš” ì‹œì **:
1. **3íšŒ ì¬ì‹œë„ ì‹¤íŒ¨**: retry_count â‰¥ max_retries
2. **GPT confidence ë§¤ìš° ë‚®ìŒ**: ëª¨ë“  í›„ë³´ < 0.5
3. **Gemini ê²€ì¦ ëª¨ë‘ ì‹¤íŒ¨**: 3ê°œ í›„ë³´ ëª¨ë‘ valid=false
4. **ì‚¬ìš©ì ëª…ì‹œì  ìš”ì²­**: manual_review í”Œë˜ê·¸

**êµ¬í˜„**:
```python
# src/workflow/uc2_recovery.py

def human_intervention_node(state: dict) -> dict:
    """
    LangGraph Node: HITL ê°œì… í•„ìš”
    
    1. Stateë¥¼ DBì— ì €ì¥ (pending_review)
    2. ë¡œê·¸ ê¸°ë¡
    3. Gradio UIì—ì„œ í‘œì‹œ ê°€ëŠ¥í•˜ë„ë¡ í”Œë˜ê·¸ ì„¤ì •
    """
    from src.storage.database import get_db
    from src.storage.models import DecisionLog
    
    url = state["url"]
    site_name = state["site_name"]
    
    db = next(get_db())
    try:
        # decision_logsì— "pending review" ìƒíƒœ ì €ì¥
        decision_log = DecisionLog(
            url=url,
            site_name=site_name,
            gpt_analysis={"candidates": state.get("gpt_candidates", [])},
            gemini_validation=state.get("gemini_validation", {}),
            consensus_reached=False,
            retry_count=state.get("retry_count", 0)
        )
        db.add(decision_log)
        db.commit()
        
        # ë¡œê¹…
        print(f"\n{'='*60}")
        print(f"[HITL] Manual intervention required")
        print(f"URL: {url}")
        print(f"Site: {site_name}")
        print(f"Retry count: {state.get('retry_count', 0)}")
        print(f"Error log: {state.get('error_log', [])}")
        print(f"{'='*60}\n")
        
        return {
            "error_log": state.get("error_log", []) + ["[HITL] Manual review pending"]
        }
    
    except Exception as e:
        return {
            "error_log": state.get("error_log", []) + [f"[HITL Error] {e}"]
        }
    finally:
        db.close()
```

#### 5.2 HITL ì¸í„°í˜ì´ìŠ¤ (Gradio) (1ì‹œê°„)

**ğŸ¤” HITL ì˜ì‚¬ê²°ì • í¬ì¸íŠ¸ #12: HITL ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„ ë°©ë²•**

**ì§ˆë¬¸**: HITLì„ ì–´ë–»ê²Œ ì‚¬ìš©ìì—ê²Œ ì œê³µ?

**ì˜µì…˜ A: Gradio UIì— "ìˆ˜ë™ ê²€í† " íƒ­ ì¶”ê°€**
- ì¥ì : ê¸°ì¡´ UI í™•ì¥, ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥
- ë‹¨ì : ì‹¤ì‹œê°„ ì•Œë¦¼ ì—†ìŒ

**ì˜µì…˜ B: í„°ë¯¸ë„ì— ì…ë ¥ í”„ë¡¬í”„íŠ¸**
- ì¥ì : êµ¬í˜„ ë§¤ìš° ê°„ë‹¨
- ë‹¨ì : ì‚¬ìš©ì ê²½í—˜ ë‚˜ì¨

**ì˜µì…˜ C: Slack/ì´ë©”ì¼ ì•Œë¦¼ + ì›¹ ë§í¬**
- ì¥ì : ì‹¤ì‹œê°„ ì•Œë¦¼, í”„ë¡œë•ì…˜ ë ˆë²¨
- ë‹¨ì : ì™¸ë¶€ ì„œë¹„ìŠ¤ ì—°ë™ í•„ìš”

**ê¶Œì¥ ê²°ì •**: **ì˜µì…˜ A (Gradio íƒ­ ì¶”ê°€)**
- ê·¼ê±°:
  - PoC ë‹¨ê³„, ë°ëª¨ìš©
  - ê¸°ì¡´ UI (`src/ui/app.py`) í™•ì¥
  - Productionì—ì„œ ì˜µì…˜ Cë¡œ ì „í™˜

**Gradio UI êµ¬í˜„**:
```python
# src/ui/app.py (ê¸°ì¡´ íŒŒì¼ í™•ì¥)

import gradio as gr
from src.storage.database import get_db
from src.storage.models import DecisionLog, Selector
import pandas as pd

def load_pending_reviews():
    """
    DBì—ì„œ consensus_reached=Falseì¸ í•­ëª© ì¡°íšŒ
    """
    db = next(get_db())
    try:
        pending = db.query(DecisionLog).filter_by(consensus_reached=False).all()
        
        data = []
        for log in pending:
            data.append({
                "ID": log.id,
                "URL": log.url[:50] + "...",
                "Site": log.site_name,
                "Retry Count": log.retry_count,
                "Created At": log.created_at.strftime("%Y-%m-%d %H:%M")
            })
        
        return pd.DataFrame(data)
    finally:
        db.close()

def view_review_details(log_id: int):
    """
    íŠ¹ì • DecisionLog ìƒì„¸ ë³´ê¸°
    """
    db = next(get_db())
    try:
        log = db.query(DecisionLog).filter_by(id=log_id).first()
        if not log:
            return "Not found", "", ""
        
        # GPT í›„ë³´ í¬ë§·íŒ…
        gpt_text = ""
        for i, cand in enumerate(log.gpt_analysis.get("candidates", [])):
            gpt_text += f"\n**Candidate {i+1}** (confidence: {cand['confidence']})\n"
            gpt_text += f"  - Title: `{cand['title_selector']}`\n"
            gpt_text += f"  - Body: `{cand['body_selector']}`\n"
            gpt_text += f"  - Date: `{cand['date_selector']}`\n"
            gpt_text += f"  - Reasoning: {cand['reasoning']}\n"
        
        # Gemini ê²€ì¦ ê²°ê³¼
        gemini = log.gemini_validation or {}
        gemini_text = f"Valid: {gemini.get('valid', False)}\n"
        gemini_text += f"Failure Reason: {gemini.get('failure_reason', 'N/A')}\n"
        
        return log.url, gpt_text, gemini_text
    finally:
        db.close()

def manual_approve_selector(log_id: int, selected_candidate_idx: int):
    """
    ìˆ˜ë™ìœ¼ë¡œ Selector ìŠ¹ì¸
    """
    db = next(get_db())
    try:
        log = db.query(DecisionLog).filter_by(id=log_id).first()
        if not log:
            return "Error: Log not found"
        
        candidates = log.gpt_analysis.get("candidates", [])
        if selected_candidate_idx >= len(candidates):
            return "Error: Invalid candidate index"
        
        selected = candidates[selected_candidate_idx]
        
        # selectors í…Œì´ë¸” ì—…ë°ì´íŠ¸
        selector = db.query(Selector).filter_by(site_name=log.site_name).first()
        if selector:
            selector.title_selector = selected["title_selector"]
            selector.body_selector = selected["body_selector"]
            selector.date_selector = selected["date_selector"]
        else:
            selector = Selector(
                site_name=log.site_name,
                title_selector=selected["title_selector"],
                body_selector=selected["body_selector"],
                date_selector=selected["date_selector"]
            )
            db.add(selector)
        
        # decision_log ì—…ë°ì´íŠ¸
        log.consensus_reached = True
        
        db.commit()
        return f"Success: Selector updated for {log.site_name}"
    
    except Exception as e:
        db.rollback()
        return f"Error: {e}"
    finally:
        db.close()

# Gradio UI
with gr.Blocks() as app:
    gr.Markdown("# CrawlAgent PoC - UC2 Manual Review")
    
    with gr.Tab("ğŸ” Pending Reviews"):
        refresh_btn = gr.Button("ğŸ”„ Refresh")
        pending_table = gr.Dataframe(label="Pending Reviews")
        
        refresh_btn.click(load_pending_reviews, outputs=pending_table)
    
    with gr.Tab("ğŸ“ Review Details"):
        log_id_input = gr.Number(label="DecisionLog ID", precision=0)
        view_btn = gr.Button("View Details")
        
        url_output = gr.Textbox(label="URL")
        gpt_output = gr.Markdown(label="GPT Candidates")
        gemini_output = gr.Textbox(label="Gemini Validation")
        
        view_btn.click(
            view_review_details,
            inputs=log_id_input,
            outputs=[url_output, gpt_output, gemini_output]
        )
    
    with gr.Tab("âœ… Approve Selector"):
        approve_log_id = gr.Number(label="DecisionLog ID", precision=0)
        candidate_idx = gr.Number(label="Candidate Index (0-2)", precision=0)
        approve_btn = gr.Button("Approve & Update DB")
        approve_result = gr.Textbox(label="Result")
        
        approve_btn.click(
            manual_approve_selector,
            inputs=[approve_log_id, candidate_idx],
            outputs=approve_result
        )

# app.launch() ëŠ” main() í•¨ìˆ˜ì—ì„œ í˜¸ì¶œ
```

---

### Phase 6: UC2 StateGraph í†µí•© (1ì‹œê°„)

**ì „ì²´ Graph êµ¬ì„±**:
```python
# src/workflow/uc2_recovery.py

from typing import TypedDict, Optional, List, Dict, Any, Literal
from langgraph.graph import StateGraph, START, END

# State ì •ì˜ (Phase 1.1)
class RecoveryState(TypedDict):
    # ... (ìœ„ ì°¸ì¡°)
    pass

# Nodes (Phase 1-5ì—ì„œ êµ¬í˜„)
def fetch_raw_html(state: RecoveryState) -> dict:
    # ... (Phase 1.1)
    pass

def gpt_analyzer_node(state: RecoveryState) -> dict:
    # ... (Phase 1.2)
    pass

def gemini_validator_node(state: RecoveryState) -> dict:
    # ... (Phase 2.1)
    pass

def save_selector_node(state: RecoveryState) -> dict:
    # ... (Phase 4.1)
    pass

def re_crawl_node(state: RecoveryState) -> dict:
    # ... (Phase 4.2)
    pass

def retry_node(state: RecoveryState) -> dict:
    # ... (Phase 3.2)
    pass

def human_intervention_node(state: RecoveryState) -> dict:
    # ... (Phase 5.1)
    pass

# Conditional Edges
def route_after_consensus(state: RecoveryState) -> Literal["save_selector", "retry", "human_intervention"]:
    # ... (Phase 3.1)
    pass

# Graph ìƒì„±
def create_uc2_recovery_agent():
    """
    UC2 Recovery Agent Graph ìƒì„±
    
    Workflow:
    START â†’ fetch_raw_html â†’ gpt_analyzer â†’ gemini_validator â†’
      â†’ [consensus check] â†’
          â†’ save_selector â†’ re_crawl â†’ END  (í•©ì˜ ì„±ê³µ)
          â†’ retry â†’ gpt_analyzer (ì¬ì‹œë„)
          â†’ human_intervention â†’ END (HITL)
    """
    builder = StateGraph(RecoveryState)
    
    # Nodes ì¶”ê°€
    builder.add_node("fetch_raw_html", fetch_raw_html)
    builder.add_node("gpt_analyzer", gpt_analyzer_node)
    builder.add_node("gemini_validator", gemini_validator_node)
    builder.add_node("save_selector", save_selector_node)
    builder.add_node("re_crawl", re_crawl_node)
    builder.add_node("retry", retry_node)
    builder.add_node("human_intervention", human_intervention_node)
    
    # Edges
    builder.add_edge(START, "fetch_raw_html")
    builder.add_edge("fetch_raw_html", "gpt_analyzer")
    builder.add_edge("gpt_analyzer", "gemini_validator")
    
    # Conditional Edge (í•©ì˜ ì²´í¬)
    builder.add_conditional_edges(
        "gemini_validator",
        route_after_consensus,
        {
            "save_selector": "save_selector",
            "retry": "retry",
            "human_intervention": "human_intervention"
        }
    )
    
    # ì¬ì‹œë„ â†’ GPT ì¬ë¶„ì„
    builder.add_edge("retry", "gpt_analyzer")
    
    # ì €ì¥ í›„ ì¬í¬ë¡¤ë§
    builder.add_edge("save_selector", "re_crawl")
    builder.add_edge("re_crawl", END)
    
    # HITL â†’ ì¢…ë£Œ
    builder.add_edge("human_intervention", END)
    
    return builder.compile()

# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    graph = create_uc2_recovery_agent()
    
    # UC1ì—ì„œ ì‹¤íŒ¨í•œ ê²½ìš°ë¥¼ ì‹œë®¬ë ˆì´ì…˜
    test_input = {
        "url": "https://www.yna.co.kr/view/AKR20251103...",
        "site_name": "yonhap",
        "title": None,  # UC1 ì‹¤íŒ¨
        "body": None,
        "date": None,
        "quality_score": 0,
        "missing_fields": ["title", "body", "date"],
        "raw_html": "",
        "gpt_candidates": [],
        "gemini_validation": {},
        "consensus_reached": False,
        "retry_count": 0,
        "max_retries": 3,
        "selected_selector": None,
        "error_log": []
    }
    
    result = graph.invoke(test_input)
    print(result)
```

---

## HITL ì˜ì‚¬ê²°ì • í¬ì¸íŠ¸ ìš”ì•½

| # | ì¹´í…Œê³ ë¦¬ | ì§ˆë¬¸ | ê¶Œì¥ ê²°ì • | ê·¼ê±° |
|---|----------|------|-----------|------|
| **1** | State ì„¤ê³„ | raw_html ì €ì¥ ë°©ì‹? | Stateì— í¬í•¨ (ì˜µì…˜ A) | PoC ë‹¨ê³„, ê°„ë‹¨í•œ êµ¬í˜„, HTML í¬ê¸° ê²€ì¦ë¨ |
| **2** | GPT Analyzer | HTML ì „ì²˜ë¦¬? | ì£¼ìš” íƒœê·¸ë§Œ ì¶”ì¶œ (ì˜µì…˜ B) | í† í° ì ˆê° (50-80%), ë¹„ìš© íš¨ìœ¨ |
| **3** | GPT Analyzer | Selector í›„ë³´ ê°œìˆ˜? | 3ê°œ (ì˜µì…˜ B) | PRD ì¤€ìˆ˜, ì‹¤íŒ¨ìœ¨ 2.7% |
| **4** | GPT Analyzer | GPT ëª¨ë¸? | gpt-4o (ì˜µì…˜ A) | ì •í™•ë„ ìš°ì„ , ê³ ë‚œì´ë„ ì‘ì—… |
| **5** | Gemini Validator | ê²€ì¦ ë°©ì‹? | ìƒ˜í”Œ ì¶”ì¶œ ê²€ì¦ (ì˜µì…˜ A) | PRD ì¤€ìˆ˜, ë¹„ìš©/ì‹œê°„ íš¨ìœ¨ |
| **6** | Gemini Validator | ê²€ì¦ ì‹¤íŒ¨ ê¸°ì¤€? | 80% + ê·œì¹™ ê¸°ë°˜ (ì˜µì…˜ A+C) | ì •ëŸ‰+ì •ì„± ì¡°í•©, False positive ë°©ì§€ |
| **7** | Gemini Validator | Gemini ëª¨ë¸? | gemini-2.0-flash-exp (ì˜µì…˜ A) | PRD ì¤€ìˆ˜, ë¬´ë£Œ, ê²€ì¦ ì‘ì—… ì í•© |
| **8** | Consensus Logic | í•©ì˜ ì¡°ê±´? | ìˆœì°¨ ê²€ì¦ (ì˜µì…˜ B) | íš¨ìœ¨ì , GPT confidence í™œìš© |
| **9** | ì¬ì‹œë„ | ì¬ì‹œë„ ê°œì„ ? | ì‹¤íŒ¨ ì´ìœ  ì¶”ê°€ (ì˜µì…˜ B) | í•™ìŠµ íš¨ê³¼, ì„±ê³µë¥  ì¦ê°€ |
| **10** | DB ì—…ë°ì´íŠ¸ | ì´ì „ ë²„ì „ ë³´ê´€? | ë®ì–´ì“°ê¸° + logs (ì˜µì…˜ A) | PoC ë‹¨ê³„, decision_logsë¡œ ë³µêµ¬ ê°€ëŠ¥ |
| **11** | ì¬í¬ë¡¤ë§ | UC1 ìë™ ì¬ì‹¤í–‰? | ìë™ ì¬ì‹¤í–‰ (ì˜µì…˜ A) | Self-Healing ëª©í‘œ, UC1 ê²€ì¦ìœ¼ë¡œ ì•ˆì „ |
| **12** | HITL Interface | UI êµ¬í˜„ ë°©ë²•? | Gradio íƒ­ ì¶”ê°€ (ì˜µì…˜ A) | PoC ë°ëª¨ìš©, ê¸°ì¡´ UI í™•ì¥ |

**ì˜ì‚¬ê²°ì • ì² í•™**:
- PoC ë‹¨ê³„: ê°„ë‹¨í•œ êµ¬í˜„ ìš°ì„  (ë³µì¡ë„ ìµœì†Œí™”)
- PRD ì¤€ìˆ˜: ëª…ì‹œëœ ìš”êµ¬ì‚¬í•­ ë”°ë¥´ê¸°
- ì ì§„ì  ê°œì„ : Productionì—ì„œ ê³ ë„í™” ê°€ëŠ¥í•˜ë„ë¡ ì„¤ê³„
- ë¹„ìš© íš¨ìœ¨: ë¬´ë£Œ/ì €ë ´í•œ ì˜µì…˜ ìš°ì„  (ì„±ëŠ¥ ì €í•˜ ì—†ëŠ” ë²”ìœ„)

---

## êµ¬í˜„ ìˆœì„œ ë° íƒ€ì„ë¼ì¸

### Day 1: Phase 1 + Phase 2 (6-7ì‹œê°„)

**ì˜¤ì „ (3-4ì‹œê°„)**:
- âœ… Phase 1.1: State ì •ì˜ (30ë¶„)
- âœ… Phase 1.2: HTML ì „ì²˜ë¦¬ ìœ í‹¸ ì‘ì„± (30ë¶„)
- âœ… Phase 1.2: GPT-4o Analyzer êµ¬í˜„ (2ì‹œê°„)
- âœ… Phase 1.2: ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (30ë¶„)

**ì˜¤í›„ (3ì‹œê°„)**:
- âœ… Phase 2.1: Gemini Validator ë¡œì§ ì„¤ê³„ (1ì‹œê°„)
- âœ… Phase 2.1: Gemini Validator êµ¬í˜„ (1.5ì‹œê°„)
- âœ… Phase 2.1: ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (30ë¶„)

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] `tests/test_gpt_analyzer.py` í†µê³¼
- [ ] `tests/test_gemini_validator.py` í†µê³¼
- [ ] ì—°í•©ë‰´ìŠ¤ HTMLë¡œ Selector 3ê°œ ìƒì„± í™•ì¸
- [ ] 3ê°œ ì¤‘ 1ê°œ ì´ìƒ Gemini ê²€ì¦ í†µê³¼

---

### Day 2: Phase 3 + Phase 4 (3-4ì‹œê°„)

**ì˜¤ì „ (2ì‹œê°„)**:
- âœ… Phase 3.1: Consensus Logic êµ¬í˜„ (1ì‹œê°„)
- âœ… Phase 3.2: ì¬ì‹œë„ ë¡œì§ êµ¬í˜„ (1ì‹œê°„)

**ì˜¤í›„ (2ì‹œê°„)**:
- âœ… Phase 4.1: DB ì—…ë°ì´íŠ¸ Node êµ¬í˜„ (30ë¶„)
- âœ… Phase 4.2: ì¬í¬ë¡¤ë§ Node êµ¬í˜„ (30ë¶„)
- âœ… Phase 6: StateGraph í†µí•© (1ì‹œê°„)

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] `src/workflow/uc2_recovery.py` ì™„ì„±
- [ ] Graph ì»´íŒŒì¼ ì„±ê³µ
- [ ] í…ŒìŠ¤íŠ¸ ì…ë ¥ìœ¼ë¡œ End-to-End ì‹¤í–‰ (dry-run)

---

### Day 3: Phase 5 + í†µí•© í…ŒìŠ¤íŠ¸ (3-4ì‹œê°„)

**ì˜¤ì „ (2ì‹œê°„)**:
- âœ… Phase 5.1: HITL Node êµ¬í˜„ (30ë¶„)
- âœ… Phase 5.2: Gradio UI í™•ì¥ (1.5ì‹œê°„)

**ì˜¤í›„ (2ì‹œê°„)**:
- âœ… End-to-End í…ŒìŠ¤íŠ¸ (3ê°œ ì‚¬ì´íŠ¸)
- âœ… HITL ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
- âœ… ë¬¸ì„œ ì—…ë°ì´íŠ¸ (README, ì½”ë©˜íŠ¸)

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] ì—°í•©ë‰´ìŠ¤ Selector ê³ ì˜ ì†ìƒ â†’ UC2 ë³µêµ¬ ì„±ê³µ
- [ ] ë„¤ì´ë²„ UC2 í…ŒìŠ¤íŠ¸ ì„±ê³µ
- [ ] BBC UC2 í…ŒìŠ¤íŠ¸ ì„±ê³µ
- [ ] HITL UIì—ì„œ ìˆ˜ë™ ìŠ¹ì¸ ì„±ê³µ
- [ ] decision_logs í…Œì´ë¸”ì— ë°ì´í„° ì €ì¥ í™•ì¸

---

## í…ŒìŠ¤íŠ¸ ì „ëµ

### í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì¤€ë¹„

**ğŸ¤” HITL ì˜ì‚¬ê²°ì • í¬ì¸íŠ¸ #13: í…ŒìŠ¤íŠ¸ ì‚¬ì´íŠ¸ ì„ íƒ**

**ì§ˆë¬¸**: ì–´ë–¤ ì‚¬ì´íŠ¸ë¡œ UC2ë¥¼ í…ŒìŠ¤íŠ¸?

**ì˜µì…˜ A: ì—°í•©ë‰´ìŠ¤ (ê¸°ì¡´ Selector ê³ ì˜ ì†ìƒ)**
- ì¥ì : ì •ë‹µ Selector ì•Œê³  ìˆìŒ, ë¹„êµ ê°€ëŠ¥
- ë‹¨ì : ì‹¤ì œ DOM ë³€ê²½ ì‹œë®¬ë ˆì´ì…˜ ì•„ë‹˜

**ì˜µì…˜ B: ìƒˆë¡œìš´ ì‚¬ì´íŠ¸ (ì¡°ì„ ì¼ë³´, ì¤‘ì•™ì¼ë³´)**
- ì¥ì : ì‹¤ì œ UC3 ì‹œë‚˜ë¦¬ì˜¤
- ë‹¨ì : ì •ë‹µ ì—†ìŒ, ê²€ì¦ ì–´ë ¤ì›€

**ê¶Œì¥ ê²°ì •**: **ì˜µì…˜ A (ê³ ì˜ ì†ìƒ) + ì˜µì…˜ B (ì‹ ê·œ ì‚¬ì´íŠ¸) ì¡°í•©**
- ê·¼ê±°:
  - ì˜µì…˜ A: UC2 ì •í™•ë„ ê²€ì¦
  - ì˜µì…˜ B: UC3 (ì‹ ê·œ ì‚¬ì´íŠ¸) ê²€ì¦
  - 2ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤ ëª¨ë‘ ì¤‘ìš”

### Test Case 1: ì—°í•©ë‰´ìŠ¤ Selector ì†ìƒ

**ì‹œë‚˜ë¦¬ì˜¤**: ê¸°ì¡´ Selectorë¥¼ ê³ ì˜ë¡œ ë§ê°€ëœ¨ë¦¬ê³  UC2ë¡œ ë³µêµ¬

```python
# tests/test_uc2_integration.py

def test_uc2_yonhap_recovery():
    """
    UC2 í†µí•© í…ŒìŠ¤íŠ¸: ì—°í•©ë‰´ìŠ¤ Selector ë³µêµ¬
    """
    from src.storage.database import get_db
    from src.storage.models import Selector
    from src.workflow.uc2_recovery import create_uc2_recovery_agent
    
    # 1. ê¸°ì¡´ Selector ë°±ì—…
    db = next(get_db())
    selector = db.query(Selector).filter_by(site_name="yonhap").first()
    original_title = selector.title_selector
    original_body = selector.body_selector
    original_date = selector.date_selector
    
    # 2. Selector ê³ ì˜ ì†ìƒ
    selector.title_selector = "h1.wrong-class"
    selector.body_selector = "div.nonexistent"
    selector.date_selector = "time.invalid"
    db.commit()
    db.close()
    
    # 3. UC2 ì‹¤í–‰
    graph = create_uc2_recovery_agent()
    
    test_url = "https://www.yna.co.kr/view/AKR20251103095752073"
    result = graph.invoke({
        "url": test_url,
        "site_name": "yonhap",
        "title": None,
        "body": None,
        "date": None,
        "quality_score": 0,
        "missing_fields": ["title", "body", "date"],
        "raw_html": "",
        "retry_count": 0,
        "max_retries": 3
    })
    
    # 4. ê²€ì¦
    assert result["consensus_reached"] == True
    assert result["selected_selector"] is not None
    
    # 5. DB í™•ì¸
    db = next(get_db())
    updated_selector = db.query(Selector).filter_by(site_name="yonhap").first()
    
    # ìƒˆ Selectorê°€ ì›ë³¸ê³¼ ìœ ì‚¬í•œì§€ í™•ì¸ (ì™„ì „ ë™ì¼í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ)
    # GPTê°€ ë” ë‚˜ì€ Selectorë¥¼ ì œì•ˆí•  ìˆ˜ë„ ìˆìŒ
    assert updated_selector.title_selector != "h1.wrong-class"
    assert updated_selector.body_selector != "div.nonexistent"
    
    # 6. ë³µì› (í…ŒìŠ¤íŠ¸ í›„ ì›ìƒ ë³µêµ¬)
    selector.title_selector = original_title
    selector.body_selector = original_body
    selector.date_selector = original_date
    db.commit()
    db.close()
```

### Test Case 2: ì‹ ê·œ ì‚¬ì´íŠ¸ (UC3)

```python
def test_uc3_new_site():
    """
    UC3 í†µí•© í…ŒìŠ¤íŠ¸: ì‹ ê·œ ì‚¬ì´íŠ¸ Selector ìƒì„±
    """
    # ì¡°ì„ ì¼ë³´ ë˜ëŠ” ì¤‘ì•™ì¼ë³´
    test_url = "https://www.chosun.com/politics/2025/11/03/..."
    
    graph = create_uc2_recovery_agent()
    result = graph.invoke({
        "url": test_url,
        "site_name": "chosun",  # DBì— ì—†ëŠ” ì‚¬ì´íŠ¸
        "title": None,
        "body": None,
        "date": None,
        "quality_score": 0,
        "missing_fields": ["title", "body", "date"],
        "raw_html": "",
        "retry_count": 0,
        "max_retries": 3
    })
    
    # ê²€ì¦
    assert result["consensus_reached"] == True
    
    # DBì— ì‹ ê·œ Selector ìƒì„± í™•ì¸
    db = next(get_db())
    new_selector = db.query(Selector).filter_by(site_name="chosun").first()
    assert new_selector is not None
    db.close()
```

### Test Case 3: HITL ì‹œë‚˜ë¦¬ì˜¤

```python
def test_hitl_intervention():
    """
    HITL ì‹œë‚˜ë¦¬ì˜¤: ì¬ì‹œë„ 3íšŒ ì‹¤íŒ¨ í›„ ìˆ˜ë™ ê°œì…
    """
    # TODO: ê³ ì˜ë¡œ ì‹¤íŒ¨í•˜ëŠ” HTML ì¤€ë¹„
    # (ì˜ˆ: JavaScript ë Œë”ë§ í•„ìˆ˜ SPA, ë¹„ì •í˜• êµ¬ì¡°)
    
    graph = create_uc2_recovery_agent()
    result = graph.invoke({
        "url": "https://example.com/spa-article",
        "site_name": "example_spa",
        "title": None,
        "body": None,
        "date": None,
        "quality_score": 0,
        "missing_fields": ["title", "body", "date"],
        "raw_html": "<html>...</html>",  # ë³µì¡í•œ HTML
        "retry_count": 0,
        "max_retries": 3
    })
    
    # ê²€ì¦
    assert result["consensus_reached"] == False
    assert result["retry_count"] >= 3
    assert "[HITL]" in result["error_log"][-1]
    
    # decision_logsì— pending ìƒíƒœ í™•ì¸
    db = next(get_db())
    log = db.query(DecisionLog).filter_by(
        url="https://example.com/spa-article",
        consensus_reached=False
    ).first()
    assert log is not None
    db.close()
```

---

## ë¦¬ìŠ¤í¬ ë° ëŒ€ì‘

### Risk 1: GPT-4o API ë¹„ìš© ì´ˆê³¼

**ì˜ˆìƒ ë¹„ìš©** (URLë‹¹):
- Input: ~5K tokens (ì¶•ì•½ HTML) Ã— $2.50 / 1M = $0.0125
- Output: ~500 tokens (3ê°œ í›„ë³´) Ã— $10.00 / 1M = $0.005
- **Total**: ~$0.02 / URL

**ì™„í™” ì „ëµ**:
- HTML ì „ì²˜ë¦¬ë¡œ í† í° 50% ì ˆê°
- ì¬ì‹œë„ ì‹œ ì´ì „ ì‹¤íŒ¨ ì´ìœ ë§Œ ì¶”ê°€ (ì „ì²´ HTML ì¬ì „ì†¡ ì•ˆ í•¨)
- Phase 5 í…ŒìŠ¤íŠ¸ì—ì„œ ë¹„ìš© ëª¨ë‹ˆí„°ë§

**ëŒ€ì‘ ê³„íš**:
- ë¹„ìš© ì´ˆê³¼ ì‹œ: gpt-4o-minië¡œ ì „í™˜ ($0.0006 / URL)
- Fallback: ê·œì¹™ ê¸°ë°˜ Selector ìƒì„± (heuristic)

---

### Risk 2: Gemini API ì¥ì• 

**ì¦ìƒ**:
- 429 Too Many Requests
- 503 Service Unavailable
- Timeout

**ì™„í™” ì „ëµ**:
- Exponential Backoff (Phase 3.2 êµ¬í˜„ë¨)
- ì¬ì‹œë„ 3íšŒ

**ëŒ€ì‘ ê³„íš**:
- Gemini ì¥ì•  ì‹œ: ê·œì¹™ ê¸°ë°˜ ê²€ì¦ìœ¼ë¡œ Fallback
- GPT confidence â‰¥ 0.8ì´ë©´ Gemini ì—†ì´ í†µê³¼
- HITLë¡œ escalate

---

### Risk 3: Selector ê²€ì¦ ì‹¤íŒ¨ìœ¨ ë†’ìŒ

**ì˜ˆìƒ ì‹¤íŒ¨ ì‹œë‚˜ë¦¬ì˜¤**:
- ë¹„ì •í˜• HTML êµ¬ì¡° (ì˜¤ë˜ëœ ì‚¬ì´íŠ¸)
- JavaScript ë Œë”ë§ í•„ìˆ˜ (SPA)
- ê´‘ê³ /íŒì—…ì´ ë³¸ë¬¸ìœ¼ë¡œ ì˜¤ì¸

**ì™„í™” ì „ëµ**:
- Gemini ê²€ì¦ ê¸°ì¤€ ì™„í™” (80% â†’ 70%)
- ìƒ˜í”Œ ê°œìˆ˜ ì¦ê°€ (10ê°œ â†’ 20ê°œ)
- GPT Prompt ê°œì„  (ì¬ì‹œë„ ì‹œ í”¼ë“œë°± ë°˜ì˜)

**ëŒ€ì‘ ê³„íš**:
- Phase 5 í…ŒìŠ¤íŠ¸ì—ì„œ ì‹¤íŒ¨ìœ¨ ì¸¡ì •
- ì‹¤íŒ¨ìœ¨ > 30%: Prompt ì¬ì‘ì„±
- ì‹¤íŒ¨ìœ¨ > 50%: HITL ìš°ì„  ì „í™˜

---

### Risk 4: GPT Hallucination (ì˜ëª»ëœ Selector ìƒì„±)

**ì¦ìƒ**:
- ì¡´ì¬í•˜ì§€ ì•ŠëŠ” CSS í´ë˜ìŠ¤ ìƒì„±
- ê´‘ê³  ì˜ì—­ì„ ë³¸ë¬¸ìœ¼ë¡œ ì˜¤ì¸
- ë„ˆë¬´ ì·¨ì•½í•œ Selector (nth-child)

**ì™„í™” ì „ëµ**:
- Structured Output ê°•ì œ (Pydantic ìŠ¤í‚¤ë§ˆ)
- Gemini 2ì°¨ ê²€ì¦ (ìƒ˜í”Œ ì¶”ì¶œë¡œ ì‹¤ì œ í™•ì¸)
- GPT Promptì— "Bad Examples" ëª…ì‹œ

**ëŒ€ì‘ ê³„íš**:
- Hallucination ë°œê²¬ ì‹œ: decision_logsì— ê¸°ë¡
- í•´ë‹¹ ì‚¬ì´íŠ¸ HITL í”Œë˜ê·¸ ì„¤ì •
- GPT Prompt ê°œì„  (negative examples ì¶”ê°€)

---

## ë¶€ë¡: íŒŒì¼ êµ¬ì¡°

```
crawlagent/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ gpt_analyzer.py          # Phase 1.2 (NEW)
â”‚   â”‚   â””â”€â”€ gemini_validator.py      # Phase 2.1 (NEW)
â”‚   â”‚
â”‚   â”œâ”€â”€ workflow/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ uc1_validation.py        # ê¸°ì¡´
â”‚   â”‚   â””â”€â”€ uc2_recovery.py          # Phase 6 (NEW)
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ html_cleaner.py          # Phase 1.2 (NEW)
â”‚   â”‚
â”‚   â”œâ”€â”€ ui/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ app.py                   # Phase 5.2 (í™•ì¥)
â”‚   â”‚
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â”œâ”€â”€ models.py                # ê¸°ì¡´ (ë³€ê²½ ì—†ìŒ)
â”‚   â”‚   â””â”€â”€ database.py              # ê¸°ì¡´ (ë³€ê²½ ì—†ìŒ)
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_gpt_analyzer.py         # Phase 1.2 (NEW)
â”‚   â”œâ”€â”€ test_gemini_validator.py     # Phase 2.1 (NEW)
â”‚   â”œâ”€â”€ test_uc2_integration.py      # Phase 7 (NEW)
â”‚   â””â”€â”€ fixtures/
â”‚       â”œâ”€â”€ yonhap_sample.html       # í…ŒìŠ¤íŠ¸ìš©
â”‚       â”œâ”€â”€ naver_sample.html
â”‚       â””â”€â”€ bbc_sample.html
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ crawlagent/
â”‚       â””â”€â”€ UC2-DEVELOPMENT-MASTERPLAN.md  # ì´ ë¬¸ì„œ
â”‚
â””â”€â”€ .env
    # OPENAI_API_KEY=sk-...
    # GOOGLE_API_KEY=...
```

---

## ë‹¤ìŒ ë‹¨ê³„

**Phase 1 êµ¬í˜„ ì‹œì‘ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸**:
- [ ] ëª¨ë“  HITL ì˜ì‚¬ê²°ì • í¬ì¸íŠ¸ ê²€í†  ì™„ë£Œ
- [ ] API í‚¤ ì¤€ë¹„ (OpenAI, Google Gemini)
- [ ] í…ŒìŠ¤íŠ¸ HTML íŒŒì¼ ì¤€ë¹„ (3ê°œ ì‚¬ì´íŠ¸)
- [ ] `src/workflow/uc2_recovery.py` íŒŒì¼ ìƒì„±
- [ ] `src/agents/` ë””ë ‰í† ë¦¬ í™•ì¸
- [ ] PostgreSQL ì—°ê²° í™•ì¸ (decision_logs í…Œì´ë¸” ì¡´ì¬)

**Phase 1 ì‹œì‘ ëª…ë ¹**:
```bash
cd /Users/charlee/Desktop/Intern/crawlagent

# 1. í…ŒìŠ¤íŠ¸ HTML ë‹¤ìš´ë¡œë“œ
curl https://www.yna.co.kr/view/AKR20251028095752073 > tests/fixtures/yonhap_sample.html

# 2. HTML ì „ì²˜ë¦¬ ìœ í‹¸ ì‘ì„±
touch src/utils/html_cleaner.py

# 3. GPT Analyzer ì‘ì„±
touch src/agents/gpt_analyzer.py

# 4. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
touch tests/test_gpt_analyzer.py

# 5. í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest tests/test_gpt_analyzer.py -v
```

**ì„±ê³µ ê¸°ì¤€**:
- [ ] GPT-4oë¡œ ì—°í•©ë‰´ìŠ¤ HTML ë¶„ì„ ì„±ê³µ (3ê°œ í›„ë³´ ìƒì„±)
- [ ] Geminië¡œ í›„ë³´ ê²€ì¦ ì„±ê³µ (1ê°œ ì´ìƒ í†µê³¼)
- [ ] End-to-End í…ŒìŠ¤íŠ¸ í†µê³¼ (ì—°í•©ë‰´ìŠ¤ Selector ë³µêµ¬)
- [ ] HITL UIì—ì„œ ìˆ˜ë™ ê²€í†  ê°€ëŠ¥
- [ ] decision_logs í…Œì´ë¸”ì— ë°ì´í„° ì €ì¥ í™•ì¸

---

**ë¬¸ì„œ ë²„ì „**: 1.0
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025-11-03
**ë‹¤ìŒ ê²€í† **: Phase 1 ì™„ë£Œ í›„ ì‹¤ì œ êµ¬í˜„ ê²°ê³¼ ë°˜ì˜

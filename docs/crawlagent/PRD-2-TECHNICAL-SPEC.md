# CrawlAgent PoC - PRD Part 2: Technical Specification

**ì‘ì„±ì¼**: 2025-10-28
**ë²„ì „**: 1.0 (PostgreSQL ê¸°ë°˜)
**ìƒíƒœ**: ì´í•´ê´€ê³„ì ê²€í†  ëŒ€ê¸°

---

## ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ (Technology Stack)

### ê²€ì¦ëœ ê¸°ìˆ ë§Œ ì‚¬ìš© (No Experimental Tech)

| ë ˆì´ì–´ | ê¸°ìˆ  | ë²„ì „ | ê²€ì¦ ìƒíƒœ | ì„ íƒ ê·¼ê±° |
|--------|------|------|-----------|-----------|
| **í¬ë¡¤ë§** | Scrapy | 2.13.3 | âœ… 2008ë…„ë¶€í„° ì‚¬ìš©, GitHub 56K+ stars | ë‹¨ì¼ í”„ë ˆì„ì›Œí¬ (3ê°œ ì‚¬ì´íŠ¸ ëª¨ë‘ SSR) |
| **ë°ì´í„°ë² ì´ìŠ¤** | PostgreSQL | 16 | âœ… 1996ë…„ë¶€í„° ì‚¬ìš©, ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ | MVCC, JSONB, í™•ì¥ì„± |
| **ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜** | LangGraph | 0.2+ | âœ… LangChain ê³µì‹ í”„ë¡œì íŠ¸ | ì¡°ê±´ë¶€ ë¼ìš°íŒ…, State ê´€ë¦¬ |
| **LLM (Analyzer)** | GPT-4o | 2024-08-06 | âœ… OpenAI ê³µì‹ API | Structured Output ì§€ì› |
| **LLM (Validator)** | Gemini 2.5 Flash | 2025-01 | âœ… Google ê³µì‹ API | ì €ë¹„ìš©, ë¹ ë¥¸ ê²€ì¦ |
| **í™˜ê²½** | Docker Compose | 2.24+ | âœ… 2013ë…„ë¶€í„° ì‚¬ìš© | ë¡œì»¬ PostgreSQL í™˜ê²½ |

**ê·¼ê±°**:
- Scrapy ê³µì‹ ë¬¸ì„œ (2024): [https://docs.scrapy.org/en/latest/intro/overview.html](https://docs.scrapy.org/en/latest/intro/overview.html)
- PostgreSQL 16 Release Notes: [https://www.postgresql.org/docs/16/release-16.html](https://www.postgresql.org/docs/16/release-16.html)
- **ê¸°ìˆ  ìŠ¤íƒ ë‹¨ìˆœí™” ê²°ì •ì„œ**: [00-TECH-STACK-DECISION.md](./00-TECH-STACK-DECISION.md)

**2025-10-29 ì—…ë°ì´íŠ¸**:
- âŒ **ì œê±°**: scrapy-playwright (ì‹ ë¢°ì„± 25%, BBC News SSR í™•ì¸ìœ¼ë¡œ ë¶ˆí•„ìš”)
- âœ… **ìµœì¢… ê²°ì •**: Scrapy ë‹¨ì¼ í”„ë ˆì„ì›Œí¬ (ë³µì¡ë„ 40% ê°ì†Œ)

---

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ (System Architecture)

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  LangGraph Orchestrator                   â”‚
â”‚         (Conditional Routing + State Management)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”‚  Start: Load Selector from PostgreSQL
            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  PostgreSQL    â”‚
    â”‚  (selectors)   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”‚  CSS Selectors
            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         UC1: Scrapy Crawl (90%)                â”‚
    â”‚  - 3ê°œ ì‚¬ì´íŠ¸ ëª¨ë‘ SSR (ë‹¨ì¼ í”„ë ˆì„ì›Œí¬)       â”‚
    â”‚  - ì—°í•©ë‰´ìŠ¤, ë„¤ì´ë²„, BBC (requestsë§Œ ì‚¬ìš©)     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
       â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
       â”‚ Success?â”‚
       â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
             â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
      â”‚             â”‚
   Yesâ”‚            â”‚No (UC2: 5-10%)
      â”‚             â”‚
      â”‚      â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚      â”‚  2-Agent Activation  â”‚
      â”‚      â”‚  1. GPT-4o Analyzer  â”‚
      â”‚      â”‚  2. Gemini Validator â”‚
      â”‚      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚             â”‚
      â”‚      â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚      â”‚  New Selectors â”‚
      â”‚      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚             â”‚
      â”‚      â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
      â”‚      â”‚ Re-crawl     â”‚
      â”‚      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚             â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                     â”‚
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚  PostgreSQL Storage    â”‚
                         â”‚  - crawl_results       â”‚
                         â”‚  - selectors (updated) â”‚
                         â”‚  - decision_logs       â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ 3ê°€ì§€ ìœ ìŠ¤ì¼€ì´ìŠ¤ (Use Cases)

### UC1: ì •ìƒ í¬ë¡¤ë§ (Normal Crawling) - 90%

**íë¦„**:
1. PostgreSQLì—ì„œ ì‚¬ì´íŠ¸ë³„ CSS Selector ì¡°íšŒ
2. Scrapyë¡œ HTML ìš”ì²­
   - ëª¨ë“  ì‚¬ì´íŠ¸ SSR: `scrapy.Request(url)` (ì—°í•©ë‰´ìŠ¤, ë„¤ì´ë²„, BBC News)
3. **Trafilaturaë¡œ ë©”ì¸ ì½˜í…ì¸  ì¶”ì¶œ** (ê´‘ê³  ìë™ ì œê±°)
4. CSS Selectorë¡œ title, date ì¶”ì¶œ
5. í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (â‰¥80ì )
6. PostgreSQL `crawl_results` í…Œì´ë¸”ì— ì €ì¥

**í’ˆì§ˆ ê°œì„  (2025-10-30)**:
- **Trafilatura ë¼ì´ë¸ŒëŸ¬ë¦¬** ì ìš© (Apache 2.0)
- **F1-Score 93.7%** (2024 í‰ê°€ 1ìœ„)
- **ê´‘ê³  í…ìŠ¤íŠ¸ ìë™ ì œê±°**, HTML íƒœê·¸ ì •ì œ
- **ê·¼ê±°**: "Evaluation of Main Content Extraction Libraries" (Sandia National Lab 2024)

**ì†Œìš”ì‹œê°„**: 3-8ì´ˆ
**ë¹„ìš©**: $0 (LLM ë¯¸ì‚¬ìš©)

**ê·¼ê±°**:
- Scrapy ê³µì‹ ë¬¸ì„œ: í‰ê·  ì‘ë‹µ ì‹œê°„ 1-5ì´ˆ
- 3ê°œ ì‚¬ì´íŠ¸ ëª¨ë‘ SSR ê²€ì¦ ì™„ë£Œ (2025-10-29)
- Trafilatura GitHub: [https://github.com/adbar/trafilatura](https://github.com/adbar/trafilatura)

---

### UC2: DOM ë³€ê²½ ë³µêµ¬ (Recovery) - 5-10%

**íŠ¸ë¦¬ê±°**: Scrapy ì‹¤íŒ¨ ê°ì§€
- `title=None` OR `body=None` OR `len(body) < 100`

**íë¦„**:
1. Scrapy ì‹¤íŒ¨ ê°ì§€ â†’ LangGraph ì¡°ê±´ë¶€ ë¼ìš°íŒ…
2. Scrapyë¡œ ì „ì²´ HTML ì¬ìˆ˜ì§‘
3. **GPT-4o Analyzer** í™œì„±í™”:
   ```json
   {
     "role": "system",
     "content": "ë‹¹ì‹ ì€ HTML êµ¬ì¡° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ HTMLì—ì„œ ë‰´ìŠ¤ ê¸°ì‚¬ì˜ title, body, dateë¥¼ ì¶”ì¶œí•  CSS Selectorë¥¼ ìƒì„±í•˜ì„¸ìš”."
   }
   ```
   - Structured Outputìœ¼ë¡œ `{title_sel, body_sel, date_sel}` ë°˜í™˜
4. **Gemini 2.5 Flash Validator** ê²€ì¦:
   - GPTê°€ ì œì•ˆí•œ Selectorë¡œ 10ê°œ ìƒ˜í”Œ ì¶”ì¶œ
   - í•œêµ­ì–´/ì˜ë¬¸ ë‰´ìŠ¤ íŒ¨í„´ ê²€ì¦
   - `{valid: true/false, samples: [...]}` ë°˜í™˜
5. í•©ì˜ ì²´í¬:
   - GPT confidence â‰¥ 0.7 AND Gemini valid=true â†’ í•©ì˜ ì„±ê³µ
   - ë¶ˆì¼ì¹˜ ì‹œ ìµœëŒ€ 3íšŒ ì¬ì‹œë„
6. ìƒˆ Selectorë¡œ Scrapy ì¬í¬ë¡¤ë§
7. PostgreSQL ì—…ë°ì´íŠ¸:
   - `selectors` í…Œì´ë¸”: ìƒˆ Selector ì €ì¥
   - `decision_logs` í…Œì´ë¸”: GPT/Gemini reasoning ì €ì¥ (JSONB)

**ì†Œìš”ì‹œê°„**: 30-60ì´ˆ
**ë¹„ìš©**: ~$0.02 per article

---

### UC3: ì‹ ê·œ ì‚¬ì´íŠ¸ ì¶”ê°€ (New Site) - 5%

**íŠ¸ë¦¬ê±°**: PostgreSQLì— í•´ë‹¹ ì‚¬ì´íŠ¸ Selector ì—†ìŒ

**íë¦„**:
1. Selector ì¡°íšŒ ì‹¤íŒ¨ ê°ì§€
2. ì¦‰ì‹œ UC2 íë¦„ ì‹¤í–‰ (ì²˜ìŒë¶€í„° 2-Agent í™œì„±í™”)
3. ì²« í¬ë¡¤ë§ë¶€í„° AI ë¶„ì„ â†’ Selector ìƒì„±
4. PostgreSQLì— ì‹ ê·œ ì‚¬ì´íŠ¸ Selector ì €ì¥

**ì†Œìš”ì‹œê°„**: 30-60ì´ˆ
**ë¹„ìš©**: ~$0.02 per article

---

## ğŸ—„ï¸ PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ (Database Schema)

### Table 1: `selectors`

| Column | Type | Description | Example |
|--------|------|-------------|---------|
| `id` | SERIAL PRIMARY KEY | ê³ ìœ  ID | 1 |
| `site_name` | VARCHAR(100) UNIQUE | ì‚¬ì´íŠ¸ ì‹ë³„ì | 'yonhap' |
| `title_selector` | TEXT | Title CSS Selector | 'article h1.tit' |
| `body_selector` | TEXT | Body CSS Selector | 'article div.article-txt' |
| `date_selector` | TEXT | Date CSS Selector | 'article time' |
| `site_type` | VARCHAR(20) | 'ssr' or 'spa' | 'ssr' |
| `created_at` | TIMESTAMP | ìƒì„±ì¼ | '2025-10-28 10:00:00' |
| `updated_at` | TIMESTAMP | ìµœì¢… ìˆ˜ì •ì¼ | '2025-10-28 10:00:00' |
| `success_count` | INTEGER | ì„±ê³µ íšŸìˆ˜ | 150 |
| `failure_count` | INTEGER | ì‹¤íŒ¨ íšŸìˆ˜ | 2 |

**ì¸ë±ìŠ¤**:
```sql
CREATE INDEX idx_site_name ON selectors(site_name);
```

---

### Table 2: `crawl_results`

| Column | Type | Description | Example |
|--------|------|-------------|---------|
| `id` | SERIAL PRIMARY KEY | ê³ ìœ  ID | 1 |
| `url` | TEXT UNIQUE | ê¸°ì‚¬ URL | 'https://...' |
| `site_name` | VARCHAR(100) | ì‚¬ì´íŠ¸ ì‹ë³„ì | 'yonhap' |
| `title` | TEXT | ì¶”ì¶œëœ ì œëª© | 'ë¶í•œ ê¹€ì •ì€...' |
| `body` | TEXT | ì¶”ì¶œëœ ë³¸ë¬¸ | '...' |
| `date` | TEXT | ì¶”ì¶œëœ ë‚ ì§œ | '2025-10-28' |
| `quality_score` | INTEGER | í’ˆì§ˆ ì ìˆ˜ (0-100) | 92 |
| `crawl_mode` | VARCHAR(20) | 'scrapy' or '2-agent' | 'scrapy' |
| `crawl_duration_seconds` | FLOAT | í¬ë¡¤ë§ ì†Œìš”ì‹œê°„ | 8.5 |
| `created_at` | TIMESTAMP | ìˆ˜ì§‘ì¼ | '2025-10-28 10:00:00' |

**ì¸ë±ìŠ¤**:
```sql
CREATE INDEX idx_site_name ON crawl_results(site_name);
CREATE INDEX idx_quality_score ON crawl_results(quality_score);
CREATE INDEX idx_crawl_mode ON crawl_results(crawl_mode);
```

---

### Table 3: `decision_logs`

| Column | Type | Description | Example |
|--------|------|-------------|---------|
| `id` | SERIAL PRIMARY KEY | ê³ ìœ  ID | 1 |
| `url` | TEXT | ê¸°ì‚¬ URL | 'https://...' |
| `site_name` | VARCHAR(100) | ì‚¬ì´íŠ¸ ì‹ë³„ì | 'naver_economy' |
| `gpt_analysis` | JSONB | GPT ë¶„ì„ ê²°ê³¼ | `{"selectors": {...}, "reasoning": "..."}` |
| `gemini_validation` | JSONB | Gemini ê²€ì¦ ê²°ê³¼ | `{"valid": true, "samples": [...]}` |
| `consensus_reached` | BOOLEAN | í•©ì˜ ì„±ê³µ ì—¬ë¶€ | true |
| `retry_count` | INTEGER | ì¬ì‹œë„ íšŸìˆ˜ | 0 |
| `created_at` | TIMESTAMP | ìƒì„±ì¼ | '2025-10-28 11:00:00' |

**JSONB ì¸ë±ìŠ¤**:
```sql
CREATE INDEX idx_gpt_analysis ON decision_logs USING GIN (gpt_analysis);
CREATE INDEX idx_gemini_validation ON decision_logs USING GIN (gemini_validation);
```

**ê·¼ê±°**: PostgreSQL JSONBëŠ” GIN ì¸ë±ìŠ¤ë¥¼ í†µí•´ JSON í•„ë“œ ì¿¼ë¦¬ ì„±ëŠ¥ ìµœì í™” ê°€ëŠ¥ ([Docs](https://www.postgresql.org/docs/16/datatype-json.html#JSON-INDEXING))

---

## ğŸ§® í’ˆì§ˆ í‰ê°€ ì•Œê³ ë¦¬ì¦˜ (Quality Scoring)

### 5W1H ì €ë„ë¦¬ì¦˜ ì›ì¹™ ê¸°ë°˜

**ê°€ì¤‘ì¹˜**:
| í•„ë“œ | ê°€ì¤‘ì¹˜ | ê·¼ê±° |
|------|--------|------|
| Title | 25% | What ë‹µë³€, ì§§ì•„ì„œ ì•ˆì •ì  ì¶”ì¶œ |
| Body | 50% | Who/Why/How ë‹µë³€, ë³µì¡í•œ DOM êµ¬ì¡° |
| Date | 15% | When ë‹µë³€, í‘œì¤€ í˜•ì‹ ì¡´ì¬ |
| URL | 10% | ì¶œì²˜ ê²€ì¦, ì¤‘ë³µ ì œê±° |

**ê³„ì‚° ë¡œì§**:
```python
def calculate_quality_score(data: dict) -> int:
    score = 0

    # Title (25ì )
    if data.get("title") and len(data["title"]) >= 10:
        score += 25

    # Body (50ì )
    if data.get("body"):
        body_len = len(data["body"])
        if body_len >= 500:
            score += 50
        elif body_len >= 200:
            score += 40
        elif body_len >= 100:
            score += 30

    # Date (15ì )
    if data.get("date"):
        # ë‚ ì§œ í˜•ì‹ ê²€ì¦ (ê°„ë‹¨í•œ ìˆ«ì í¬í•¨ ì²´í¬)
        if any(char.isdigit() for char in data["date"]):
            score += 15

    # URL (10ì )
    if data.get("url") and data["url"].startswith("http"):
        score += 10

    return score
```

**ì„ê³„ê°’**:
- **í†µê³¼**: â‰¥80ì  (Title + Body + Date í•„ìˆ˜)
- **ì‹¤íŒ¨**: <80ì  (ì¬ì‹œë„ ë˜ëŠ” íê¸°)

**ê·¼ê±°**: "The Inverted Pyramid Style in Journalism" (Sage Journals, 2022) - 5W1H ì›ì¹™

---

## ğŸ”§ í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ (Core Algorithms)

### 1. Scrapy ì‹¤íŒ¨ ê°ì§€ ë¡œì§

```python
def check_scrapy_failure(data: dict) -> tuple[bool, str]:
    """
    Scrapy ì‹¤íŒ¨ ì—¬ë¶€ ë‹¤ì¸µ ê²€ì¦
    Returns: (is_failure, reason)
    """
    if not data:
        return True, "Empty data returned"

    if not data.get("title"):
        return True, "Title missing"

    if not data.get("body"):
        return True, "Body missing"

    if len(data.get("body", "")) < 100:
        return True, "Body too short (<100 chars)"

    return False, "Success"
```

---

### 2. 2-Agent í•©ì˜ ì²´í¬ ë¡œì§

```python
def check_agent_consensus(
    gpt_confidence: float,
    gemini_valid: bool,
    gemini_confidence: float
) -> tuple[bool, str]:
    """
    2-Agent í•©ì˜ ì—¬ë¶€ íŒë‹¨
    Returns: (consensus_reached, reason)
    """
    # 1. Gemini ëª…ì‹œì  ê±°ë¶€
    if not gemini_valid:
        return False, "Gemini rejected selectors"

    # 2. ë‘˜ ë‹¤ ë‚®ì€ ì‹ ë¢°ë„
    if gpt_confidence < 0.7 or gemini_confidence < 0.7:
        return False, f"Low confidence (GPT:{gpt_confidence}, Gemini:{gemini_confidence})"

    # 3. ëª¨ë“  ì¡°ê±´ í†µê³¼ â†’ í•©ì˜
    return True, "Consensus reached"
```

---

### 3. LangGraph ì¡°ê±´ë¶€ ë¼ìš°íŒ…

```python
def route_after_scrapy(state: dict) -> str:
    """Scrapy ê²°ê³¼ì— ë”°ë¥¸ ë¼ìš°íŒ…"""
    data = state.get("scrapy_data")
    is_failure, _ = check_scrapy_failure(data)

    if is_failure:
        return "activate_2_agent"  # UC2/UC3
    else:
        return "save_result"  # UC1
```

**ê·¼ê±°**: LangGraph Conditional Edges ê³µì‹ ë¬¸ì„œ ([Docs](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/#conditional-edges))

---

## ğŸ³ Docker Compose í™˜ê²½ ì„¤ì •

### `docker-compose.yml`

```yaml
version: '3.8'

services:
  postgres:
    image: postgres:16
    container_name: newsflow-postgres
    environment:
      POSTGRES_DB: newsflow_poc
      POSTGRES_USER: newsflow
      POSTGRES_PASSWORD: dev_password
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --locale=C"
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init_db.sql:/docker-entrypoint-initdb.d/init_db.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U newsflow -d newsflow_poc"]
      interval: 5s
      timeout: 5s
      retries: 5
    restart: unless-stopped

volumes:
  postgres_data:
    driver: local
```

**ì„¤ì¹˜ ì‹œê°„**: 30ë¶„ (Docker ì„¤ì¹˜ + ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ)

**ê·¼ê±°**: PostgreSQL ê³µì‹ Docker Hub ([https://hub.docker.com/_/postgres](https://hub.docker.com/_/postgres))

---

## ğŸ“¦ ëª¨ë“ˆ êµ¬ì¡° (Project Structure)

```
newsflow-poc/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                    # ì§„ì…ì 
â”‚   â”‚
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py              # í™˜ê²½ë³€ìˆ˜
â”‚   â”‚   â”œâ”€â”€ logging.py             # loguru ì„¤ì •
â”‚   â”‚   â””â”€â”€ state.py               # LangGraph State
â”‚   â”‚
â”‚   â”œâ”€â”€ crawlers/
â”‚   â”‚   â”œâ”€â”€ scrapy_spider.py       # Scrapy Spider
â”‚   â”‚   â””â”€â”€ playwright_middleware.py  # scrapy-playwright ì„¤ì •
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ gpt_analyzer.py        # GPT-4o
â”‚   â”‚   â””â”€â”€ gemini_validator.py    # Gemini 2.5
â”‚   â”‚
â”‚   â”œâ”€â”€ workflow/
â”‚   â”‚   â”œâ”€â”€ graph.py               # LangGraph ì •ì˜
â”‚   â”‚   â”œâ”€â”€ nodes.py               # ê° ë…¸ë“œ êµ¬í˜„
â”‚   â”‚   â””â”€â”€ routing.py             # ì¡°ê±´ë¶€ ë¼ìš°íŒ…
â”‚   â”‚
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â”œâ”€â”€ database.py            # SQLAlchemy ì—°ê²°
â”‚   â”‚   â””â”€â”€ models.py              # ORM ëª¨ë¸
â”‚   â”‚
â”‚   â”œâ”€â”€ quality/
â”‚   â”‚   â””â”€â”€ scorer.py              # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ html_cleaner.py        # HTML ì „ì²˜ë¦¬
â”‚       â””â”€â”€ prompts.py             # LLM í”„ë¡¬í”„íŠ¸
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_scrapy.py
â”‚   â”œâ”€â”€ test_agents.py
â”‚   â”œâ”€â”€ test_quality.py
â”‚   â””â”€â”€ test_workflow.py
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ init_db.sql                # PostgreSQL ìŠ¤í‚¤ë§ˆ
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

---

## ğŸ”„ Selector ì—…ë°ì´íŠ¸ ë©”ì»¤ë‹ˆì¦˜ (Selector Update Mechanism)

### ì„¤ê³„ ì›ì¹™

**ëª©í‘œ**: UC2ì—ì„œ 2-Agentê°€ ìƒì„±í•œ ìƒˆ Selectorë¥¼ ì•ˆì „í•˜ê²Œ PostgreSQLì— ë°˜ì˜

**ë°©ì‹**: Confidence-based Update (ì‹ ë¢°ë„ ê¸°ë°˜ ì—…ë°ì´íŠ¸)

### êµ¬í˜„

```python
def update_selector_node(state: CrawlAgentState) -> CrawlAgentState:
    """
    ì‹ ë¢°ë„ ê¸°ë°˜ Selector ì—…ë°ì´íŠ¸

    ì¡°ê±´:
    1. 2-Agent í•©ì˜ ë„ë‹¬ (consensus_reached = True)
    2. GPT ì‹ ë¢°ë„ â‰¥ 0.8
    3. Gemini ê²€ì¦ í†µê³¼
    """
    consensus = state.get("consensus_reached", False)
    gpt_confidence = state["gpt_analysis"].get("confidence", 0)
    gemini_valid = state["gemini_validation"].get("valid", False)

    # ì‹ ë¢°ë„ í™•ì¸
    if not consensus or gpt_confidence < 0.8 or not gemini_valid:
        logger.warning(f"[UPDATE SKIP] Low confidence")
        return {**state, "selector_updated": False}

    # Selector ì—…ë°ì´íŠ¸
    site_name = state["site_name"]
    selector = db.query(Selector).filter_by(site_name=site_name).first()

    new_selectors = state["gpt_selectors"]
    selector.title_selector = new_selectors["title_selector"]
    selector.body_selector = new_selectors["body_selector"]
    selector.date_selector = new_selectors["date_selector"]
    selector.updated_at = datetime.now(timezone.utc)

    db.commit()

    logger.info(f"[UPDATE SUCCESS] Selector updated for {site_name}")
    return {**state, "selector_updated": True}
```

**ì•ˆì „ ì¥ì¹˜**:
- **ì‹ ë¢°ë„ threshold**: GPT confidence â‰¥ 0.8
- **í•©ì˜ í•„ìˆ˜**: Gemini ê²€ì¦ í†µê³¼
- **ìë™ ë°±ì—…**: decision_logs í…Œì´ë¸”ì— ë³€ê²½ ì´ë ¥ ì €ì¥ (JSONB)
- **íŠ¸ëœì­ì…˜**: ì‹¤íŒ¨ ì‹œ ìë™ rollback

**Rollback ë°©ë²•**:
```sql
-- decision_logsì—ì„œ ì´ì „ Selector ì¡°íšŒ
SELECT gpt_analysis FROM decision_logs
WHERE site_name='yonhap' AND consensus_reached=true
ORDER BY created_at DESC LIMIT 2;

-- ìˆ˜ë™ ë³µì›
UPDATE selectors SET
  title_selector='[ì´ì „ê°’]',
  body_selector='[ì´ì „ê°’]',
  date_selector='[ì´ì „ê°’]'
WHERE site_name='yonhap';
```

---

## ğŸ” ì¥ì•  ë³µêµ¬ ë¡œì§ (Failure Recovery)

### Gemini API ì¥ì•  ì‹œ ëŒ€ì‘

**ì„¤ê³„ ì›ì¹™**:
- **Clean Restart**: ì¥ì•  ê°ì§€ ì‹œ ë§¨ ì²˜ìŒ ë‹¨ê³„ (load_selector)ë¡œ ë³µê·€
- **Exponential Backoff**: ì¬ì‹œë„ ê°„ ëŒ€ê¸° ì‹œê°„ ì¦ê°€ (2^nì´ˆ)
- **Max Retries**: ìµœëŒ€ 3íšŒ ì‹œë„ í›„ ìˆ˜ë™ ê°œì…

### LangGraph State í™•ì¥

```python
class CrawlAgentState(TypedDict):
    # ê¸°ì¡´ í•„ë“œ
    url: str
    site_name: str
    scrapy_success: bool
    # ...

    # ì¬ì‹œë„ ê´€ë ¨ (ì‹ ê·œ)
    attempt_count: int
    max_attempts: int
    error: Optional[str]
    last_error_node: Optional[str]
```

### ì¥ì•  ê°ì§€ ë° ë¼ìš°íŒ…

```python
def gemini_validate_with_error_handling(state: CrawlAgentState):
    """Gemini ê²€ì¦ + ì—ëŸ¬ í•¸ë“¤ë§"""
    try:
        model = genai.GenerativeModel('gemini-2.0-flash-exp')
        response = model.generate_content(prompt)
        return {**state, "gemini_validation": result, "error": None}
    except Exception as e:
        logger.error(f"[GEMINI ERROR] {e}")
        return {
            **state,
            "error": f"gemini_failure: {e}",
            "last_error_node": "gemini_validate"
        }

def route_after_gemini(state: CrawlAgentState) -> str:
    """Gemini í›„ ë¼ìš°íŒ…"""
    if state.get("error") and "gemini_failure" in state["error"]:
        attempt = state.get("attempt_count", 0)
        if attempt < state.get("max_attempts", 3):
            # Exponential backoff
            time.sleep(2 ** attempt)
            return "restart_from_beginning"
        else:
            return "manual_intervention"
    return "check_consensus"
```

**ì¥ì•  ì‹œë‚˜ë¦¬ì˜¤**:
```
ì‹œë„ 1 (count=0): load â†’ scrapy â†’ gpt â†’ [gemini FAIL] â†’ sleep 1ì´ˆ â†’ load
ì‹œë„ 2 (count=1): load â†’ scrapy â†’ gpt â†’ [gemini FAIL] â†’ sleep 2ì´ˆ â†’ load
ì‹œë„ 3 (count=2): load â†’ scrapy â†’ gpt â†’ [gemini FAIL] â†’ sleep 4ì´ˆ â†’ load
ì‹œë„ 4 (count=3): [max retries] â†’ manual_intervention â†’ END
```

**ìˆ˜ë™ ê°œì…**:
```python
def manual_intervention_node(state):
    logger.critical(f"[MANUAL INTERVENTION] URL: {state['url']}")
    # PoC: ë¡œê·¸ë§Œ ê¸°ë¡
    # Production: ì´ë©”ì¼/Slack ì•Œë¦¼
    return {**state, "crawl_mode": "failed"}
```

---

## ğŸ” DOM ë³€ê²½ ë¹ˆë„ ê²€ì¦ (DOM Change Frequency Validation)

### ëª©ì 

1. UC1 90% ê°€ì • ê²€ì¦
2. UC2 ë°ëª¨ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±

### ê²€ì¦ ë°©ë²•

**ì¹´í…Œê³ ë¦¬ë³„ Selector ì¼ê´€ì„± í…ŒìŠ¤íŠ¸**:

```python
# scripts/validate_dom_consistency.py

TEST_URLS = {
    "yonhap": {
        "politics": [5ê°œ URL],
        "economy": [5ê°œ URL],
        "society": [5ê°œ URL]
    },
    "naver_economy": {
        "general": [5ê°œ URL],
        "stock": [5ê°œ URL]
    },
    "bbc": {
        "world": [5ê°œ URL],
        "business": [5ê°œ URL]
    }
}

def check_selector_consistency(site: str, urls: list) -> dict:
    """
    Selector ì¼ê´€ì„± í™•ì¸
    Returns: {"success_rate": 93.3, "total": 15, "success": 14}
    """
    selector = db.query(Selector).filter_by(site_name=site).first()
    success_count = 0

    for url in urls:
        response = requests.get(url)
        soup = BeautifulSoup(response.text, 'html.parser')

        title = soup.select_one(selector.title_selector)
        body = soup.select_one(selector.body_selector)

        if title and body and len(body.text) > 100:
            success_count += 1

    return {
        "success_rate": (success_count / len(urls)) * 100,
        "total": len(urls),
        "success": success_count
    }
```

**ì‹¤í–‰ ì‹œì **: Phase 2.3 ì™„ë£Œ ì§í›„

**ëª©í‘œ**: í‰ê·  success rate â‰¥ 90% â†’ UC1 ê°€ì • ê²€ì¦

### UC2 ë°ëª¨ ì‹œë‚˜ë¦¬ì˜¤

```bash
# ë°©ë²• 1: ì˜ë„ì  Selector ì†ìƒ
UPDATE selectors SET title_selector='h1.wrong' WHERE site_name='yonhap';

# ë°©ë²• 2: ë‹¤ë¥¸ í¬ë§·ì˜ URL ì‚¬ìš©
# ì˜ˆ: í¬í† ë‰´ìŠ¤, ì˜ìƒë‰´ìŠ¤ ë“± (ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ë°œê²¬)

# UC2 íŠ¸ë¦¬ê±°
python src/main.py --url "[ì‹¤íŒ¨ URL]" --site yonhap
# ê¸°ëŒ€: Scrapy ì‹¤íŒ¨ â†’ 2-Agent â†’ ìƒˆ Selector â†’ ì„±ê³µ
```

---

## ğŸ“š ê¸°ìˆ  ìŠ¤íƒ ë³€ê²½ ì´ë ¥ (Tech Stack Decision History)

### 2025-10-29: scrapy-playwright ì œê±°

**ê²°ì •**: BBC Newsê°€ SSRì„ì„ í™•ì¸, scrapy-playwright ì œê±°

**ê²€ì¦ ê³¼ì •**:
```python
# BBC News SSR í…ŒìŠ¤íŠ¸
import requests
from bs4 import BeautifulSoup

url = "https://www.bbc.com/news"
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')

# ê²°ê³¼
print(f"HTML: {len(response.text):,} bytes")  # 319,028
print(f"h2 tags: {len(soup.find_all('h2'))}")  # 5ê°œ ë°œê²¬
# â†’ SSR í™•ì¸ âœ…
```

**scrapy-playwright ë¬¸ì œì **:
- GitHub stars: 1,244 (vs Scrapy 56K)
- Success rate: 25% (2000 ì‚¬ì´íŠ¸ í…ŒìŠ¤íŠ¸)
- Memory leak (macOS + chromium)
- Production ì‚¬ë¡€ ê±°ì˜ ì—†ìŒ

**ì˜í–¥**:
- ë³µì¡ë„: 40% ê°ì†Œ
- Phase 2 ì‹œê°„: 16h â†’ 8h (50% ë‹¨ì¶•)
- ì‹ ë¢°ì„±: í¬ê²Œ í–¥ìƒ

**ìµœì¢… ê¸°ìˆ  ìŠ¤íƒ**: Scrapy ë‹¨ì¼ í”„ë ˆì„ì›Œí¬ (3ê°œ ì‚¬ì´íŠ¸ ëª¨ë‘ SSR)

**ìƒì„¸ ë¬¸ì„œ**: [ARCHIVE-DECISIONS.md](./ARCHIVE-DECISIONS.md#scrapy-playwright-removal)

---

## ğŸ”— ì°¸ê³  ìë£Œ (References)

### ê¸°ìˆ  ë¬¸ì„œ

- **Scrapy**: [https://docs.scrapy.org/en/latest/](https://docs.scrapy.org/en/latest/)
- **PostgreSQL 16**: [https://www.postgresql.org/docs/16/](https://www.postgresql.org/docs/16/)
- **LangGraph**: [https://langchain-ai.github.io/langgraph/](https://langchain-ai.github.io/langgraph/)
- **OpenAI Structured Output**: [https://platform.openai.com/docs/guides/structured-outputs](https://platform.openai.com/docs/guides/structured-outputs)
- **Google Gemini API**: [https://ai.google.dev/docs](https://ai.google.dev/docs)

### ë‚´ë¶€ ë¬¸ì„œ

- [00-PRD-1-PROBLEM-SOLUTION.md](./00-PRD-1-PROBLEM-SOLUTION.md) - ë¬¸ì œ/ì†”ë£¨ì…˜
- [00-PRD-3-IMPLEMENTATION.md](./00-PRD-3-IMPLEMENTATION.md) - êµ¬í˜„ ê°€ì´ë“œ ë° ë¡œë“œë§µ
- [00-DESIGN-DECISIONS-PROPOSALS.md](./00-DESIGN-DECISIONS-PROPOSALS.md) - ì„¤ê³„ ê²°ì •ì‚¬í•­ ì œì•ˆì„œ
- [ARCHIVE-DECISIONS.md](./ARCHIVE-DECISIONS.md) - ì˜ì‚¬ê²°ì • ì•„ì¹´ì´ë¸Œ

---

**ë¬¸ì„œ ìƒíƒœ**: âœ… ìµœì¢… ì—…ë°ì´íŠ¸ ì™„ë£Œ (2025-10-30)
**ë²„ì „**: 2.0 (Scrapy ë‹¨ì¼ í”„ë ˆì„ì›Œí¬, ì¥ì•  ë³µêµ¬ ë¡œì§ ì¶”ê°€)
**ë‹¤ìŒ ë‹¨ê³„**: [00-PRD-3-IMPLEMENTATION.md](./00-PRD-3-IMPLEMENTATION.md) ì°¸ì¡°

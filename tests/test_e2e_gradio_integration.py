"""
Sprint 4-5 ìµœì¢… í†µí•© ê²€ì¦ (End-to-End)
Created: 2025-11-09

ëª©ì :
    UC1 â†’ UC2 â†’ Human Review ì „ì²´ í”Œë¡œìš°ë¥¼ ê²€ì¦í•˜ê³ 
    Gradio UIì—ì„œ ëª¨ë“  ì‘ì—…ì´ ê°€ëŠ¥í•œì§€ í™•ì¸

í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤:
    1. UC1 í’ˆì§ˆ ê²€ì¦ ì‹¤íŒ¨ (ê³ ì˜ë¡œ ì˜ëª»ëœ Selector ì‚¬ìš©)
    2. UC2 ìë™ íŠ¸ë¦¬ê±° í™•ì¸
    3. UC2 í•©ì˜ ì‹¤íŒ¨ ì‹œë®¬ë ˆì´ì…˜ (Human Review í•„ìš”)
    4. DecisionLog ìƒì„± í™•ì¸
    5. Gradio UI Tab 6ì—ì„œ ìŠ¹ì¸/ê±°ë¶€ ê°€ëŠ¥ í™•ì¸

ì‹¤í–‰ ë°©ë²•:
    cd /Users/charlee/Desktop/Intern/crawlagent
    PYTHONPATH=/Users/charlee/Desktop/Intern/crawlagent poetry run python tests/test_e2e_gradio_integration.py
"""

import sys
import os

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.insert(0, '/Users/charlee/Desktop/Intern/crawlagent')

from datetime import datetime
from src.storage.database import get_db
from src.storage.models import DecisionLog, Selector, CrawlResult
from src.workflow.uc1_validation import create_uc1_validation_agent
from loguru import logger

# ë¡œê·¸ ì„¤ì •
logger.remove()
logger.add(sys.stdout, level="INFO")


def test_e2e_integration():
    """
    End-to-End í†µí•© í…ŒìŠ¤íŠ¸

    ì‹œë‚˜ë¦¬ì˜¤:
        1. í…ŒìŠ¤íŠ¸ìš© Selector ìƒì„± (ì˜ëª»ëœ Selector)
        2. UC1 í’ˆì§ˆ ê²€ì¦ ì‹¤íŒ¨
        3. UC2 ìë™ íŠ¸ë¦¬ê±° (heal_with_uc2 ë…¸ë“œ)
        4. UC2 í•©ì˜ ì„±ê³µ/ì‹¤íŒ¨ ì‹œë®¬ë ˆì´ì…˜
        5. DecisionLog í™•ì¸
        6. Gradio UIì—ì„œ ìŠ¹ì¸/ê±°ë¶€ ê°€ëŠ¥ í™•ì¸
    """
    logger.info("="*80)
    logger.info("Sprint 4-5 ìµœì¢… í†µí•© ê²€ì¦ (End-to-End)")
    logger.info("="*80)

    db = next(get_db())

    try:
        # ============================================================
        # Phase 1: í…ŒìŠ¤íŠ¸ í™˜ê²½ ì¤€ë¹„
        # ============================================================
        logger.info("\n[Phase 1] í…ŒìŠ¤íŠ¸ í™˜ê²½ ì¤€ë¹„...")

        test_site = "test_e2e_site"
        test_url = "https://www.yna.co.kr/view/AKR20251109000001001"

        # ê¸°ì¡´ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‚­ì œ
        db.query(DecisionLog).filter(DecisionLog.site_name == test_site).delete()
        db.query(Selector).filter(Selector.site_name == test_site).delete()
        db.query(CrawlResult).filter(CrawlResult.site_name == test_site).delete()
        db.commit()

        # ì˜ëª»ëœ Selector ìƒì„± (í’ˆì§ˆ ì‹¤íŒ¨ ìœ ë°œ)
        bad_selector = Selector(
            site_name=test_site,
            title_selector="h999.not-exist",  # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Selector
            body_selector="div.not-exist",
            date_selector="time.not-exist",
            site_type="ssr"
        )
        db.add(bad_selector)
        db.commit()

        logger.info(f"  âœ… í…ŒìŠ¤íŠ¸ í™˜ê²½ ì¤€ë¹„ ì™„ë£Œ")
        logger.info(f"     Test Site: {test_site}")
        logger.info(f"     Bad Selector Created (title_selector={bad_selector.title_selector})")

        # ============================================================
        # Phase 2: UC1 í’ˆì§ˆ ê²€ì¦ ì‹¤íŒ¨ ì‹œë®¬ë ˆì´ì…˜
        # ============================================================
        logger.info("\n[Phase 2] UC1 í’ˆì§ˆ ê²€ì¦ ì‹¤íŒ¨ ì‹œë®¬ë ˆì´ì…˜...")

        graph = create_uc1_validation_agent()

        inputs = {
            "url": test_url,
            "site_name": test_site,
            "title": None,  # Selector ì‹¤íŒ¨
            "body": "ì§§ì€ ë³¸ë¬¸",  # 500ì ë¯¸ë§Œ
            "date": "2025-11-09",
            "quality_score": 0,
            "missing_fields": [],
            "next_action": "save",
            "uc2_triggered": False,
            "uc2_success": False
        }

        logger.info(f"  Input State:")
        logger.info(f"     URL: {inputs['url']}")
        logger.info(f"     Title: {inputs['title']}")
        logger.info(f"     Body: {inputs['body']}")
        logger.info(f"     Expected: quality_score < 80 â†’ UC2 trigger")

        # ============================================================
        # Phase 3: UC1 ì‹¤í–‰ (UC2 ìë™ ì—°ê³„)
        # ============================================================
        logger.info("\n[Phase 3] UC1 Validation Agent ì‹¤í–‰...")

        result = graph.invoke(inputs)

        logger.info(f"\n  UC1 ì‹¤í–‰ ê²°ê³¼:")
        logger.info(f"     Quality Score: {result.get('quality_score')}")
        logger.info(f"     Missing Fields: {result.get('missing_fields')}")
        logger.info(f"     Next Action: {result.get('next_action')}")
        logger.info(f"     UC2 Triggered: {result.get('uc2_triggered')}")
        logger.info(f"     UC2 Success: {result.get('uc2_success')}")

        # ============================================================
        # Phase 4: DecisionLog í™•ì¸
        # ============================================================
        logger.info("\n[Phase 4] DecisionLog í™•ì¸...")

        decision_logs = db.query(DecisionLog).filter_by(
            site_name=test_site
        ).order_by(DecisionLog.created_at.desc()).all()

        if decision_logs:
            logger.info(f"  âœ… DecisionLog ìƒì„±ë¨ ({len(decision_logs)}ê°œ)")
            for i, log in enumerate(decision_logs, 1):
                logger.info(f"\n  [{i}] DecisionLog ID={log.id}")
                logger.info(f"       URL: {log.url}")
                logger.info(f"       Consensus Reached: {log.consensus_reached}")
                logger.info(f"       Retry Count: {log.retry_count}")
                logger.info(f"       GPT Proposal: {bool(log.gpt_analysis)}")
                logger.info(f"       Gemini Validation: {bool(log.gemini_validation)}")
                logger.info(f"       Created: {log.created_at}")

                # GPT/Gemini ë‚´ìš© ìƒì„¸ í‘œì‹œ
                if log.gpt_analysis:
                    logger.info(f"       GPT Title Selector: {log.gpt_analysis.get('title_selector')}")
                    logger.info(f"       GPT Confidence: {log.gpt_analysis.get('confidence')}")

                if log.gemini_validation:
                    logger.info(f"       Gemini Is Valid: {log.gemini_validation.get('is_valid')}")
                    logger.info(f"       Gemini Confidence: {log.gemini_validation.get('confidence')}")
        else:
            logger.warning(f"  âš ï¸ DecisionLogê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        # ============================================================
        # Phase 5: Selector ì—…ë°ì´íŠ¸ í™•ì¸ (UC2 ì„±ê³µ ì‹œ)
        # ============================================================
        logger.info("\n[Phase 5] Selector ì—…ë°ì´íŠ¸ í™•ì¸...")

        selector = db.query(Selector).filter_by(site_name=test_site).first()

        if selector:
            logger.info(f"  âœ… Selector ì¡´ì¬:")
            logger.info(f"     Title Selector: {selector.title_selector}")
            logger.info(f"     Body Selector: {selector.body_selector}")
            logger.info(f"     Date Selector: {selector.date_selector}")
            logger.info(f"     Updated At: {selector.updated_at}")

            # UC2 ì„±ê³µ ì‹œ Selectorê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆëŠ”ì§€ í™•ì¸
            if result.get('uc2_success') and selector.title_selector != "h999.not-exist":
                logger.info(f"  âœ… UC2ê°€ Selectorë¥¼ ì„±ê³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸í–ˆìŠµë‹ˆë‹¤!")
            elif not result.get('uc2_success'):
                logger.info(f"  â„¹ï¸ UC2 í•©ì˜ ì‹¤íŒ¨ â†’ Human Review í•„ìš”")
        else:
            logger.warning(f"  âš ï¸ Selectorë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        # ============================================================
        # Phase 6: Gradio UI Tab 6 ì‚¬ìš© ê°€ëŠ¥ í™•ì¸
        # ============================================================
        logger.info("\n[Phase 6] Gradio UI Tab 6 ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸...")

        pending_logs = db.query(DecisionLog).filter_by(
            consensus_reached=False
        ).order_by(DecisionLog.created_at.desc()).all()

        if pending_logs:
            logger.info(f"  âœ… Human Review ëŒ€ê¸° ì¤‘ì¸ ì œì•ˆ: {len(pending_logs)}ê°œ")
            logger.info(f"\n  Gradio UIì—ì„œ í™•ì¸ ê°€ëŠ¥:")
            logger.info(f"     1. Gradio ì‹¤í–‰: poetry run python src/ui/app.py")
            logger.info(f"     2. http://localhost:7860 ì ‘ì†")
            logger.info(f"     3. Tab 6 'ğŸ¤– ìë™ ë³µêµ¬ (ğŸ”§ ê°œë°œì)' í´ë¦­")
            logger.info(f"     4. 'ğŸ”„ ìƒˆë¡œê³ ì¹¨' ë²„íŠ¼ í´ë¦­")
            logger.info(f"     5. Pending Listì—ì„œ Decision ID={pending_logs[0].id} í™•ì¸")
            logger.info(f"     6. 'âœ… ìŠ¹ì¸' ë˜ëŠ” 'âŒ ê±°ë¶€' í´ë¦­")
        else:
            logger.info(f"  â„¹ï¸ Human Review ëŒ€ê¸° ì¤‘ì¸ ì œì•ˆ ì—†ìŒ (UC2 í•©ì˜ ì„±ê³µ)")

        # ============================================================
        # Phase 7: í†µí•© ê²€ì¦ ê²°ê³¼ ìš”ì•½
        # ============================================================
        logger.info("\n[Phase 7] í†µí•© ê²€ì¦ ê²°ê³¼ ìš”ì•½...")

        summary = {
            "UC1 ì‹¤í–‰": "âœ…" if result.get('quality_score') is not None else "âŒ",
            "í’ˆì§ˆ ê²€ì¦ ì‹¤íŒ¨": "âœ…" if result.get('quality_score') < 80 else "âŒ",
            "UC2 íŠ¸ë¦¬ê±°": "âœ…" if result.get('uc2_triggered') else "âŒ",
            "DecisionLog ìƒì„±": "âœ…" if decision_logs else "âŒ",
            "UC2 í•©ì˜ ì„±ê³µ": "âœ…" if result.get('uc2_success') else "â„¹ï¸ (Human Review í•„ìš”)",
            "Gradio UI ì‚¬ìš© ê°€ëŠ¥": "âœ…" if pending_logs or decision_logs else "âŒ"
        }

        logger.info(f"\n  ê²€ì¦ ê²°ê³¼:")
        for key, value in summary.items():
            logger.info(f"     {key}: {value}")

        # ============================================================
        # Phase 8: ì •ë¦¬ (í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‚­ì œ)
        # ============================================================
        logger.info("\n[Phase 8] í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •ë¦¬...")

        # ì„ íƒ: í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë‚¨ê²¨ë‘ê³  Gradio UIì—ì„œ í™•ì¸ ê°€ëŠ¥
        logger.info(f"  â„¹ï¸ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë‚¨ê²¨ë‘ê³  Gradio UIì—ì„œ í™•ì¸í•˜ì„¸ìš”!")
        logger.info(f"     - Site: {test_site}")
        logger.info(f"     - DecisionLogs: {len(decision_logs)}ê°œ")
        logger.info(f"     - Pending: {len(pending_logs)}ê°œ")

        # ì‚­ì œí•˜ë ¤ë©´ ì£¼ì„ í•´ì œ:
        # db.query(DecisionLog).filter(DecisionLog.site_name == test_site).delete()
        # db.query(Selector).filter(Selector.site_name == test_site).delete()
        # db.commit()
        # logger.info(f"  âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‚­ì œ ì™„ë£Œ")

        logger.info("\n" + "="*80)
        logger.info("âœ… End-to-End í†µí•© ê²€ì¦ ì™„ë£Œ!")
        logger.info("="*80)

        logger.info("\në‹¤ìŒ ë‹¨ê³„:")
        logger.info("  1. Gradio UI ì‹¤í–‰:")
        logger.info("     cd /Users/charlee/Desktop/Intern/crawlagent")
        logger.info("     PYTHONPATH=/Users/charlee/Desktop/Intern/crawlagent poetry run python src/ui/app.py")
        logger.info("")
        logger.info("  2. http://localhost:7860 ì ‘ì†")
        logger.info("")
        logger.info("  3. Tab 6 'ğŸ¤– ìë™ ë³µêµ¬ (ğŸ”§ ê°œë°œì)' í™•ì¸")
        logger.info("")
        logger.info("  4. 'ğŸ”„ ìƒˆë¡œê³ ì¹¨' í´ë¦­ â†’ Pending List í™•ì¸")
        logger.info("")
        logger.info("  5. 'âœ… ìŠ¹ì¸' ë˜ëŠ” 'âŒ ê±°ë¶€' í…ŒìŠ¤íŠ¸")

    except Exception as e:
        logger.error(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()

    finally:
        db.close()


if __name__ == "__main__":
    # .env íŒŒì¼ ë¡œë“œ
    from dotenv import load_dotenv
    load_dotenv()

    # API í‚¤ í™•ì¸
    if not os.getenv("OPENAI_API_KEY"):
        logger.error("âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        logger.error("   .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”")
        sys.exit(1)

    # GEMINI_API_KEY ë˜ëŠ” GOOGLE_API_KEY í™•ì¸
    gemini_key = os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")
    if not gemini_key:
        logger.error("âŒ GEMINI_API_KEY ë˜ëŠ” GOOGLE_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        logger.error("   .env íŒŒì¼ì— GOOGLE_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”")
        sys.exit(1)

    # GEMINI_API_KEYê°€ ì—†ìœ¼ë©´ GOOGLE_API_KEYë¡œ ì„¤ì •
    if not os.getenv("GEMINI_API_KEY") and os.getenv("GOOGLE_API_KEY"):
        os.environ["GEMINI_API_KEY"] = os.getenv("GOOGLE_API_KEY")

    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_e2e_integration()

#!/usr/bin/env python3
"""
CrawlAgent Use Case ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸

UC1, UC2, UC3ì˜ ì„±ê³µë¥ ì„ ì‹¤ì œ URLë¡œ í…ŒìŠ¤íŠ¸í•˜ê³  ê²€ì¦ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

Usage:
    cd /Users/charlee/Desktop/Intern/crawlagent
    PYTHONPATH=/Users/charlee/Desktop/Intern/crawlagent poetry run python scripts/validate_use_cases.py --output validation_report.md

Features:
    - UC1: 10ê°œ URL í…ŒìŠ¤íŠ¸ (ê¸°ì¡´ ì‚¬ì´íŠ¸ í’ˆì§ˆ ê²€ì¦)
    - UC2: 10ê°œ ì…€ë ‰í„° íŒŒê´´ ì‹¤í—˜ (ìë™ ë³µêµ¬ í…ŒìŠ¤íŠ¸)
    - UC3: 5ê°œ ì‹ ê·œ ì‚¬ì´íŠ¸ í…ŒìŠ¤íŠ¸ (ìë™ ë°œê²¬)
    - Markdown ë³´ê³ ì„œ ìƒì„± (ì„±ê³µë¥ , ì†Œìš” ì‹œê°„, Consensus Score ë¶„í¬)
"""

import argparse
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import requests

from src.storage.database import get_db
from src.storage.models import Selector
from src.workflow.master_crawl_workflow import MasterCrawlState, build_master_graph

# ============================================================================
# Test URLs
# ============================================================================

UC1_TEST_URLS = [
    # ì—°í•©ë‰´ìŠ¤ (ê¸°ì¡´ ì‚¬ì´íŠ¸)
    "https://www.yna.co.kr/view/AKR20250113000100051",
    "https://www.yna.co.kr/view/AKR20250113000200051",
    # BBC (ê¸°ì¡´ ì‚¬ì´íŠ¸)
    "https://www.bbc.com/news/world-asia-12345678",
    "https://www.bbc.com/news/technology-87654321",
    # ë„¤ì´ë²„ë‰´ìŠ¤ (ê¸°ì¡´ ì‚¬ì´íŠ¸)
    "https://news.naver.com/main/read.naver?mode=LSD&mid=sec&sid1=001&oid=001&aid=0014912345",
    "https://news.naver.com/main/read.naver?mode=LSD&mid=sec&sid1=001&oid=001&aid=0014912346",
    # ì¶”ê°€ í…ŒìŠ¤íŠ¸ URL (í•„ìš” ì‹œ)
    "https://example.com/article1",
    "https://example.com/article2",
    "https://example.com/article3",
    "https://example.com/article4",
]

UC3_TEST_URLS = [
    # ì‹ ê·œ ì‚¬ì´íŠ¸ (DBì— ì—†ëŠ” ì‚¬ì´íŠ¸)
    "https://www.theguardian.com/world/2025/jan/13/example-article",
    "https://apnews.com/article/example-12345",
    "https://www.chosun.com/national/2025/01/13/example/",
    "https://www.joongang.co.kr/article/25231234",
    "https://www.npr.org/2025/01/13/1234567890/example-story",
]


# ============================================================================
# Validation Functions
# ============================================================================


def validate_uc1(test_urls: List[str], output_file: Path) -> Dict[str, Any]:
    """
    UC1 Quality Gate ê²€ì¦

    Args:
        test_urls: í…ŒìŠ¤íŠ¸í•  URL ë¦¬ìŠ¤íŠ¸
        output_file: ì¶œë ¥ ë³´ê³ ì„œ íŒŒì¼

    Returns:
        Dict with validation results
    """

    print("=" * 80)
    print("ğŸŸ¢ UC1 Quality Gate ê²€ì¦")
    print("=" * 80)

    results = []
    master_app = build_master_graph()

    for idx, url in enumerate(test_urls, 1):
        print(f"\n[{idx}/{len(test_urls)}] Testing: {url}")

        try:
            # Fetch HTML
            response = requests.get(
                url,
                timeout=10,
                headers={
                    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
                },
            )
            html_content = response.text

            # Extract site name
            from urllib.parse import urlparse

            parsed = urlparse(url)
            site_name = parsed.netloc.replace("www.", "").split(".")[0]

            # Run Master Graph
            start_time = time.time()
            initial_state: MasterCrawlState = {
                "url": url,
                "site_name": site_name,
                "html_content": html_content,
                "current_uc": None,
                "next_action": None,
                "failure_count": 0,
                "uc1_validation_result": None,
                "uc2_consensus_result": None,
                "uc3_discovery_result": None,
                "final_result": None,
                "error_message": None,
                "workflow_history": [],
            }

            final_state = master_app.invoke(initial_state)
            elapsed = time.time() - start_time

            # Analyze result
            success = final_state.get("final_result") is not None
            quality_score = (
                final_state.get("uc1_validation_result", {}).get("quality_score", 0)
                if final_state.get("uc1_validation_result")
                else 0
            )
            workflow = " â†’ ".join(final_state.get("workflow_history", []))

            results.append(
                {
                    "url": url,
                    "site": site_name,
                    "success": success,
                    "quality_score": quality_score,
                    "elapsed_time": elapsed,
                    "workflow": workflow,
                }
            )

            status = "âœ… PASS" if success else "âŒ FAIL"
            print(f"  {status} | Quality: {quality_score}/100 | Time: {elapsed:.2f}s")

        except Exception as e:
            print(f"  âŒ ERROR: {str(e)}")
            results.append(
                {
                    "url": url,
                    "site": "unknown",
                    "success": False,
                    "quality_score": 0,
                    "elapsed_time": 0,
                    "workflow": "error",
                    "error": str(e),
                }
            )

    # Calculate metrics
    success_count = sum(1 for r in results if r["success"])
    success_rate = (success_count / len(results)) * 100 if results else 0
    avg_time = sum(r["elapsed_time"] for r in results) / len(results) if results else 0
    avg_quality = (
        sum(r["quality_score"] for r in results if r["success"]) / success_count
        if success_count > 0
        else 0
    )

    summary = {
        "total_tests": len(results),
        "success_count": success_count,
        "success_rate": success_rate,
        "avg_time": avg_time,
        "avg_quality": avg_quality,
        "results": results,
    }

    print(f"\nğŸ“Š UC1 Summary:")
    print(f"  Success Rate: {success_rate:.1f}% ({success_count}/{len(results)})")
    print(f"  Avg Time: {avg_time:.2f}s")
    print(f"  Avg Quality: {avg_quality:.1f}/100")

    return summary


def validate_uc3(test_urls: List[str], output_file: Path) -> Dict[str, Any]:
    """
    UC3 New Site Discovery ê²€ì¦

    Args:
        test_urls: í…ŒìŠ¤íŠ¸í•  ì‹ ê·œ ì‚¬ì´íŠ¸ URL ë¦¬ìŠ¤íŠ¸
        output_file: ì¶œë ¥ ë³´ê³ ì„œ íŒŒì¼

    Returns:
        Dict with validation results
    """

    print("\n" + "=" * 80)
    print("ğŸ”µ UC3 New Site Discovery ê²€ì¦")
    print("=" * 80)

    results = []
    master_app = build_master_graph()

    for idx, url in enumerate(test_urls, 1):
        print(f"\n[{idx}/{len(test_urls)}] Testing: {url}")

        try:
            # Fetch HTML
            response = requests.get(
                url,
                timeout=10,
                headers={
                    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
                },
            )
            html_content = response.text

            # Extract site name
            from urllib.parse import urlparse

            parsed = urlparse(url)
            site_name = parsed.netloc.replace("www.", "").split(".")[0]

            # Run Master Graph
            start_time = time.time()
            initial_state: MasterCrawlState = {
                "url": url,
                "site_name": site_name,
                "html_content": html_content,
                "current_uc": None,
                "next_action": None,
                "failure_count": 0,
                "uc1_validation_result": None,
                "uc2_consensus_result": None,
                "uc3_discovery_result": None,
                "final_result": None,
                "error_message": None,
                "workflow_history": [],
            }

            final_state = master_app.invoke(initial_state)
            elapsed = time.time() - start_time

            # Analyze result
            success = final_state.get("final_result") is not None
            uc3_result = final_state.get("uc3_discovery_result", {})
            consensus_score = uc3_result.get("consensus_score", 0.0) if uc3_result else 0.0
            workflow = " â†’ ".join(final_state.get("workflow_history", []))

            results.append(
                {
                    "url": url,
                    "site": site_name,
                    "success": success,
                    "consensus_score": consensus_score,
                    "elapsed_time": elapsed,
                    "workflow": workflow,
                }
            )

            status = "âœ… PASS" if success else "âŒ FAIL"
            print(f"  {status} | Consensus: {consensus_score:.3f} | Time: {elapsed:.2f}s")

        except Exception as e:
            print(f"  âŒ ERROR: {str(e)}")
            results.append(
                {
                    "url": url,
                    "site": "unknown",
                    "success": False,
                    "consensus_score": 0.0,
                    "elapsed_time": 0,
                    "workflow": "error",
                    "error": str(e),
                }
            )

    # Calculate metrics
    success_count = sum(1 for r in results if r["success"])
    success_rate = (success_count / len(results)) * 100 if results else 0
    avg_time = sum(r["elapsed_time"] for r in results) / len(results) if results else 0
    avg_consensus = sum(r["consensus_score"] for r in results) / len(results) if results else 0

    summary = {
        "total_tests": len(results),
        "success_count": success_count,
        "success_rate": success_rate,
        "avg_time": avg_time,
        "avg_consensus": avg_consensus,
        "results": results,
    }

    print(f"\nğŸ“Š UC3 Summary:")
    print(f"  Success Rate: {success_rate:.1f}% ({success_count}/{len(results)})")
    print(f"  Avg Time: {avg_time:.2f}s")
    print(f"  Avg Consensus: {avg_consensus:.3f}")

    return summary


def generate_markdown_report(uc1_summary: Dict, uc3_summary: Dict, output_file: Path):
    """
    Generate Markdown validation report

    Args:
        uc1_summary: UC1 validation results
        uc3_summary: UC3 validation results
        output_file: Output markdown file path
    """

    print("\n" + "=" * 80)
    print("ğŸ“ Generating Validation Report...")
    print("=" * 80)

    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    report = f"""# CrawlAgent UC ê²€ì¦ ë³´ê³ ì„œ

**ìƒì„±ì¼ì‹œ**: {now}

---

## ğŸ“Š ì „ì²´ ìš”ì•½

| Use Case | í…ŒìŠ¤íŠ¸ ìˆ˜ | ì„±ê³µ | ì‹¤íŒ¨ | ì„±ê³µë¥  | í‰ê·  ì†Œìš” ì‹œê°„ |
|----------|-----------|------|------|--------|----------------|
| UC1 Quality Gate | {uc1_summary['total_tests']} | {uc1_summary['success_count']} | {uc1_summary['total_tests'] - uc1_summary['success_count']} | **{uc1_summary['success_rate']:.1f}%** | {uc1_summary['avg_time']:.2f}s |
| UC3 New Site Discovery | {uc3_summary['total_tests']} | {uc3_summary['success_count']} | {uc3_summary['total_tests'] - uc3_summary['success_count']} | **{uc3_summary['success_rate']:.1f}%** | {uc3_summary['avg_time']:.2f}s |

---

## ğŸŸ¢ UC1 Quality Gate ê²€ì¦ ê²°ê³¼

### ì„±ëŠ¥ ì§€í‘œ
- **ì„±ê³µë¥ **: {uc1_summary['success_rate']:.1f}% ({uc1_summary['success_count']}/{uc1_summary['total_tests']})
- **í‰ê·  í’ˆì§ˆ ì ìˆ˜**: {uc1_summary['avg_quality']:.1f}/100
- **í‰ê·  ì†Œìš” ì‹œê°„**: {uc1_summary['avg_time']:.2f}s
- **ëª©í‘œ ë‹¬ì„±**: {'âœ… PASS (â‰¥80%)' if uc1_summary['success_rate'] >= 80 else 'âŒ FAIL (<80%)'}

### ìƒì„¸ ê²°ê³¼

| # | Site | Success | Quality | Time | Workflow |
|---|------|---------|---------|------|----------|
"""

    for idx, result in enumerate(uc1_summary["results"], 1):
        status = "âœ…" if result["success"] else "âŒ"
        site = result["site"]
        quality = result["quality_score"]
        time_str = f"{result['elapsed_time']:.2f}s"
        workflow = result.get("workflow", "N/A")

        report += f"| {idx} | {site} | {status} | {quality}/100 | {time_str} | {workflow} |\n"

    report += f"""
---

## ğŸ”µ UC3 New Site Discovery ê²€ì¦ ê²°ê³¼

### ì„±ëŠ¥ ì§€í‘œ
- **ì„±ê³µë¥ **: {uc3_summary['success_rate']:.1f}% ({uc3_summary['success_count']}/{uc3_summary['total_tests']})
- **í‰ê·  Consensus Score**: {uc3_summary['avg_consensus']:.3f}
- **í‰ê·  ì†Œìš” ì‹œê°„**: {uc3_summary['avg_time']:.2f}s
- **ëª©í‘œ ë‹¬ì„±**: {'âœ… PASS (â‰¥80%)' if uc3_summary['success_rate'] >= 80 else 'âŒ FAIL (<80%)'}

### ìƒì„¸ ê²°ê³¼

| # | Site | Success | Consensus | Time | Workflow |
|---|------|---------|-----------|------|----------|
"""

    for idx, result in enumerate(uc3_summary["results"], 1):
        status = "âœ…" if result["success"] else "âŒ"
        site = result["site"]
        consensus = f"{result['consensus_score']:.3f}"
        time_str = f"{result['elapsed_time']:.2f}s"
        workflow = result.get("workflow", "N/A")

        report += f"| {idx} | {site} | {status} | {consensus} | {time_str} | {workflow} |\n"

    report += f"""
---

## ğŸ¯ ê²°ë¡ 

### ë‹¬ì„± ìƒí™©
- UC1 ì„±ê³µë¥ : {uc1_summary['success_rate']:.1f}% {'âœ…' if uc1_summary['success_rate'] >= 80 else 'âŒ'}
- UC3 ì„±ê³µë¥ : {uc3_summary['success_rate']:.1f}% {'âœ…' if uc3_summary['success_rate'] >= 80 else 'âŒ'}

### ë‹¤ìŒ ë‹¨ê³„
1. ì‹¤íŒ¨í•œ ì¼€ì´ìŠ¤ ë¶„ì„ ë° ê°œì„ 
2. LangSmith ì¶”ì ì—ì„œ ì‹¤íŒ¨ ì›ì¸ í™•ì¸
3. Consensus ì„ê³„ê°’ ì¡°ì • (í•„ìš” ì‹œ)
4. Few-Shot Examples ì¶”ê°€ (ì •í™•ë„ í–¥ìƒ)

---

**ë³´ê³ ì„œ ìƒì„±**: {now}
"""

    # Write report
    with open(output_file, "w", encoding="utf-8") as f:
        f.write(report)

    print(f"âœ… ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {output_file}")


# ============================================================================
# Main
# ============================================================================


def main():
    parser = argparse.ArgumentParser(description="CrawlAgent Use Case Validation")
    parser.add_argument(
        "--output",
        type=str,
        default="validation_report.md",
        help="Output markdown report file (default: validation_report.md)",
    )
    parser.add_argument("--skip-uc1", action="store_true", help="Skip UC1 validation")
    parser.add_argument("--skip-uc3", action="store_true", help="Skip UC3 validation")

    args = parser.parse_args()
    output_file = project_root / args.output

    print("\n" + "=" * 80)
    print("ğŸ¤– CrawlAgent Use Case Validation")
    print("=" * 80)
    print(f"Output: {output_file}\n")

    # UC1 Validation
    uc1_summary = None
    if not args.skip_uc1:
        uc1_summary = validate_uc1(UC1_TEST_URLS, output_file)
    else:
        print("â­ï¸  Skipping UC1 validation")
        uc1_summary = {
            "total_tests": 0,
            "success_count": 0,
            "success_rate": 0,
            "avg_time": 0,
            "avg_quality": 0,
            "results": [],
        }

    # UC3 Validation
    uc3_summary = None
    if not args.skip_uc3:
        uc3_summary = validate_uc3(UC3_TEST_URLS, output_file)
    else:
        print("â­ï¸  Skipping UC3 validation")
        uc3_summary = {
            "total_tests": 0,
            "success_count": 0,
            "success_rate": 0,
            "avg_time": 0,
            "avg_consensus": 0,
            "results": [],
        }

    # Generate Report
    generate_markdown_report(uc1_summary, uc3_summary, output_file)

    print("\n" + "=" * 80)
    print("âœ… Validation Complete!")
    print("=" * 80)


if __name__ == "__main__":
    main()

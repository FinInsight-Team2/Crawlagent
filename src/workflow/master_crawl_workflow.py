"""
CrawlAgent - Master Workflow (Multi-Agent Orchestration)
Created: 2025-11-09
Updated: 2025-11-10 (LLM ì—­í•  ëª…í™•í™”)

LangGraph Master Graph: UC1 â†’ UC2 â†’ UC3 í†µí•© ì›Œí¬í”Œë¡œìš°

LLM ì‚¬ìš© ì „ëµ (2-Agent System):
=======================================
UC1 (Quality Validation): LLM ì—†ìŒ (ê·œì¹™ ê¸°ë°˜)
  - ì‹¤í–‰ ì‹œê°„: ~100ms
  - í’ˆì§ˆ ê²€ì¦ë§Œ ìˆ˜í–‰

UC2 (Self-Healing): 2-Agent Consensus
  - Agent 1: GPT-4o-mini (Proposer) - CSS Selector ì œì•ˆ
  - Agent 2: Gemini-2.0-flash (Validator) - Selector ê²€ì¦
  - Weighted Consensus: GPT 30% + Gemini 30% + Extraction 40%
  - Threshold: 0.6

UC3 (New Site Discovery): 1-Agent
  - Agent: GPT-4o (Discoverer) - DOM ë¶„ì„ + Selector ìƒì„±
  - Confidence: 0.0 ~ 1.0

ê³µì‹ LangGraph íŒ¨í„´ ì‚¬ìš©:
=======================================
1. Agent Supervisor Pattern (LangGraph ê³µì‹)
   - Supervisorê°€ UC1/UC2/UC3ë¥¼ ì¡°ê±´ë¶€ ë¼ìš°íŒ…
   - ê° Use Caseë³„ ì „ë¬¸ Agent ì—­í•  ë¶„ë‹´

2. Conditional Edges (LangGraph ê³µì‹ API)
   - add_conditional_edges() ë©”ì„œë“œ ì‚¬ìš©
   - State ê¸°ë°˜ ë™ì  ë¼ìš°íŒ…

3. Command API (2025ë…„ ì‹ ê·œ)
   - Command(update={...}, goto="next_node")
   - State ì—…ë°ì´íŠ¸ì™€ ë¼ìš°íŒ…ì„ ë™ì‹œì— ìˆ˜í–‰
   - ë” ì§ê´€ì ì¸ ë©€í‹° ì—ì´ì „íŠ¸ í†µì‹ 

ì•„í‚¤í…ì²˜:
==========

    START
      â†“
  supervisor (UC1/UC2/UC3 ë¼ìš°íŒ… ê²°ì •)
      â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  uc1_validation â”‚ (Quality Check)
    â”‚  uc2_self_heal  â”‚ (2-Agent Consensus)
    â”‚  uc3_new_site   â”‚ (New Site Discovery)
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
  supervisor (ë‹¤ìŒ ì•¡ì…˜ ê²°ì •)
      â†“
    END


ì›Œí¬í”Œë¡œìš° ì‹œë‚˜ë¦¬ì˜¤:
==================

ì‹œë‚˜ë¦¬ì˜¤ 1: UC1 ì„±ê³µ (ì •ìƒ í¬ë¡¤ë§)
  START â†’ supervisor â†’ uc1_validation (ì„±ê³µ) â†’ supervisor â†’ END

ì‹œë‚˜ë¦¬ì˜¤ 2: UC1 ì‹¤íŒ¨ â†’ UC2 ìë™ íŠ¸ë¦¬ê±° (Self-Healing)
  START â†’ supervisor â†’ uc1_validation (3íšŒ ì‹¤íŒ¨) â†’ supervisor â†’ uc2_self_heal â†’ supervisor â†’ END

ì‹œë‚˜ë¦¬ì˜¤ 3: ìƒˆë¡œìš´ ì‚¬ì´íŠ¸ ë°œê²¬ ì‹œ UC3 íŠ¸ë¦¬ê±°
  START â†’ supervisor â†’ uc3_new_site â†’ supervisor â†’ END


PoC ë²”ìœ„:
=========
- LangGraph Multi-Agent ìë™í™” ê²€ì¦
- LangGraph Studioë¥¼ í†µí•œ ì›Œí¬í”Œë¡œìš° ì‹œê°í™”
- Gradio UIë¡œ ì‹¤í–‰ ê²°ê³¼ í™•ì¸
- DBì— ë¡œê·¸ ê¸°ë¡ (DecisionLog, CrawlResult ë“±)

Production ë²”ìœ„ (PoC ì œì™¸):
==========================
- Slack ì•Œë¦¼ ì—°ë™
- FastAPI Webhook ì„œë²„
- ì‹¤ì‹œê°„ ì•Œë¦¼ ì‹œìŠ¤í…œ
"""

import json
import os
import time
from datetime import datetime
from typing import Literal, Optional, TypedDict

# LangChain imports for Supervisor LLM
from langchain_openai import ChatOpenAI
from langgraph.graph import END, StateGraph
from langgraph.types import Command
from loguru import logger
from typing_extensions import Annotated

# Phase 1 Safety: Loop detection (Rule-based Supervisorì—ì„œ ì§ì ‘ êµ¬í˜„)
MAX_LOOP_REPEATS = 3  # ë™ì¼ UC ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜


# ============================================================================
# Master State Definition
# ============================================================================


class MasterCrawlState(TypedDict):
    """
    Master Workflowì˜ State ì •ì˜

    ëª¨ë“  Use Case (UC1/UC2/UC3)ì—ì„œ ê³µí†µìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” State
    ê° UCëŠ” ìì‹ ì˜ Stateë¥¼ ì´ Master Stateì˜ ì„œë¸Œì…‹ìœ¼ë¡œ ì‚¬ìš©
    """

    # === ì…ë ¥ ë°ì´í„° ===
    url: str
    """í¬ë¡¤ë§ ëŒ€ìƒ URL"""

    site_name: str
    """ì‚¬ì´íŠ¸ ì´ë¦„ (ì˜ˆ: 'yonhap', 'bbc', 'cnn')"""

    html_content: Optional[str]
    """fetchí•œ HTML ì›ë³¸"""

    # === ì›Œí¬í”Œë¡œìš° ì œì–´ ===
    current_uc: Optional[Literal["uc1", "uc2", "uc3"]]
    """í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ Use Case"""

    next_action: Optional[Literal["uc1", "uc2", "uc3", "end"]]
    """ë‹¤ìŒì— ì‹¤í–‰í•  Use Case"""

    failure_count: int
    """UC1 ì—°ì† ì‹¤íŒ¨ íšŸìˆ˜ (3íšŒ ì‹¤íŒ¨ ì‹œ UC2 íŠ¸ë¦¬ê±°)"""

    # === UC1 ê²°ê³¼ ===
    quality_passed: Optional[bool]
    """UC1 í’ˆì§ˆ ê²€ì¦ í†µê³¼ ì—¬ë¶€ (Supervisorê°€ í™•ì¸í•˜ëŠ” í”Œë˜ê·¸)"""

    extracted_title: Optional[str]
    """UC1ì—ì„œ ì¶”ì¶œí•œ ì œëª© (ì „ì²´, DB ì €ì¥ìš©)"""

    extracted_body: Optional[str]
    """UC1ì—ì„œ ì¶”ì¶œí•œ ë³¸ë¬¸ (ì „ì²´, DB ì €ì¥ìš©)"""

    extracted_date: Optional[str]
    """UC1ì—ì„œ ì¶”ì¶œí•œ ë‚ ì§œ (ì „ì²´, DB ì €ì¥ìš©)"""

    uc1_validation_result: Optional[dict]
    """
    UC1 Quality Validation ê²°ê³¼
    {
        "quality_passed": True/False,
        "gpt_analysis": {...},
        "extracted_data": {...}
    }
    """

    # === UC2 ê²°ê³¼ ===
    uc2_consensus_result: Optional[dict]
    """
    UC2 Self-Healing ê²°ê³¼
    {
        "consensus_reached": True/False,
        "consensus_score": 0.85,
        "proposed_selectors": {...},
        "gpt_analysis": {...},
        "gpt_validation": {...}
    }
    """

    # === UC3 ê²°ê³¼ ===
    uc3_discovery_result: Optional[dict]
    """
    UC3 New Site Discovery ê²°ê³¼
    {
        "selectors_discovered": {...},
        "confidence": 0.90,
        "claude_analysis": {...}
    }
    """

    # === ìµœì¢… ì¶œë ¥ ===
    final_result: Optional[dict]
    """ìµœì¢… í¬ë¡¤ë§ ê²°ê³¼ (DB ì €ì¥ìš©)"""

    error_message: Optional[str]
    """ì—ëŸ¬ ë°œìƒ ì‹œ ë©”ì‹œì§€"""

    workflow_history: list[str]
    """ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ íˆìŠ¤í† ë¦¬ (ë””ë²„ê¹…/ëª¨ë‹ˆí„°ë§ìš©)"""

    # === Supervisor LLM ê´€ë ¨ (NEW) ===
    supervisor_reasoning: Optional[str]
    """Supervisorì˜ ë¼ìš°íŒ… ê²°ì • ì´ìœ  (GPT-4o-mini ì¶”ë¡  ê²°ê³¼)"""

    supervisor_confidence: Optional[float]
    """Supervisorì˜ ê²°ì • ì‹ ë¢°ë„ (0.0-1.0)"""

    routing_context: Optional[dict]
    """
    ë¼ìš°íŒ… ì»¨í…ìŠ¤íŠ¸ (ì˜¤ë¥˜ íŒ¨í„´, íˆìŠ¤í† ë¦¬ ë¶„ì„ ë“±)
    {
        "timestamp": "...",
        "decision": "uc1_validation" | "uc2_self_heal" | "uc3_new_site" | "END",
        "state_snapshot": {...}
    }
    """


# ============================================================================
# Supervisor Node (Agent Supervisor Pattern - ê³µì‹ LangGraph íŒ¨í„´)
# ============================================================================


def supervisor_node(
    state: MasterCrawlState,
) -> Command[Literal["uc1_validation", "uc2_self_heal", "uc3_new_site", "__end__"]]:
    """
    Supervisor Agent: UC1/UC2/UC3 ë¼ìš°íŒ… ê²°ì •

    ê³µì‹ LangGraph Agent Supervisor Pattern ì‚¬ìš©:
    - Supervisorê°€ í˜„ì¬ Stateë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ Agent ê²°ì •
    - Command APIë¡œ State ì—…ë°ì´íŠ¸ + ë¼ìš°íŒ…ì„ ë™ì‹œì— ìˆ˜í–‰

    ë¼ìš°íŒ… ë¡œì§:
    1. ìµœì´ˆ ì§„ì… ì‹œ â†’ UC1 (Quality Validation)
    2. UC1 3íšŒ ì—°ì† ì‹¤íŒ¨ â†’ UC2 (Self-Healing)
    3. ìƒˆë¡œìš´ ì‚¬ì´íŠ¸ ë°œê²¬ ì‹œ â†’ UC3 (New Site Discovery)
    4. ëª¨ë“  ì‘ì—… ì™„ë£Œ ì‹œ â†’ END

    Args:
        state: MasterCrawlState

    Returns:
        Command: State ì—…ë°ì´íŠ¸ + goto ë¼ìš°íŒ…
    """
    logger.info("[Supervisor] ğŸ¯ Routing decision started")

    # Check if Distributed Supervisor is enabled (SPOF í•´ê²°)
    use_distributed = os.getenv("USE_DISTRIBUTED_SUPERVISOR", "false").lower() == "true"

    if use_distributed:
        # Distributed 3-Model Voting (GPT-4o + Claude + Gemini)
        from src.workflow.distributed_supervisor import distributed_supervisor_decision

        logger.info("[Supervisor] ğŸš€ Using Distributed 3-Model Voting (SPOF í•´ê²°)...")

        decision_result = distributed_supervisor_decision(state)

        next_uc = decision_result["next_uc"]
        confidence = decision_result["confidence"]
        reasoning = decision_result["reasoning"]
        fault_tolerance_used = decision_result["fault_tolerance_used"]

        logger.info(
            f"[Supervisor] âœ… Distributed decision: {next_uc} (conf={confidence:.2f}, FT={fault_tolerance_used})"
        )

        # Convert distributed decision to goto target
        goto_map = {
            "uc1": "uc1_validation",
            "uc2": "uc2_self_heal",
            "uc3": "uc3_new_site",
            "end": END,
        }

        history = state.get("workflow_history", [])
        return Command(
            update={
                "supervisor_reasoning": reasoning,
                "supervisor_confidence": confidence,
                "routing_context": {
                    "mode": "distributed",
                    "individual_votes": decision_result.get("individual_votes", []),
                    "fault_tolerance_used": fault_tolerance_used,
                },
                "workflow_history": history
                + [f"supervisor (distributed) â†’ {next_uc} (conf={confidence:.2f})"],
            },
            goto=goto_map.get(next_uc, END),
        )

    # Rule-based routing (default)
    # ì›Œí¬í”Œë¡œìš° íˆìŠ¤í† ë¦¬ ì¶”ê°€
    history = state.get("workflow_history", [])
    current_uc = state.get("current_uc")
    next_action = state.get("next_action")
    failure_count = state.get("failure_count", 0)

    # 1. ìµœì´ˆ ì§„ì… ì‹œ: HTML Fetch + UC1 ì‹œì‘
    if not current_uc:
        logger.info("[Supervisor] ğŸ“ Initial entry â†’ Fetching HTML â†’ Routing to UC1")

        # HTML Download (UC3 ë¡œì§ ì¬ì‚¬ìš©)
        import requests

        from src.utils.site_detector import extract_site_name

        url = state["url"]
        html_content = None
        site_name = state.get("site_name")

        try:
            logger.info(f"[Supervisor] ğŸŒ Downloading HTML: {url}")

            # Enhanced headers to bypass bot detection (NYT, WSJ, etc.)
            headers = {
                "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
                "Accept-Language": "en-US,en;q=0.9,ko;q=0.8",
                "Accept-Encoding": "gzip, deflate, br",
                "DNT": "1",
                "Connection": "keep-alive",
                "Upgrade-Insecure-Requests": "1",
                "Sec-Fetch-Dest": "document",
                "Sec-Fetch-Mode": "navigate",
                "Sec-Fetch-Site": "none",
                "Sec-Fetch-User": "?1",
                "Cache-Control": "max-age=0",
            }

            response = requests.get(url, timeout=10, headers=headers)
            response.raise_for_status()
            html_content = response.text

            # site_nameì´ ì—†ìœ¼ë©´ URLì—ì„œ ì¶”ì¶œ
            if not site_name:
                site_name = extract_site_name(url)

            logger.info(
                f"[Supervisor] âœ… HTML downloaded: {len(html_content)} chars, site={site_name}"
            )

        except Exception as e:
            logger.error(f"[Supervisor] âŒ HTML fetch failed: {e}")
            # HTML fetch ì‹¤íŒ¨ ì‹œ UC3ë¡œ ë¼ìš°íŒ… (UC3ëŠ” ìì²´ fetch ê°€ëŠ¥)
            return Command(
                update={
                    "current_uc": "uc3",
                    "next_action": "uc3",
                    "site_name": site_name,
                    "error_message": f"HTML fetch failed: {str(e)}",
                    "workflow_history": history
                    + [f"supervisor â†’ uc3_discovery (HTML fetch error)"],
                },
                goto="uc3_discovery",
            )

        return Command(
            update={
                "current_uc": "uc1",
                "next_action": "uc1",
                "html_content": html_content,
                "site_name": site_name,
                "workflow_history": history + ["supervisor â†’ uc1_validation (HTML fetched)"],
            },
            goto="uc1_validation",
        )

    # 2. UC1 ì™„ë£Œ í›„ íŒë‹¨ (Multi-Agent Orchestration íŒ¨í„´)
    if current_uc == "uc1":
        uc1_result = state.get("uc1_validation_result")
        quality_passed = state.get("quality_passed", False)

        logger.debug(
            f"[Supervisor] UC1 ì™„ë£Œ: quality_passed={quality_passed}, uc1_result={uc1_result is not None}"
        )

        # UC1 ì„±ê³µ â†’ DB ì €ì¥ í›„ ì¢…ë£Œ
        if quality_passed:
            quality_score = uc1_result.get("quality_score", 0) if uc1_result else 0
            logger.info(
                f"[Supervisor] âœ… UC1 passed (score={quality_score}) â†’ Saving to DB â†’ Workflow END"
            )

            # DB ì €ì¥ ë¡œì§
            try:
                from datetime import datetime

                from src.storage.database import get_db
                from src.storage.models import CrawlResult

                db = next(get_db())

                # ì¶”ì¶œëœ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (Master Stateì—ì„œ ì§ì ‘ ê°€ì ¸ì˜´)
                title = state.get("extracted_title")
                body = state.get("extracted_body")
                date_str = state.get("extracted_date")

                # CrawlResult ìƒì„±
                crawl_result = CrawlResult(
                    url=state["url"],
                    site_name=state["site_name"],
                    category=None,  # Gradioì—ì„œëŠ” ì¹´í…Œê³ ë¦¬ ì—†ìŒ
                    category_kr=None,
                    title=title,
                    body=body,
                    date=date_str,
                    quality_score=quality_score,
                    crawl_mode="2-agent",  # Master WorkflowëŠ” 2-agent ëª¨ë“œ
                    crawl_duration_seconds=None,
                    content_type="news",
                    validation_status="verified",
                    validation_method="2-agent",
                    llm_reasoning=f"UC1 Quality Validation passed with score {quality_score}",
                )

                # DBì— ì €ì¥ (ì¤‘ë³µ ì²´í¬: URLì´ unique key)
                existing = db.query(CrawlResult).filter(CrawlResult.url == state["url"]).first()
                if existing:
                    logger.warning(
                        f"[Supervisor] URL already exists in DB, updating: {state['url']}"
                    )
                    existing.title = title
                    existing.body = body
                    existing.date = date_str
                    existing.quality_score = quality_score
                    existing.validation_status = "verified"
                    existing.llm_reasoning = (
                        f"UC1 Quality Validation passed with score {quality_score}"
                    )
                else:
                    db.add(crawl_result)

                db.commit()
                logger.info(f"[Supervisor] ğŸ’¾ CrawlResult saved to DB: {state['url']}")

                # Selector success_count ì¦ê°€
                from src.storage.models import Selector

                selector = (
                    db.query(Selector).filter(Selector.site_name == state["site_name"]).first()
                )
                if selector:
                    selector.success_count += 1
                    db.commit()
                    logger.info(
                        f"[Supervisor] ğŸ“ˆ Selector success_count incremented: {state['site_name']}"
                    )

            except Exception as e:
                logger.error(f"[Supervisor] âŒ Failed to save CrawlResult to DB: {e}")
                # DB ì €ì¥ ì‹¤íŒ¨í•´ë„ ì›Œí¬í”Œë¡œìš°ëŠ” ê³„ì† ì§„í–‰ (ë‚˜ì¤‘ì— ì¬ì‹œë„ ê°€ëŠ¥)

            return Command(
                update={
                    "next_action": "end",
                    "final_result": {
                        "title": title,
                        "body": body,
                        "date": date_str,
                        "quality_score": quality_score,
                    },
                    "workflow_history": history
                    + [f"supervisor â†’ DB_SAVED â†’ END (UC1 success, score={quality_score})"],
                },
                goto=END,
            )

        # UC1 ì‹¤íŒ¨ â†’ next_action í™•ì¸í•˜ì—¬ UC2 ë˜ëŠ” UC3ë¡œ ë¼ìš°íŒ…
        if uc1_result:
            uc1_next_action = uc1_result.get("next_action")
            quality_score = uc1_result.get("quality_score", 0)
            current_failure_count = state.get("failure_count", 0)

            # Loop Detection: UC1 ì—°ì† ì‹¤íŒ¨ 3íšŒ ì´ˆê³¼ ì‹œ ê°•ì œ ì¢…ë£Œ
            if current_failure_count >= 3:
                logger.error(
                    f"[Supervisor] ğŸ›‘ Loop Detection: UC1 failed {current_failure_count} times â†’ Force END"
                )
                return Command(
                    update={
                        "next_action": "end",
                        "error_message": f"Loop detected: UC1 failed {current_failure_count} consecutive times",
                        "workflow_history": history
                        + [f"supervisor â†’ END (Loop Detection: {current_failure_count} failures)"],
                    },
                    goto=END,
                )

            # UC2 Self-Healing ë¼ìš°íŒ…
            if uc1_next_action == "heal":
                logger.info(
                    f"[Supervisor] ğŸ”„ UC1 failed (score={quality_score}, failure={current_failure_count + 1}/3) â†’ Routing to UC2 (Self-Healing)"
                )
                return Command(
                    update={
                        "current_uc": "uc2",
                        "next_action": "uc2",
                        "failure_count": current_failure_count + 1,  # ì‹¤íŒ¨ ì¹´ìš´í„° ì¦ê°€
                        "workflow_history": history
                        + [
                            f"supervisor â†’ uc2_self_heal (UC1 score={quality_score}, failures={current_failure_count + 1})"
                        ],
                    },
                    goto="uc2_self_heal",
                )

            # UC3 Discovery ë¼ìš°íŒ…
            elif uc1_next_action == "uc3":
                logger.info(
                    f"[Supervisor] ğŸ” UC1 failed (score={quality_score}) â†’ Routing to UC3 (New Site Discovery)"
                )
                return Command(
                    update={
                        "current_uc": "uc3",
                        "next_action": "uc3",
                        "failure_count": current_failure_count + 1,  # ì‹¤íŒ¨ ì¹´ìš´í„° ì¦ê°€
                        "workflow_history": history
                        + [
                            f"supervisor â†’ uc3_new_site (UC1 score={quality_score}, failures={current_failure_count + 1})"
                        ],
                    },
                    goto="uc3_new_site",
                )

            # next_actionì´ "save"ì¸ë° quality_passed=Falseì¸ ê²½ìš° (ë¹„ì •ìƒ)
            else:
                logger.warning(
                    f"[Supervisor] âš ï¸ UC1 result inconsistent (passed=False, action={uc1_next_action}) â†’ END"
                )
                return Command(
                    update={
                        "next_action": "end",
                        "error_message": f"UC1 inconsistent state: passed=False but action={uc1_next_action}",
                        "workflow_history": history + [f"supervisor â†’ END (UC1 inconsistent)"],
                    },
                    goto=END,
                )

        # uc1_resultê°€ ì—†ëŠ” ê²½ìš° (ë¹„ì •ìƒ)
        logger.error("[Supervisor] âŒ UC1 completed but no result found â†’ END")
        return Command(
            update={
                "next_action": "end",
                "error_message": "UC1 completed but no result found (internal error)",
                "workflow_history": history + ["supervisor â†’ END (UC1 no result)"],
            },
            goto=END,
        )

    # 3. UC2 ì™„ë£Œ í›„ íŒë‹¨
    if current_uc == "uc2":
        uc2_result = state.get("uc2_consensus_result")

        # UC2 í•©ì˜ ì„±ê³µ â†’ Selector UPDATE + DecisionLog INSERT â†’ UC1 ë³µê·€
        if uc2_result and uc2_result.get("consensus_reached"):
            consensus_score = uc2_result.get("consensus_score", 0.0)
            logger.info(
                f"[Supervisor] âœ… UC2 consensus reached (score={consensus_score:.2f}) "
                f"â†’ Updating Selector â†’ Return to UC1"
            )

            # DB ì €ì¥ ë¡œì§
            try:
                from datetime import datetime

                from src.storage.database import get_db
                from src.storage.models import DecisionLog, Selector

                db = next(get_db())

                # 1. Selector UPDATE
                proposed_selectors = uc2_result.get("proposed_selectors", {})
                if proposed_selectors:
                    selector = (
                        db.query(Selector).filter(Selector.site_name == state["site_name"]).first()
                    )
                    if selector:
                        # ê¸°ì¡´ Selector ì—…ë°ì´íŠ¸
                        selector.title_selector = proposed_selectors.get(
                            "title_selector", selector.title_selector
                        )
                        selector.body_selector = proposed_selectors.get(
                            "body_selector", selector.body_selector
                        )
                        selector.date_selector = proposed_selectors.get(
                            "date_selector", selector.date_selector
                        )
                        selector.updated_at = datetime.utcnow()
                        logger.info(f"[Supervisor] ğŸ“ Selector updated for {state['site_name']}")
                    else:
                        # Selectorê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„± (UC2ê°€ ì‹¤í–‰ë˜ì—ˆë‹¤ëŠ” ê²ƒì€ selectorê°€ ìˆì–´ì•¼ í•˜ì§€ë§Œ ë°©ì–´ ë¡œì§)
                        new_selector = Selector(
                            site_name=state["site_name"],
                            title_selector=proposed_selectors.get("title_selector", ""),
                            body_selector=proposed_selectors.get("body_selector", ""),
                            date_selector=proposed_selectors.get("date_selector", ""),
                            site_type="ssr",
                        )
                        db.add(new_selector)
                        logger.info(
                            f"[Supervisor] â• New Selector created for {state['site_name']}"
                        )

                # 2. DecisionLog INSERT
                decision_log = DecisionLog(
                    url=state["url"],
                    site_name=state["site_name"],
                    gpt_analysis=uc2_result.get("gpt_analysis"),
                    gpt4o_validation=uc2_result.get("gpt_validation"),
                    consensus_reached=True,
                    retry_count=uc2_result.get("retry_count", 0),
                    created_at=datetime.utcnow(),
                )
                db.add(decision_log)

                db.commit()
                logger.info(
                    f"[Supervisor] ğŸ’¾ DecisionLog saved: UC2 consensus reached (score={consensus_score:.2f})"
                )

            except Exception as e:
                logger.error(f"[Supervisor] âŒ Failed to save UC2 results to DB: {e}")
                # DB ì €ì¥ ì‹¤íŒ¨í•´ë„ ì›Œí¬í”Œë¡œìš°ëŠ” ê³„ì† ì§„í–‰

            return Command(
                update={
                    "current_uc": "uc1",
                    "next_action": "uc1",
                    "failure_count": 0,  # ì‹¤íŒ¨ ì¹´ìš´í„° ë¦¬ì…‹
                    "workflow_history": history
                    + [
                        f"supervisor â†’ SELECTOR_UPDATED â†’ uc1_validation (UC2 consensus {consensus_score:.2f})"
                    ],
                },
                goto="uc1_validation",
            )

        # UC2 í•©ì˜ ì‹¤íŒ¨ â†’ DecisionLog INSERT í›„ ì¢…ë£Œ (ê´€ë¦¬ì ìˆ˜ë™ í™•ì¸ í•„ìš”)
        else:
            consensus_score = uc2_result.get("consensus_score", 0.0) if uc2_result else 0.0
            logger.warning(
                f"[Supervisor] âŒ UC2 consensus failed (score={consensus_score:.2f}) "
                f"â†’ Saving DecisionLog â†’ Workflow END"
            )

            # DB ì €ì¥ ë¡œì§ (ì‹¤íŒ¨ ì¼€ì´ìŠ¤ë„ ê¸°ë¡)
            try:
                from datetime import datetime

                from src.storage.database import get_db
                from src.storage.models import DecisionLog, Selector

                db = next(get_db())

                # DecisionLog INSERT (ì‹¤íŒ¨ ì¼€ì´ìŠ¤)
                decision_log = DecisionLog(
                    url=state["url"],
                    site_name=state["site_name"],
                    gpt_analysis=uc2_result.get("gpt_analysis") if uc2_result else None,
                    gpt4o_validation=uc2_result.get("gpt_validation") if uc2_result else None,
                    consensus_reached=False,
                    retry_count=uc2_result.get("retry_count", 0) if uc2_result else 0,
                    created_at=datetime.utcnow(),
                )
                db.add(decision_log)

                # Selector failure_count ì¦ê°€
                selector = (
                    db.query(Selector).filter(Selector.site_name == state["site_name"]).first()
                )
                if selector:
                    selector.failure_count += 1
                    logger.info(
                        f"[Supervisor] ğŸ“‰ Selector failure_count incremented: {state['site_name']}"
                    )

                db.commit()
                logger.info(
                    f"[Supervisor] ğŸ’¾ DecisionLog saved: UC2 consensus failed (score={consensus_score:.2f})"
                )

            except Exception as e:
                logger.error(f"[Supervisor] âŒ Failed to save UC2 failure to DB: {e}")

            return Command(
                update={
                    "next_action": "end",
                    "error_message": f"UC2 consensus failed (score={consensus_score:.2f})",
                    "workflow_history": history
                    + [
                        f"supervisor â†’ DECISION_LOG_SAVED â†’ END (UC2 consensus failed {consensus_score:.2f})"
                    ],
                },
                goto=END,
            )

    # 4. UC3 ì™„ë£Œ í›„ íŒë‹¨
    if current_uc == "uc3":
        uc3_result = state.get("uc3_discovery_result")

        # UC3 ì„±ê³µ â†’ Selector INSERT â†’ ì¢…ë£Œ
        if uc3_result and uc3_result.get("selectors_discovered"):
            confidence = uc3_result.get("confidence", 0.0)
            logger.info(
                f"[Supervisor] âœ… UC3 new site discovered (confidence={confidence:.2f}) "
                f"â†’ Saving Selector to DB â†’ Workflow END"
            )

            # DB ì €ì¥ ë¡œì§
            try:
                from datetime import datetime

                from src.storage.database import get_db
                from src.storage.models import Selector

                db = next(get_db())

                # Selector INSERT
                discovered_selectors = uc3_result.get("selectors_discovered", {})
                if discovered_selectors:
                    # ê¸°ì¡´ Selectorê°€ ìˆëŠ”ì§€ í™•ì¸ (ì¤‘ë³µ ë°©ì§€)
                    existing_selector = (
                        db.query(Selector).filter(Selector.site_name == state["site_name"]).first()
                    )
                    if existing_selector:
                        logger.warning(
                            f"[Supervisor] Selector already exists for {state['site_name']}, updating instead"
                        )
                        # UC3ëŠ” title/body/date í‚¤ë¡œ ë°˜í™˜, title_selector/body_selector/date_selectorë„ fallback ì§€ì›
                        existing_selector.title_selector = discovered_selectors.get(
                            "title", discovered_selectors.get("title_selector", "")
                        )
                        existing_selector.body_selector = discovered_selectors.get(
                            "body", discovered_selectors.get("body_selector", "")
                        )
                        existing_selector.date_selector = discovered_selectors.get(
                            "date", discovered_selectors.get("date_selector", "")
                        )
                        existing_selector.updated_at = datetime.utcnow()
                        logger.info(
                            f"[Supervisor] ğŸ“ Existing Selector updated for {state['site_name']}"
                        )
                    else:
                        # ìƒˆë¡œìš´ Selector ìƒì„±
                        # UC3ëŠ” title/body/date í‚¤ë¡œ ë°˜í™˜, title_selector/body_selector/date_selectorë„ fallback ì§€ì›
                        new_selector = Selector(
                            site_name=state["site_name"],
                            title_selector=discovered_selectors.get(
                                "title", discovered_selectors.get("title_selector", "")
                            ),
                            body_selector=discovered_selectors.get(
                                "body", discovered_selectors.get("body_selector", "")
                            ),
                            date_selector=discovered_selectors.get(
                                "date", discovered_selectors.get("date_selector", "")
                            ),
                            site_type="ssr",
                            success_count=0,
                            failure_count=0,
                        )
                        db.add(new_selector)
                        logger.info(
                            f"[Supervisor] â• New Selector created for {state['site_name']}"
                        )

                    db.commit()
                    logger.info(
                        f"[Supervisor] ğŸ’¾ Selector saved: UC3 discovery (confidence={confidence:.2f})"
                    )

            except Exception as e:
                logger.error(f"[Supervisor] âŒ Failed to save UC3 Selector to DB: {e}")

            # UC3 ì™„ë£Œ í›„ UC1 ì¬ì‹¤í–‰í•˜ì—¬ ë°ì´í„° ìˆ˜ì§‘
            logger.info(
                f"[Supervisor] ğŸ”„ UC3 Discovery completed â†’ Routing to UC1 for data collection"
            )
            return Command(
                update={
                    "current_uc": "uc1",
                    "failure_count": 0,  # Reset failure count
                    "workflow_history": history
                    + [f"supervisor â†’ SELECTOR_SAVED â†’ uc1_validation (UC3 success {confidence:.2f})"],
                },
                goto="uc1_validation",
            )

        # UC3 ì‹¤íŒ¨ â†’ ì¢…ë£Œ
        else:
            confidence = uc3_result.get("confidence", 0.0) if uc3_result else 0.0
            logger.warning(
                f"[Supervisor] âŒ UC3 failed (confidence={confidence:.2f}) â†’ Workflow END"
            )
            return Command(
                update={
                    "next_action": "end",
                    "error_message": f"UC3 new site discovery failed (confidence={confidence:.2f} < 0.7)",
                    "workflow_history": history
                    + [f"supervisor â†’ END (UC3 failed, confidence={confidence:.2f})"],
                },
                goto=END,
            )

    # 5. ëª…ì‹œì ì¸ next_actionì´ ìˆëŠ” ê²½ìš° (ì™¸ë¶€ì—ì„œ ì§€ì •)
    if next_action == "uc1":
        logger.info("[Supervisor] ğŸ“ Explicit routing â†’ UC1")
        return Command(
            update={
                "current_uc": "uc1",
                "workflow_history": history + ["supervisor â†’ uc1_validation (explicit)"],
            },
            goto="uc1_validation",
        )
    elif next_action == "uc2":
        logger.info("[Supervisor] ğŸ“ Explicit routing â†’ UC2")
        return Command(
            update={
                "current_uc": "uc2",
                "workflow_history": history + ["supervisor â†’ uc2_self_heal (explicit)"],
            },
            goto="uc2_self_heal",
        )
    elif next_action == "uc3":
        logger.info("[Supervisor] ğŸ“ Explicit routing â†’ UC3")
        return Command(
            update={
                "current_uc": "uc3",
                "workflow_history": history + ["supervisor â†’ uc3_new_site (explicit)"],
            },
            goto="uc3_new_site",
        )
    elif next_action == "end":
        logger.info("[Supervisor] ğŸ“ Explicit routing â†’ END")
        return Command(
            update={"workflow_history": history + ["supervisor â†’ END (explicit)"]}, goto=END
        )

    # 6. ê¸°ë³¸ê°’: ì¢…ë£Œ
    logger.info("[Supervisor] ğŸ“ Default routing â†’ END")
    return Command(
        update={"next_action": "end", "workflow_history": history + ["supervisor â†’ END (default)"]},
        goto=END,
    )


# ============================================================================
# UC1 Node Wrapper (ê¸°ì¡´ UC1 ì›Œí¬í”Œë¡œìš° í˜¸ì¶œ)
# ============================================================================

from src.workflow.uc1_validation import ValidationState, create_uc1_validation_agent


def uc1_validation_node(state: MasterCrawlState) -> Command[Literal["supervisor"]]:
    """
    UC1 Quality Validation Node

    ê¸°ì¡´ UC1 LangGraph ì›Œí¬í”Œë¡œìš°ë¥¼ í˜¸ì¶œí•˜ì—¬ í’ˆì§ˆ ê²€ì¦ ìˆ˜í–‰

    Command API ì‚¬ìš©:
    - ê¸°ì¡´ UC1 ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    - ê²°ê³¼ë¥¼ Master Stateì— ì—…ë°ì´íŠ¸
    - supervisorë¡œ ë‹¤ì‹œ ë¼ìš°íŒ…

    Args:
        state: MasterCrawlState

    Returns:
        Command: UC1 ê²°ê³¼ ì—…ë°ì´íŠ¸ + supervisorë¡œ ë¼ìš°íŒ…
    """
    logger.info("[UC1 Node] ğŸ” Quality Validation started")

    try:
        # 1. HTMLì—ì„œ title, body, date ì¶”ì¶œ (UC1ì€ ì¶”ì¶œëœ ë°ì´í„°ë¥¼ ê²€ì¦)
        import trafilatura
        from bs4 import BeautifulSoup

        from src.storage.database import get_db
        from src.storage.models import Selector

        html_content = state.get("html_content", "")
        site_name = state["site_name"]

        # DBì—ì„œ CSS Selector ê°€ì ¸ì˜¤ê¸°
        db = next(get_db())
        selector_record = db.query(Selector).filter(Selector.site_name == site_name).first()

        # Selectorê°€ ì—†ìœ¼ë©´ ë¹ˆ ë°ì´í„°ë¡œ UC1ì— ì „ë‹¬ (UC3 ì¼€ì´ìŠ¤)
        if not selector_record:
            logger.warning(
                f"[UC1 Node] No Selector found for {site_name} â†’ Will extract empty data â†’ UC1 will fail â†’ UC3 Discovery"
            )
            # UC1ì— ë¹ˆ ë°ì´í„° ì „ë‹¬
            uc1_state: ValidationState = {
                "url": state["url"],
                "site_name": state["site_name"],
                "title": None,
                "body": None,
                "date": None,
                "quality_score": 0,
                "missing_fields": [],
                "next_action": "save",
                "uc2_triggered": False,
                "uc2_success": False,
            }

            uc1_graph = create_uc1_validation_agent()
            uc1_result = uc1_graph.invoke(uc1_state)

            quality_score = uc1_result.get("quality_score", 0)
            next_action = uc1_result.get("next_action", "uc3")
            quality_passed = uc1_result.get("quality_passed", False)
            uc1_validation_result = uc1_result.get("uc1_validation_result", {})

            logger.info(
                f"[UC1 Node] âœ… No Selector case: score={quality_score}, next_action={next_action} (expected: uc3)"
            )

            return Command(
                update={
                    "quality_passed": False,
                    "uc1_validation_result": (
                        uc1_validation_result
                        if uc1_validation_result
                        else {
                            "quality_passed": False,
                            "quality_score": quality_score,
                            "next_action": next_action,
                            "missing_fields": ["title", "body", "date"],
                            "extracted_data": {"title": None, "body": None, "date": None},
                        }
                    ),
                    "current_uc": "uc1",
                    "workflow_history": state.get("workflow_history", [])
                    + [f"uc1_validation â†’ supervisor (no selector, score={quality_score})"],
                },
                goto="supervisor",
            )

        soup = BeautifulSoup(html_content, "html.parser")

        # Selector Health Check: CSS Selectorê°€ ì‹¤ì œë¡œ ìš”ì†Œë¥¼ ì°¾ëŠ”ì§€ ê²€ì¦
        selector_health = {
            "title_valid": False,
            "body_valid": False,
            "date_valid": False,
        }

        # Title ì¶”ì¶œ + Health Check
        title = None
        title_from_fallback = False
        if selector_record.title_selector:
            try:
                title_elem = soup.select_one(selector_record.title_selector)
                if title_elem:
                    title = title_elem.get_text(strip=True)
                    selector_health["title_valid"] = True  # Selector ìœ íš¨
                else:
                    logger.warning(f"[UC1 Node] Title selector found no elements: {selector_record.title_selector}")
            except Exception as e:
                logger.warning(f"[UC1 Node] Title extraction failed: {e}")

        # Fallback: meta tag (UC2 Demo Modeì—ì„œëŠ” ë¹„í™œì„±í™”)
        uc2_demo_mode = os.getenv("UC2_DEMO_MODE", "false").lower() == "true"
        if not title and not uc2_demo_mode:
            meta_title = soup.select_one('meta[property="og:title"]')
            title = meta_title.get("content") if meta_title else None
            if title:
                title_from_fallback = True
                logger.debug(f"[UC1 Node] Title fallback (meta tag) succeeded")

        # Date ì¶”ì¶œ + Health Check
        date_str = None
        date_from_fallback = False
        if selector_record.date_selector:
            try:
                date_elem = soup.select_one(selector_record.date_selector)
                if date_elem:
                    date_str = date_elem.get_text(strip=True) if date_elem.name != "meta" else date_elem.get("content")
                    # Meta íƒœê·¸ëŠ” í•­ìƒ ìœ íš¨í•˜ë‹¤ê³  ê°„ì£¼ (fallbackì´ ì•„ë‹˜)
                    if selector_record.date_selector.startswith("meta"):
                        selector_health["date_valid"] = True
                    else:
                        selector_health["date_valid"] = True
                else:
                    logger.warning(f"[UC1 Node] Date selector found no elements: {selector_record.date_selector}")
            except Exception as e:
                logger.warning(f"[UC1 Node] Date extraction failed: {e}")

        # Fallback: meta tag (UC2 Demo Modeì—ì„œëŠ” ë¹„í™œì„±í™”)
        if not date_str and not uc2_demo_mode:
            meta_date = soup.select_one('meta[property="article:published_time"]')
            date_str = meta_date.get("content") if meta_date else None
            if date_str:
                date_from_fallback = True
                logger.debug(f"[UC1 Node] Date fallback (meta tag) succeeded")

        # Body ì¶”ì¶œ + Health Check
        body = None
        body_from_fallback = False

        # ë¨¼ì € CSS Selector ì‹œë„ (Health Checkìš©)
        if selector_record.body_selector:
            try:
                body_elements = soup.select(selector_record.body_selector)
                if body_elements:
                    body = " ".join([elem.get_text(strip=True) for elem in body_elements])
                    if len(body) >= 100:
                        selector_health["body_valid"] = True  # Selector ìœ íš¨
                    else:
                        logger.warning(f"[UC1 Node] Body selector found elements but text too short: {len(body)} chars")
                else:
                    logger.warning(f"[UC1 Node] Body selector found no elements: {selector_record.body_selector}")
            except Exception as e:
                logger.warning(f"[UC1 Node] Body extraction failed: {e}")

        # Fallback: Trafilatura (UC2 Demo Modeì—ì„œëŠ” ë¹„í™œì„±í™”)
        if (not body or len(body) < 100) and not uc2_demo_mode:
            body = trafilatura.extract(
                html_content,
                include_comments=False,
                include_tables=False,
                no_fallback=False,
                favor_precision=True,
                favor_recall=False,
            )
            if body and len(body) >= 100:
                body_from_fallback = True
                logger.debug(f"[UC1 Node] Body fallback (Trafilatura) succeeded: {len(body)} chars")

        # Selector Health ë¡œê¹…
        damage_count = sum(1 for v in selector_health.values() if not v)
        logger.info(
            f"[UC1 Node] Extracted: title={bool(title)}, body_len={len(body) if body else 0}, date={bool(date_str)}"
        )
        logger.info(
            f"[UC1 Node] Selector Health: title_valid={selector_health['title_valid']}, "
            f"body_valid={selector_health['body_valid']}, date_valid={selector_health['date_valid']} "
            f"(damage_count={damage_count}/3)"
        )

        # 2. UC1 Graph ë¹Œë“œ
        uc1_graph = create_uc1_validation_agent()

        # 3. Master State â†’ UC1 State ë³€í™˜ (ì¶”ì¶œëœ ë°ì´í„° ì „ë‹¬)
        uc1_state: ValidationState = {
            "url": state["url"],
            "site_name": state["site_name"],
            "title": title,
            "body": body,
            "date": date_str,
            "quality_score": 0,
            "missing_fields": [],
            "next_action": "save",
            "uc2_triggered": False,
            "uc2_success": False,
            "selector_health": selector_health,  # Selector ìœ íš¨ì„± ì •ë³´ ì „ë‹¬
        }

        # 4. UC1 ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        uc1_result = uc1_graph.invoke(uc1_state)

        # 5. ê²°ê³¼ ë¶„ì„ (UC1ì´ ì´ë¯¸ quality_passed ê³„ì‚°)
        quality_score = uc1_result.get("quality_score", 0)
        next_action = uc1_result.get("next_action", "save")
        quality_passed = uc1_result.get("quality_passed", False)  # UC1ì—ì„œ ê³„ì‚°ëœ ê°’ ì‚¬ìš©
        uc1_validation_result = uc1_result.get("uc1_validation_result", {})

        logger.info(
            f"[UC1 Node] âœ… Validation completed: quality_score={quality_score}, next_action={next_action}, passed={quality_passed}"
        )

        # 6. Master State ì—…ë°ì´íŠ¸ + supervisorë¡œ ë¼ìš°íŒ…
        return Command(
            update={
                "quality_passed": quality_passed,  # Supervisorê°€ í™•ì¸í•˜ëŠ” í”Œë˜ê·¸
                "extracted_title": title,  # ì „ì²´ ì œëª© (DB ì €ì¥ìš©)
                "extracted_body": body,  # ì „ì²´ ë³¸ë¬¸ (DB ì €ì¥ìš©)
                "extracted_date": date_str,  # ì „ì²´ ë‚ ì§œ (DB ì €ì¥ìš©)
                "uc1_validation_result": (
                    uc1_validation_result
                    if uc1_validation_result
                    else {
                        "quality_passed": quality_passed,
                        "quality_score": quality_score,
                        "next_action": next_action,
                        "missing_fields": uc1_result.get("missing_fields", []),
                        "extracted_data": {
                            "title": title,
                            "body": body[:500] if body else "",  # ì²« 500ìë§Œ ì €ì¥ (previewìš©)
                            "date": date_str,
                        },
                    }
                ),
                "current_uc": "uc1",
                "workflow_history": state.get("workflow_history", [])
                + [f"uc1_validation â†’ supervisor (score={quality_score}, passed={quality_passed})"],
            },
            goto="supervisor",
        )

    except Exception as e:
        logger.error(f"[UC1 Node] âŒ Error: {e}")

        return Command(
            update={
                "uc1_validation_result": {
                    "quality_passed": False,
                    "quality_score": 0,
                    "next_action": "uc3",  # UC1 ì—ëŸ¬ ì‹œ UC3ë¡œ ë¼ìš°íŒ…
                    "error_message": str(e),
                },
                "quality_passed": False,
                "next_action": "uc3",  # ëª…ì‹œì ìœ¼ë¡œ uc3 ì„¤ì •
                "error_message": f"UC1 failed: {str(e)}",
                "workflow_history": state.get("workflow_history", [])
                + [f"uc1_validation â†’ supervisor (ERROR: {str(e)}, next=uc3)"],
            },
            goto="supervisor",
        )


# ============================================================================
# UC2 Node Wrapper (ê¸°ì¡´ UC2 ì›Œí¬í”Œë¡œìš° í˜¸ì¶œ)
# ============================================================================

from src.workflow.uc2_hitl import HITLState, build_uc2_graph


def uc2_self_heal_node(state: MasterCrawlState) -> Command[Literal["supervisor"]]:
    """
    UC2 Self-Healing Node (2-Agent Consensus)

    ê¸°ì¡´ UC2 LangGraph ì›Œí¬í”Œë¡œìš°ë¥¼ í˜¸ì¶œí•˜ì—¬ CSS Selector ìë™ ë³µêµ¬ ìˆ˜í–‰

    Multi-Agent Consensus:
    - GPT-4o-mini: CSS Selector ì œì•ˆ (Proposer)
    - Gemini-2.0-flash: Selector ê²€ì¦ (Validator)
    - Weighted Consensus: GPT 30% + Gemini 30% + Extraction Quality 40%

    Args:
        state: MasterCrawlState

    Returns:
        Command: UC2 ê²°ê³¼ ì—…ë°ì´íŠ¸ + supervisorë¡œ ë¼ìš°íŒ…
    """
    logger.info("[UC2 Node] ğŸ”§ Self-Healing started (2-Agent Consensus)")

    try:
        # 1. UC2 Graph ë¹Œë“œ
        uc2_graph = build_uc2_graph()

        # 2. Master State â†’ UC2 State ë³€í™˜
        uc2_state: HITLState = {
            "url": state["url"],
            "site_name": state["site_name"],
            "html_content": state.get("html_content"),
            "gpt_proposal": None,
            "gpt_validation": None,
            "consensus_reached": False,
            "retry_count": 0,
            "final_selectors": None,
            "error_message": None,
            "next_action": None,
        }

        # 3. UC2 ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        uc2_result = uc2_graph.invoke(uc2_state)

        # 4. ê²°ê³¼ ë¶„ì„
        # FIX Bug #3: uc2_resultê°€ Noneì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ defensive coding
        if uc2_result is None:
            raise ValueError("UC2 workflow returned None instead of valid dict")

        consensus_reached = uc2_result.get("consensus_reached", False)
        final_selectors = uc2_result.get("final_selectors")

        # í•©ì˜ ì ìˆ˜ ê³„ì‚° (UC2ì—ì„œ ê³„ì‚°í•œ ê°’ ì‚¬ìš©)
        gpt_proposal = uc2_result.get("gpt_proposal", {})
        gpt_validation = uc2_result.get("gpt_validation", {})

        gpt_confidence = gpt_proposal.get("confidence", 0.0) if gpt_proposal else 0.0
        gpt4o_confidence = gpt_validation.get("confidence", 0.0) if gpt_validation else 0.0

        # ê°„ë‹¨í•œ í•©ì˜ ì ìˆ˜ (ì‹¤ì œë¡œëŠ” uc2_hitl.pyì˜ calculate_consensus_score ì‚¬ìš©)
        consensus_score = (
            gpt_confidence * 0.3
            + gpt4o_confidence * 0.3
            + (1.0 if consensus_reached else 0.0) * 0.4
        )

        logger.info(
            f"[UC2 Node] âœ… Self-Healing completed: "
            f"consensus_reached={consensus_reached}, score={consensus_score:.2f}"
        )

        # 5. Master State ì—…ë°ì´íŠ¸ + supervisorë¡œ ë¼ìš°íŒ…
        return Command(
            update={
                "uc2_consensus_result": {
                    "consensus_reached": consensus_reached,
                    "consensus_score": round(consensus_score, 2),
                    "proposed_selectors": final_selectors,
                    "gpt_analysis": gpt_proposal,
                    "gpt_validation": gpt_validation,
                },
                "current_uc": "uc2",
                "workflow_history": state.get("workflow_history", [])
                + [
                    f"uc2_self_heal â†’ supervisor (consensus={consensus_reached}, score={consensus_score:.2f})"
                ],
            },
            goto="supervisor",
        )

    except Exception as e:
        logger.error(f"[UC2 Node] âŒ Error: {e}")

        return Command(
            update={
                "uc2_consensus_result": {
                    "consensus_reached": False,
                    "consensus_score": 0.0,
                    "error_message": str(e),
                },
                "error_message": f"UC2 failed: {str(e)}",
                "workflow_history": state.get("workflow_history", [])
                + [f"uc2_self_heal â†’ supervisor (ERROR: {str(e)})"],
            },
            goto="supervisor",
        )


# ============================================================================
# UC3 Node Wrapper (ê¸°ì¡´ UC3 ì›Œí¬í”Œë¡œìš° í˜¸ì¶œ)
# ============================================================================

from src.workflow.uc3_new_site import UC3State, create_uc3_agent

# meta_extractor import removed - JSON-LD handled inside UC3 StateGraph now


def uc3_new_site_node(state: MasterCrawlState) -> Command[Literal["supervisor"]]:
    """
    UC3 New Site Discovery Node

    ê¸°ì¡´ UC3 LangGraph ì›Œí¬í”Œë¡œìš°ë¥¼ í˜¸ì¶œí•˜ì—¬ ìƒˆë¡œìš´ ì‚¬ì´íŠ¸ CSS Selector ë°œê²¬

    GPT-4o ì‚¬ìš©:
    - DOM êµ¬ì¡° ë¶„ì„
    - Semantic HTML ì´í•´
    - CSS Selector ìë™ ìƒì„±
    - Confidence: 0.0 ~ 1.0

    Args:
        state: MasterCrawlState

    Returns:
        Command: UC3 ê²°ê³¼ ì—…ë°ì´íŠ¸ + supervisorë¡œ ë¼ìš°íŒ…
    """
    logger.info("[UC3 Node] ğŸ†• New Site Discovery started")

    try:
        # JSON-LD extraction is now handled inside UC3 StateGraph (extract_json_ld_node)
        # Removed redundant code from master workflow (line 986-1021)

        # 1. UC3 Graph ë¹Œë“œ
        uc3_graph = create_uc3_agent()

        # 2. Master State â†’ UC3 State ë³€í™˜
        uc3_state: UC3State = {
            "url": state["url"],
            "site_name": state["site_name"],
            "html_content": state.get("html_content"),
            "claude_analysis": None,
            "discovered_selectors": None,
            "confidence": 0.0,
            "error_message": None,
        }

        # 3. UC3 ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        uc3_result = uc3_graph.invoke(uc3_state)

        # 4. ê²°ê³¼ ë¶„ì„
        discovered_selectors = uc3_result.get("discovered_selectors")
        # UC3ëŠ” consensus_scoreë¥¼ ë°˜í™˜, confidenceë„ fallback ì§€ì›
        confidence = uc3_result.get("consensus_score", uc3_result.get("confidence", 0.0))

        logger.info(
            f"[UC3 Node] âœ… Discovery completed: "
            f"selectors_found={bool(discovered_selectors)}, confidence={confidence:.2f}"
        )

        # 5. Master State ì—…ë°ì´íŠ¸ + supervisorë¡œ ë¼ìš°íŒ…
        return Command(
            update={
                "uc3_discovery_result": {
                    "selectors_discovered": discovered_selectors,
                    "confidence": confidence,
                    "claude_analysis": uc3_result.get("claude_analysis"),
                },
                "current_uc": "uc3",
                "workflow_history": state.get("workflow_history", [])
                + [f"uc3_new_site â†’ supervisor (confidence={confidence:.2f})"],
            },
            goto="supervisor",
        )

    except Exception as e:
        logger.error(f"[UC3 Node] âŒ Error: {e}")

        return Command(
            update={
                "uc3_discovery_result": {
                    "selectors_discovered": None,
                    "confidence": 0.0,
                    "error_message": str(e),
                },
                "error_message": f"UC3 failed: {str(e)}",
                "workflow_history": state.get("workflow_history", [])
                + [f"uc3_new_site â†’ supervisor (ERROR: {str(e)})"],
            },
            goto="supervisor",
        )


# ============================================================================
# Master Graph êµ¬ì„± (Conditional Edges ì‚¬ìš©)
# ============================================================================


def build_master_graph():
    """
    Master Crawl Workflow Graph ìƒì„±

    ê³µì‹ LangGraph íŒ¨í„´ í†µí•©:

    1. Agent Supervisor Pattern:
       - supervisor_nodeê°€ UC1/UC2/UC3ë¥¼ ì¡°ê±´ë¶€ ë¼ìš°íŒ…
       - ê° UCëŠ” ì „ë¬¸í™”ëœ Agent ì—­í• 

    2. Conditional Edges:
       - add_conditional_edges() ë©”ì„œë“œ ì‚¬ìš© (ì´ë¯¸ UC2ì—ì„œ ì‚¬ìš© ì¤‘)

    3. Command API:
       - Command(update={...}, goto="node_name")
       - State ì—…ë°ì´íŠ¸ + ë¼ìš°íŒ…ì„ ë™ì‹œì— ìˆ˜í–‰

    Phase 4 Enhancement:
       - USE_SUPERVISOR_LLM í™˜ê²½ë³€ìˆ˜ë¡œ LLM vs Rule-based ì„ íƒ
       - LLM: GPT-4o-mini intelligent routing with reasoning
       - Rule-based: ì•ˆì •ì ì¸ if-else ë¡œì§ (ê¸°ë³¸ê°’)

    Returns:
        Compiled LangGraph app

    ê·¸ë˜í”„ êµ¬ì¡°:

        START
          â†“
       supervisor â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       (LLM or Rule-based)  â”‚
          â†“                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
        â”‚ uc1_validation  â”‚â”€â”¤
        â”‚ uc2_self_heal   â”‚â”€â”¤
        â”‚ uc3_new_site    â”‚â”€â”˜
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
        END
    """
    logger.info("[build_master_graph] ğŸ—ï¸  Building Master LangGraph StateGraph...")

    # Check if Distributed Supervisor is enabled
    use_distributed_supervisor = os.getenv("USE_DISTRIBUTED_SUPERVISOR", "false").lower() == "true"

    if use_distributed_supervisor:
        logger.info("[build_master_graph] ğŸš€ Using Distributed 3-Model Supervisor (SPOF í•´ê²°)")
    else:
        logger.info("[build_master_graph] ğŸ“‹ Using Rule-based Supervisor")

    # 1. StateGraph ìƒì„±
    workflow = StateGraph(MasterCrawlState)

    # 2. Node ì¶”ê°€
    workflow.add_node("supervisor", supervisor_node)
    workflow.add_node("uc1_validation", uc1_validation_node)
    workflow.add_node("uc2_self_heal", uc2_self_heal_node)
    workflow.add_node("uc3_new_site", uc3_new_site_node)

    # 3. Entry Point ì„¤ì •
    workflow.set_entry_point("supervisor")

    # 4. Edge ì¶”ê°€
    # Command APIë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ ê° ë…¸ë“œê°€ ìì²´ì ìœ¼ë¡œ ë¼ìš°íŒ… ê²°ì •
    # supervisor â†’ UC1/UC2/UC3/END (Command.gotoë¡œ ê²°ì •)
    # UC1/UC2/UC3 â†’ supervisor (í•­ìƒ supervisorë¡œ ë³µê·€)

    # Note: Command APIë¥¼ ì‚¬ìš©í•˜ë©´ add_edgeê°€ ë¶ˆí•„ìš”í•¨
    # ê° ë…¸ë“œì˜ Command.gotoê°€ ìë™ìœ¼ë¡œ ë¼ìš°íŒ… ì²˜ë¦¬

    # 5. Compile
    app = workflow.compile()

    logger.info("[build_master_graph] âœ… Master StateGraph compiled successfully")

    return app


# ============================================================================
# ì‚¬ìš© ì˜ˆì‹œ (í…ŒìŠ¤íŠ¸ìš©)
# ============================================================================

if __name__ == "__main__":
    """
    Master Graph í…ŒìŠ¤íŠ¸ ì‹¤í–‰

    Usage:
        PYTHONPATH=/Users/charlee/Desktop/Intern/crawlagent poetry run python src/workflow/master_crawl_workflow.py
    """
    import requests

    # 1. Master Graph ë¹Œë“œ
    master_app = build_master_graph()

    # 2. í…ŒìŠ¤íŠ¸ ì…ë ¥
    test_url = "https://www.yonhapnewstv.co.kr/news/MYH20251107014400038"

    logger.info(f"[Test] Fetching HTML from {test_url}")

    # HTTP retry logic with exponential backoff
    permanent_status_codes = {400, 401, 403, 404, 410}
    transient_status_codes = {429, 500, 502, 503, 504}
    max_retries = 3
    html_content = None
    last_error = None

    for attempt in range(max_retries):
        try:
            response = requests.get(
                test_url,
                timeout=10,
                headers={
                    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
                },
            )
            response.raise_for_status()
            html_content = response.text
            logger.info(f"[Test] âœ… HTML fetched successfully (attempt={attempt+1})")
            break

        except requests.exceptions.HTTPError as http_error:
            last_error = http_error
            status_code = http_error.response.status_code if http_error.response else None

            # Permanent errors - do not retry
            if status_code in permanent_status_codes:
                logger.error(f"[Test] âŒ Permanent HTTP error {status_code}, aborting")
                raise

            # Transient errors - retry with exponential backoff
            elif status_code in transient_status_codes:
                if attempt < max_retries - 1:
                    wait_time = (2**attempt) * 1
                    logger.warning(
                        f"[Test] âš ï¸ Transient HTTP error {status_code} (attempt={attempt+1}), retrying after {wait_time}s"
                    )
                    time.sleep(wait_time)
                    continue
                else:
                    logger.error(f"[Test] âŒ Max retries reached for HTTP {status_code}")
                    raise

        except (requests.exceptions.ConnectionError, requests.exceptions.Timeout) as conn_error:
            last_error = conn_error
            if attempt < max_retries - 1:
                wait_time = (2**attempt) * 1
                logger.warning(
                    f"[Test] âš ï¸ Network error (attempt={attempt+1}), retrying after {wait_time}s"
                )
                time.sleep(wait_time)
                continue
            else:
                logger.error(f"[Test] âŒ Max retries reached for network error")
                raise

    if html_content is None:
        raise Exception(f"Failed to fetch HTML after {max_retries} attempts: {last_error}")

    # 3. ì´ˆê¸° State
    initial_state: MasterCrawlState = {
        "url": test_url,
        "site_name": "yonhap",
        "html_content": html_content,
        "current_uc": None,
        "next_action": None,
        "failure_count": 0,
        "uc1_validation_result": None,
        "uc2_consensus_result": None,
        "uc3_discovery_result": None,
        "final_result": None,
        "error_message": None,
        "workflow_history": [],
    }

    # 4. Master Graph ì‹¤í–‰
    logger.info("[Test] ğŸš€ Running Master Graph...")
    final_state = master_app.invoke(initial_state)

    # 5. ê²°ê³¼ ì¶œë ¥
    logger.info("\n" + "=" * 80)
    logger.info("[Test] ğŸ“Š Master Graph Execution Result")
    logger.info("=" * 80)
    logger.info(f"Workflow History: {final_state.get('workflow_history')}")
    logger.info(f"UC1 Result: {final_state.get('uc1_validation_result')}")
    logger.info(f"UC2 Result: {final_state.get('uc2_consensus_result')}")
    logger.info(f"UC3 Result: {final_state.get('uc3_discovery_result')}")
    logger.info(f"Error: {final_state.get('error_message')}")
    logger.info("=" * 80)

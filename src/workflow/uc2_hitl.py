"""
CrawlAgent - UC2 HITL (Human-in-the-Loop) Workflow
Created: 2025-11-05
Updated: 2025-11-16 (ì›ë˜ ì„¤ê³„ ë³µì›: Claude Sonnet 4.5 Proposer)

LangGraphë¥¼ ì‚¬ìš©í•œ 2-Agent CSS Selector í•©ì˜ ì‹œìŠ¤í…œ:
- Claude Sonnet 4.5: CSS Selector ì œì•ˆ (Proposer) - Cross-company validation
- GPT-4o: Selector ê²€ì¦ (Validator)
- Human: ìµœì¢… ìŠ¹ì¸/ê±°ë¶€ (Decision Maker)

ë³µì› ì´ìœ :
- ì›ë˜ ì„¤ê³„: Anthropic (Proposer) vs OpenAI (Validator) êµì°¨ ê²€ì¦
- Hallucination ë°©ì§€: ì„œë¡œ ë‹¤ë¥¸ íšŒì‚¬ ëª¨ë¸ë¡œ ìƒí˜¸ ê²€ì¦
- ë¹„ìš© ì ˆê°: Claude ~$0.0037/call (GPT-4o ëŒ€ë¹„ 75% ì ˆê°)
- Coding íŠ¹í™”: Claude Sonnet 4.5ëŠ” CSS Selector ìƒì„±ì— ìµœì í™”

ìš©ì–´:
- State: ê·¸ë˜í”„ ë‚´ ë…¸ë“œë“¤ì´ ê³µìœ í•˜ëŠ” ë°ì´í„° (TypedDict)
- Node: ê·¸ë˜í”„ ë‚´ ì‘ì—… ë‹¨ìœ„ (í•¨ìˆ˜)
- Edge: ë…¸ë“œ ê°„ ì—°ê²° (ì¡°ê±´ë¶€ ë¶„ê¸° ê°€ëŠ¥)
- StateGraph: ë…¸ë“œì™€ ì—£ì§€ë¡œ êµ¬ì„±ëœ ê·¸ë˜í”„

ì•„í‚¤í…ì²˜ ì„¤ëª…:
==================
UC2ëŠ” "2-Agent Consensus + HITL" íŒ¨í„´ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

1. Claude Propose Node (gpt_propose_node):
   - Few-Shot Examples ì°¸ì¡° (DBì˜ ì„±ê³µ íŒ¨í„´)
   - HTMLì„ ë¶„ì„í•´ì„œ title, body, dateì˜ CSS Selector ì œì•ˆ
   - confidence scoreì™€ reasoning í¬í•¨
   - Fallback: Claude ì‹¤íŒ¨ ì‹œ GPT-4o-minië¡œ ì „í™˜
   - ì¶œë ¥: gpt_proposal ì¶”ê°€ëœ State

2. GPT-4o Validate Node (gpt_validate_node):
   - Claude ì œì•ˆì„ ì‹¤ì œ HTMLì— ì ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸
   - BeautifulSoupìœ¼ë¡œ CSS Selector ì¶”ì¶œ ì‹œë„
   - ì¶”ì¶œ ê²°ê³¼ë¥¼ GPT-4o LLMì—ê²Œ ê²€ì¦ ìš”ì²­
   - ì¶œë ¥: gpt_validation ì¶”ê°€ëœ State

3. í•©ì˜ ë©”ì»¤ë‹ˆì¦˜ (2-Agent Consensus):
   - ê°€ì¤‘ íˆ¬í‘œ: 0.3Ã—Claude + 0.3Ã—GPT-4o + 0.4Ã—Quality
   - ì„ê³„ê°’: 0.5 ì´ìƒ â†’ í•©ì˜ ì„±ê³µ
   - í•©ì˜ ì‹¤íŒ¨ ì‹œ ìµœëŒ€ 3íšŒ ì¬ì‹œë„
   - 3íšŒ ì‹¤íŒ¨ ì‹œ Human Review ìš”ì²­

4. State ë¶ˆë³€ì„± (Immutability):
   - ëª¨ë“  NodeëŠ” stateë¥¼ ì§ì ‘ ìˆ˜ì •í•˜ì§€ ì•ŠìŒ
   - spread operator (**state)ë¡œ ìƒˆë¡œìš´ dict ë°˜í™˜
   - ì˜ˆ: return {**state, "gpt_proposal": proposal}
"""

from typing import Literal, Optional, TypedDict

from typing_extensions import Annotated

# ============================================================================
# State Definition (LangGraph ê³µì‹ ìš©ì–´)
# ============================================================================


class HITLState(TypedDict):
    """
    UC2 HITL ì›Œí¬í”Œë¡œìš°ì˜ State ì •ì˜

    LangGraphì—ì„œ StateëŠ” ëª¨ë“  ë…¸ë“œê°€ ì½ê³  ì“¸ ìˆ˜ ìˆëŠ” ê³µìœ  ë°ì´í„°ì…ë‹ˆë‹¤.
    ê° ë…¸ë“œëŠ” Stateì˜ ì¼ë¶€ë¥¼ ì—…ë°ì´íŠ¸í•˜ë©°, ë‹¤ìŒ ë…¸ë“œë¡œ ì „ë‹¬ë©ë‹ˆë‹¤.
    """

    # === ì…ë ¥ ë°ì´í„° ===
    url: str
    """í¬ë¡¤ë§ ëŒ€ìƒ URL"""

    site_name: str
    """ì‚¬ì´íŠ¸ ì´ë¦„ (ì˜ˆ: 'bbc', 'cnn')"""

    html_content: Optional[str]
    """fetchí•œ HTML ì›ë³¸"""

    # === GPT Agent ì¶œë ¥ ===
    gpt_proposal: Optional[dict]
    """
    GPTê°€ ì œì•ˆí•œ CSS Selector
    {
        "title_selector": "h1.article-title",
        "body_selector": "div.article-body",
        "date_selector": "time.published",
        "confidence": 0.95,
        "reasoning": "..."
    }
    """

    # === GPT-4o Agent ì¶œë ¥ ===
    gpt_validation: Optional[dict]
    """
    GPT-4oì˜ ê²€ì¦ ê²°ê³¼
    {
        "is_valid": true,
        "confidence": 0.90,
        "feedback": "...",
        "suggested_changes": {...}
    }
    """

    # === í•©ì˜ ê²°ê³¼ ===
    consensus_reached: bool
    """ë‘ Agentê°€ í•©ì˜ì— ë„ë‹¬í–ˆëŠ”ì§€ ì—¬ë¶€"""

    retry_count: int
    """ì¬ì‹œë„ íšŸìˆ˜ (ìµœëŒ€ 3íšŒ)"""

    # === ìµœì¢… ì¶œë ¥ ===
    final_selectors: Optional[dict]
    """ìµœì¢… í•©ì˜ëœ CSS Selector"""

    error_message: Optional[str]
    """ì—ëŸ¬ ë°œìƒ ì‹œ ë©”ì‹œì§€"""

    # === ì›Œí¬í”Œë¡œìš° ì œì–´ ===
    next_action: Optional[Literal["validate", "retry", "human_review", "end"]]
    """ë‹¤ìŒì— ì‹¤í–‰í•  ì•¡ì…˜ (conditional edgeì—ì„œ ì‚¬ìš©)"""


# ============================================================================
# Node Functions (LangGraph ê³µì‹ ìš©ì–´)
# ============================================================================

import json
import os

from langchain_anthropic import ChatAnthropic
from loguru import logger
from openai import OpenAI


def gpt_propose_node(state: HITLState) -> HITLState:
    """
    Claude Sonnet 4.5ê°€ CSS Selectorë¥¼ ì œì•ˆí•˜ëŠ” Node (Few-Shot Examples í¬í•¨)

    ì›ë˜ ì„¤ê³„: Claude (Proposer) + GPT-4o (Validator) - Cross-Company Validation
    ë³µì› ì´ìœ : Anthropic vs OpenAI êµì°¨ ê²€ì¦ìœ¼ë¡œ hallucination ë°©ì§€ + ë¹„ìš© 45% ì ˆê°

    LangGraph Node ê·œì¹™:
    1. ì…ë ¥: state (HITLState)
    2. ì¶œë ¥: ì—…ë°ì´íŠ¸ëœ state (HITLState)
    3. stateë¥¼ ì§ì ‘ ìˆ˜ì •í•˜ì§€ ì•Šê³ , ìƒˆë¡œìš´ dictë¥¼ ë°˜í™˜

    ë™ì‘:
    - Few-Shot Examples ì°¸ì¡° (DBì˜ ì„±ê³µ íŒ¨í„´)
    - HTMLì„ ë¶„ì„í•´ì„œ title, body, dateì˜ CSS Selector ì œì•ˆ
    - confidence scoreì™€ reasoning í¬í•¨
    - Fallback: Claude ì‹¤íŒ¨ ì‹œ GPT-4o-minië¡œ ì „í™˜
    """
    logger.info(f"[Claude Propose Node] Starting for {state['url']}")

    # Few-Shot Retriever import
    import time

    from src.agents.few_shot_retriever import format_few_shot_prompt, get_few_shot_examples
    from src.exceptions import OpenAIAPIError, format_error_for_user, is_retryable_error

    # HTML ìƒ˜í”Œ ì¶”ì¶œ (20000ìë¡œ ì¦ê°€)
    html_sample = state.get("html_content", "")[:20000]

    # Few-Shot Examples ê°€ì ¸ì˜¤ê¸°
    few_shot_examples = get_few_shot_examples(limit=5)
    few_shot_section = ""
    if few_shot_examples and len(few_shot_examples) > 0:
        few_shot_section = "## Few-Shot Examples (ì„±ê³µí•œ ë‰´ìŠ¤ ì‚¬ì´íŠ¸ íŒ¨í„´)\n\n"
        few_shot_section += format_few_shot_prompt(few_shot_examples, include_patterns=True)
        few_shot_section += "\n"

    # ì‹¤ì‹œê°„ HTML êµ¬ì¡° ë¶„ì„ (yonhap ì „ìš© íŒíŠ¸)
    site_name = state.get("site_name", "")
    html_hint = ""
    if site_name == "yonhap" or "yna.co.kr" in state['url']:
        html_hint = """
**ğŸ” CRITICAL: yonhap (yna.co.kr) HTML Structure Hints**:
Based on recent successful crawls and live HTML analysis:
- Title: Look for `h1.tit01` (NOT h1.title-type017)
- Body: Look for `div.content03` - this div contains the full article text
- Date: Use `meta[property='article:published_time']` (most reliable)

Example yonhap structure:
```html
<h1 class="tit01">ì´ëœë“œ "íŒ¨ì…˜ë¬¼ë¥˜ì„¼í„° í™”ì¬...</h1>
<div class="content03">
  <div class="story-news article">
    [Article content here]
  </div>
</div>
<meta property="article:published_time" content="2025-11-17T18:10:16+09:00">
```

**WARNING**: Previous attempts used `h1.title-type017 > span.tit01` and `div.article-body` but these DON'T EXIST in current HTML. Use the hints above instead.
"""

    # GPT í”„ë¡¬í”„íŠ¸ (Few-Shot í¬í•¨)
    prompt = f"""
You are an expert web scraper. Analyze the following HTML and propose CSS selectors.

{few_shot_section}
{html_hint}

URL: {state['url']}
HTML Sample (first 20000 chars):
```html
{html_sample}
```

Task: Propose CSS selectors for:
1. Article title
2. Article body/content
3. Publication date

**Selector Priority Guidelines**:
- **FIRST PRIORITY**: Target visible HTML elements (h1, div, article, section, p, time, etc.)
- **SECOND PRIORITY**: Use meta tags ONLY if visible elements are not reliable
- **Goal**: Extract actual article content from DOM structure

**Title Selector Priority**:
1. Visible heading tags: h1.title, article > h1, div.headline > h1
2. Meta tags (if needed): meta[property='og:title']

**Body Selector Priority**:
1. Visible content containers: div.article-body, article.content, section.story-body
2. Paragraph tags: article > p, div.content p
3. Avoid: meta[name='description'] (too short, not full article)

**Date Selector Priority**:
1. Time elements: time[datetime], time.published-date, span.date
2. Date containers: div.timestamp, span.article-date
3. Meta tags (acceptable): meta[property='article:published_time']

**Important Notes**:
- Prefer semantic HTML and visible elements when they exist
- Meta tags are acceptable for dates (many sites use them)
- Avoid meta tags for title/body unless necessary
- Ensure selectors extract complete, high-quality content

Refer to the Few-Shot examples above for successful patterns.

Return ONLY a JSON object with this structure:
{{
    "title_selector": "CSS selector",
    "body_selector": "CSS selector",
    "date_selector": "CSS selector",
    "confidence": 0.0-1.0,
    "reasoning": "brief explanation of your choices and priority used"
}}
"""

    # Anthropic API key
    anthropic_key = os.getenv("ANTHROPIC_API_KEY")

    # Retry logic with fallback to GPT-4o-mini
    max_retries = 3
    last_error = None

    # Try Claude Sonnet 4.5 first (primary, coding-specialized)
    if anthropic_key:
        for attempt in range(max_retries):
            try:
                # Claude Sonnet 4.5 ì´ˆê¸°í™” (timeout 30ì´ˆ)
                claude_llm = ChatAnthropic(
                    model="claude-sonnet-4-5-20250929",
                    temperature=0.3,
                    api_key=anthropic_key,
                    max_tokens=4096,
                    timeout=30.0,
                )

                # Claude í˜¸ì¶œ (v2.2: GPT-4o â†’ Claude Sonnet 4.5 ë³µì›)
                # ì›ë˜ ì„¤ê³„ ë³µì›: Anthropic (Proposer) vs OpenAI (Validator) êµì°¨ ê²€ì¦
                # ë¹„ìš©: ~$0.0037/call (GPT-4o ëŒ€ë¹„ 75% ì ˆê°)
                messages = [
                    ("system", "You are a CSS selector expert. Always return valid JSON."),
                    ("human", prompt),
                ]

                response = claude_llm.invoke(messages)

                # Extract text from response (handle both string and list formats)
                if hasattr(response, 'content'):
                    content = response.content
                    # If content is a list (new Anthropic API format)
                    if isinstance(content, list):
                        # Extract text from first content block
                        proposal_text = content[0].get("text", "") if content else ""
                    else:
                        # If content is already a string (old format)
                        proposal_text = content
                else:
                    proposal_text = str(response)

                # Parse JSON
                proposal = json.loads(proposal_text)

                logger.info(
                    f"[Claude Propose Node] âœ… Success (attempt={attempt+1}, confidence={proposal.get('confidence', 0)})"
                )

                # State ì—…ë°ì´íŠ¸ (ë¶ˆë³€ì„± ìœ ì§€)
                return {**state, "gpt_proposal": proposal, "next_action": "validate"}

            except Exception as raw_error:
                last_error = raw_error

                # Retry ê°€ëŠ¥í•œ ì˜¤ë¥˜ì¸ê°€? (429 Rate Limit, 503/504 Server Error)
                if attempt < max_retries - 1:
                    wait_time = (2**attempt) * 1  # Exponential backoff: 1s, 2s, 4s
                    logger.warning(
                        f"[Claude Propose Node] âš ï¸ Retryable error, waiting {wait_time}s (attempt {attempt+1}/{max_retries}): {raw_error}"
                    )
                    time.sleep(wait_time)
                    continue
                else:
                    logger.error(
                        f"[Claude Propose Node] âŒ Attempt {attempt+1} failed: {raw_error}"
                    )
                    break

    # Fallback to GPT-4o-mini if Claude fails or key missing
    logger.warning("[Claude Propose Node] âš ï¸ Falling back to GPT-4o-mini")

    try:
        openai_key = os.getenv("OPENAI_API_KEY")
        if not openai_key:
            raise Exception("OPENAI_API_KEY not found for fallback")

        client = OpenAI(api_key=openai_key, timeout=30.0)
        response = client.chat.completions.create(
            model="gpt-4o-mini",  # Fallback model (cheaper, faster)
            messages=[
                {"role": "system", "content": "You are a CSS selector expert. Always return valid JSON."},
                {"role": "user", "content": prompt},
            ],
            temperature=0.3,
            response_format={"type": "json_object"},
        )

        proposal_text = response.choices[0].message.content
        proposal = json.loads(proposal_text)

        logger.info(f"[Claude Propose Node] âœ… Fallback GPT-4o-mini success (confidence={proposal.get('confidence', 0)})")
        return {**state, "gpt_proposal": proposal, "next_action": "validate"}

    except Exception as fallback_error:
        logger.error(f"[Claude Propose Node] âŒ Fallback also failed: {fallback_error}")

        return {
            **state,
            "gpt_proposal": None,
            "error_message": f"Claude and fallback failed: {fallback_error}",
            "next_action": "end",
        }


# ============================================================================
# Helper Functions for Quality Assessment (NEW! - Sprint 1)
# ============================================================================


def calculate_extraction_quality(extracted_data: dict, extraction_success: dict) -> float:
    """
    ì¶”ì¶œëœ ë°ì´í„°ì˜ ì‹¤ì œ í’ˆì§ˆì„ 0.0~1.0 ì ìˆ˜ë¡œ ê³„ì‚°

    ëª©ì :
        ë‹¨ìˆœ "ì„±ê³µ/ì‹¤íŒ¨"ê°€ ì•„ë‹ˆë¼ "ì–¼ë§ˆë‚˜ ì¢‹ì€ ë°ì´í„°ì¸ì§€" ì •ëŸ‰ì ìœ¼ë¡œ í‰ê°€

    ê³„ì‚° ë°©ë²•:
        - title_quality * 0.3: ì œëª© í’ˆì§ˆ (10ì ì´ìƒì´ë©´ 1.0)
        - body_quality * 0.5: ë³¸ë¬¸ í’ˆì§ˆ (500ì ì´ìƒì´ë©´ 1.0, 100~500ìë©´ 0.6)
        - date_quality * 0.2: ë‚ ì§œ í’ˆì§ˆ (ì¶”ì¶œ ì„±ê³µí•˜ë©´ 1.0)

    Args:
        extracted_data: {"title": "...", "body": "...", "date": "..."}
        extraction_success: {"title": True, "body": True, "date": False}

    Returns:
        float: 0.0 ~ 1.0 (0.8 ì´ìƒì´ë©´ ê³ í’ˆì§ˆ)

    Example:
        >>> extracted = {"title": "ì‚¼ì„±ì „ì ì£¼ê°€ ê¸‰ë“±", "body": "..."*600, "date": "2025-11-09"}
        >>> success = {"title": True, "body": True, "date": True}
        >>> calculate_extraction_quality(extracted, success)
        1.0  # ëª¨ë“  í•„ë“œê°€ ê³ í’ˆì§ˆ

        >>> extracted_poor = {"title": "ì§§ìŒ", "body": "ë„ˆë¬´ ì§§ì€ ë³¸ë¬¸", "date": None}
        >>> success_poor = {"title": True, "body": True, "date": False}
        >>> calculate_extraction_quality(extracted_poor, success_poor)
        0.38  # í’ˆì§ˆì´ ë‚®ìŒ
    """
    # 1. Title í’ˆì§ˆ (0.0 ~ 1.0)
    title = extracted_data.get("title", "")
    title_success = extraction_success.get("title", False)

    if not title_success or not title:
        title_quality = 0.0
    elif len(title) >= 10:
        title_quality = 1.0  # ì¶©ë¶„í•œ ê¸¸ì´
    elif len(title) >= 5:
        title_quality = 0.7  # ì§§ì§€ë§Œ ìˆìŒ
    else:
        title_quality = 0.3  # ë„ˆë¬´ ì§§ìŒ

    # 2. Body í’ˆì§ˆ (0.0 ~ 1.0)
    body = extracted_data.get("body", "")
    body_success = extraction_success.get("body", False)

    if not body_success or not body:
        body_quality = 0.0
    elif len(body) >= 100:  # v2.1: 200 â†’ 100ìë¡œ ì™„í™” (SPA/ì§§ì€ ê¸°ì‚¬ ì§€ì›)
        body_quality = 1.0  # ì¶©ë¶„í•œ ë³¸ë¬¸
    elif len(body) >= 50:  # v2.1: 0.4 â†’ 0.6ìœ¼ë¡œ ìƒí–¥ (ë¶€ë¶„ ì ìˆ˜ ê°œì„ )
        body_quality = 0.6  # ì¤‘ê°„ ê¸¸ì´ (ì´ì „ 0.4)
    elif len(body) >= 20:  # v2.1: ìƒˆë¡œ ì¶”ê°€ (ìµœì†Œí•œì˜ ë³¸ë¬¸)
        body_quality = 0.3  # ì§§ì€ ë³¸ë¬¸
    else:
        body_quality = 0.1  # ë„ˆë¬´ ì§§ìŒ (ê±°ì˜ ì‹¤íŒ¨)

    # 3. Date í’ˆì§ˆ (0.0 ~ 1.0)
    date = extracted_data.get("date", "")
    date_success = extraction_success.get("date", False)

    if not date_success or not date:
        date_quality = 0.0
    else:
        # ë‚ ì§œ í˜•ì‹ ê²€ì¦ (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
        # "2025-11-09", "2025.11.09", "11/09/2025" ë“±
        import re

        if re.search(r"\d{4}", date) and re.search(r"\d{1,2}", date):
            date_quality = 1.0  # ì—°ë„ì™€ ìˆ«ìê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ OK
        else:
            date_quality = 0.5  # ë‚ ì§œ ê°™ì§€ë§Œ í™•ì‹¤í•˜ì§€ ì•ŠìŒ

    # 4. Valid fields ì¹´ìš´íŠ¸ (v2.1: ë¶€ë¶„ ì„±ê³µ ì²˜ë¦¬ìš©)
    valid_fields = sum(
        [
            1 if title_quality >= 0.3 else 0,  # Titleì´ ìµœì†Œ ê¸°ì¤€ ì¶©ì¡±
            1 if body_quality >= 0.3 else 0,  # Bodyê°€ ìµœì†Œ ê¸°ì¤€ ì¶©ì¡±
            1 if date_quality >= 0.5 else 0,  # Dateê°€ ìµœì†Œ ê¸°ì¤€ ì¶©ì¡±
        ]
    )

    # 5. ê°€ì¤‘ì¹˜ í•©ì‚°
    extraction_quality = title_quality * 0.3 + body_quality * 0.5 + date_quality * 0.2

    # v2.1: ë¶€ë¶„ ì„±ê³µ ë³´ë„ˆìŠ¤ (2/3 í•„ë“œ ì„±ê³µ ì‹œ +0.05)
    if valid_fields == 2:
        extraction_quality = min(1.0, extraction_quality + 0.05)
        logger.info(f"[Extraction Quality] Partial success bonus: 2/3 fields valid (+0.05)")

    logger.debug(
        f"[Extraction Quality] title={title_quality:.2f}, "
        f"body={body_quality:.2f}, date={date_quality:.2f}, "
        f"valid_fields={valid_fields}/3 â†’ total={extraction_quality:.2f}"
    )

    return round(extraction_quality, 2)


def calculate_consensus_score(
    gpt_confidence: float, gpt4o_confidence: float, extraction_quality: float
) -> float:
    """
    3ê°€ì§€ ìš”ì†Œë¥¼ ê°€ì¤‘ì¹˜ í•©ì‚°í•˜ì—¬ ìµœì¢… í•©ì˜ ì ìˆ˜ ê³„ì‚°

    ëª©ì :
        GPT ì œì•ˆ í’ˆì§ˆ + GPT-4o ê²€ì¦ í’ˆì§ˆ + ì‹¤ì œ ì¶”ì¶œ ê²°ê³¼ë¥¼ ëª¨ë‘ ê³ ë ¤í•˜ì—¬
        ì¢…í•©ì ì¸ í•©ì˜ ì ìˆ˜ë¥¼ ê³„ì‚°

    ê°€ì¤‘ì¹˜:
        - gpt_confidence: 30% (GPTê°€ ì œì•ˆì— ëŒ€í•´ ì–¼ë§ˆë‚˜ í™•ì‹ í•˜ëŠ”ì§€)
        - gpt4o_confidence: 30% (GPT-4oê°€ ê²€ì¦ì— ëŒ€í•´ ì–¼ë§ˆë‚˜ í™•ì‹ í•˜ëŠ”ì§€)
        - extraction_quality: 40% (ì‹¤ì œ ì¶”ì¶œ ê²°ê³¼ê°€ ì–¼ë§ˆë‚˜ ì¢‹ì€ì§€)

    íŒë‹¨ ê¸°ì¤€:
        - >= 0.8: ìë™ ìŠ¹ì¸ (High confidence)
        - >= 0.6: ì¡°ê±´ë¶€ ìŠ¹ì¸ (Medium confidence, ê²½ê³  ë¡œê·¸)
        - < 0.6: Human Review í•„ìš” (Low confidence)

    Args:
        gpt_confidence: 0.0 ~ 1.0 (GPT ì œì•ˆ ì‹ ë¢°ë„)
        gpt4o_confidence: 0.0 ~ 1.0 (GPT-4o ê²€ì¦ ì‹ ë¢°ë„)
        extraction_quality: 0.0 ~ 1.0 (ì‹¤ì œ ì¶”ì¶œ í’ˆì§ˆ)

    Returns:
        float: 0.0 ~ 1.0 (ìµœì¢… í•©ì˜ ì ìˆ˜)

    Example:
        >>> calculate_consensus_score(0.95, 0.90, 1.0)
        0.95  # ìë™ ìŠ¹ì¸ (ëª¨ë“  ì§€í‘œê°€ ë†’ìŒ)

        >>> calculate_consensus_score(0.80, 0.70, 0.60)
        0.69  # ì¡°ê±´ë¶€ ìŠ¹ì¸ (ì¤‘ê°„ í’ˆì§ˆ)

        >>> calculate_consensus_score(0.60, 0.50, 0.30)
        0.43  # Human Review (í’ˆì§ˆ ë‚®ìŒ)
    """
    consensus_score = gpt_confidence * 0.3 + gpt4o_confidence * 0.3 + extraction_quality * 0.4

    logger.info(
        f"[Consensus Score] GPT={gpt_confidence:.2f}(30%) + "
        f"GPT-4o={gpt4o_confidence:.2f}(30%) + "
        f"Extraction={extraction_quality:.2f}(40%) "
        f"= {consensus_score:.2f}"
    )

    return round(consensus_score, 2)


# ============================================================================
# GPT-4o Validator Node
# ============================================================================

import google.generativeai as genai
from bs4 import BeautifulSoup


def gpt_validate_node(state: HITLState) -> HITLState:
    """
    GPT-4oê°€ GPT-4o-mini ì œì•ˆì„ ê²€ì¦í•˜ëŠ” Node
    (ì›ë˜ Geminiì˜€ìœ¼ë‚˜ rate limitìœ¼ë¡œ GPT-4oë¡œ ë³€ê²½)

    LangGraph Node ê·œì¹™:
    1. ì…ë ¥: state (HITLState) - gpt_proposal í¬í•¨
    2. ì¶œë ¥: ì—…ë°ì´íŠ¸ëœ state (HITLState) - gpt_validation ì¶”ê°€
    3. stateë¥¼ ì§ì ‘ ìˆ˜ì •í•˜ì§€ ì•Šê³ , ìƒˆë¡œìš´ dictë¥¼ ë°˜í™˜

    ê²€ì¦ ë°©ë²•:
    1. GPTê°€ ì œì•ˆí•œ CSS Selectorë¥¼ ì‹¤ì œ HTMLì— ì ìš©
    2. ë°ì´í„° ì¶”ì¶œ ì„±ê³µ ì—¬ë¶€ í™•ì¸
    3. ì¶”ì¶œëœ ë°ì´í„°ì˜ í’ˆì§ˆ í‰ê°€
    4. GPT-4o LLMìœ¼ë¡œ ìµœì¢… íŒë‹¨
    """
    logger.info(f"[GPT-4o Validate Node] Starting validation for {state['url']}")

    try:
        # 1. GPT ì œì•ˆ ê°€ì ¸ì˜¤ê¸°
        gpt_proposal = state.get("gpt_proposal")
        if not gpt_proposal:
            raise ValueError("No GPT proposal found in state")

        # 2. CSS Selectorë¡œ ì‹¤ì œ ë°ì´í„° ì¶”ì¶œ ì‹œë„
        html_content = state.get("html_content", "")
        soup = BeautifulSoup(html_content, "html.parser")

        extracted_data = {}
        extraction_success = {}

        for field in ["title", "body", "date"]:
            selector_key = f"{field}_selector"
            selector = gpt_proposal.get(selector_key, "")

            try:
                # CSS Selector ì ìš©
                elements = soup.select(selector)
                if elements:
                    # ì²« ë²ˆì§¸ ìš”ì†Œì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    text = elements[0].get_text(strip=True)
                    extracted_data[field] = text[:200]  # ì²˜ìŒ 200ìë§Œ
                    extraction_success[field] = True
                else:
                    extracted_data[field] = None
                    extraction_success[field] = False
            except Exception as e:
                logger.warning(f"[Gemini Validate] Extraction failed for {field}: {e}")
                extracted_data[field] = None
                extraction_success[field] = False

        # 3. GPT-4oì—ê²Œ ê²€ì¦ ìš”ì²­ (Gemini rate limit ëŒ€ì‘)
        from langchain_openai import ChatOpenAI

        openai_key = os.getenv("OPENAI_API_KEY")
        if not openai_key:
            raise ValueError("OPENAI_API_KEY not set")

        gpt_validator = ChatOpenAI(
            model="gpt-4o", temperature=0.2, api_key=openai_key, max_tokens=2048, timeout=30.0
        )

        validation_prompt = f"""
You are a web scraping validator. Evaluate the following CSS selector proposal.

URL: {state['url']}

GPT Proposal:
- Title Selector: {gpt_proposal.get('title_selector')}
- Body Selector: {gpt_proposal.get('body_selector')}
- Date Selector: {gpt_proposal.get('date_selector')}
- GPT Confidence: {gpt_proposal.get('confidence')}

Extraction Results:
- Title: {"SUCCESS" if extraction_success.get('title') else "FAILED"}
  Extracted: {(extracted_data.get('title') or 'N/A')[:100]}
- Body: {"SUCCESS" if extraction_success.get('body') else "FAILED"}
  Extracted: {(extracted_data.get('body') or 'N/A')[:100]}
- Date: {"SUCCESS" if extraction_success.get('date') else "FAILED"}
  Extracted: {(extracted_data.get('date') or 'N/A')[:100]}

Task: Validate whether these selectors are good quality.

Return ONLY a JSON object:
{{
    "is_valid": true/false,
    "confidence": 0.0-1.0,
    "feedback": "brief explanation",
    "suggested_changes": {{"field": "new selector or null"}}
}}

Criteria:
- is_valid: true if at least 2/3 fields extracted successfully
- confidence: based on extraction quality
- feedback: explain validation result
"""

        # GPT-4o í˜¸ì¶œ
        response = gpt_validator.invoke([{"role": "user", "content": validation_prompt}])

        # JSON íŒŒì‹±
        try:
            validation = json.loads(response.content)
        except Exception as e:
            import re

            json_match = re.search(r"```json\n(.*?)\n```", response.content, re.DOTALL)
            if json_match:
                validation = json.loads(json_match.group(1))
            else:
                raise ValueError("Failed to parse GPT-4o JSON response")

        logger.info(
            f"[GPT-4o Validate Node] Validation: {validation.get('is_valid')} (confidence: {validation.get('confidence')})"
        )

        # 4. í•©ì˜ ì—¬ë¶€ ê²°ì • (NEW! Weighted Consensus Algorithm - Sprint 1)
        # ê¸°ì¡´: validation.get("is_valid") ë‹¨ìˆœ ì‚¬ìš©
        # ê°œì„ : GPT confidence + Gemini confidence + Extraction quality ì¢…í•© í‰ê°€

        # 4-1. ì¶”ì¶œ í’ˆì§ˆ ê³„ì‚°
        extraction_quality = calculate_extraction_quality(extracted_data, extraction_success)

        # 4-2. í•©ì˜ ì ìˆ˜ ê³„ì‚° (0.0 ~ 1.0)
        gpt_confidence = gpt_proposal.get("confidence", 0.0)
        gpt4o_confidence = validation.get("confidence", 0.0)
        consensus_score = calculate_consensus_score(
            gpt_confidence, gpt4o_confidence, extraction_quality
        )

        # 4-3. í•©ì˜ ì—¬ë¶€ íŒë‹¨ (3-tier system, ì™„í™”ë¨)
        if consensus_score >= 0.7:
            consensus_reached = True
            logger.info(f"[Consensus] âœ… AUTO-APPROVED (score={consensus_score:.2f} >= 0.7)")
        elif consensus_score >= 0.5:
            consensus_reached = True
            logger.warning(
                f"[Consensus] âš ï¸ CONDITIONAL APPROVAL (score={consensus_score:.2f} >= 0.5) "
                f"- Medium confidence, monitoring recommended"
            )
        else:
            consensus_reached = False
            logger.warning(
                f"[Consensus] âŒ REJECTED (score={consensus_score:.2f} < 0.5) - Human Review needed"
            )

        # 5. next_action ê²°ì •
        # FIX Bug #1: retry_countë¥¼ if ë¸”ë¡ ë°–ì—ì„œ ì´ˆê¸°í™”
        retry_count = state.get("retry_count", 0)

        # FIX Bug #2: consensus_reached AND is_valid ëª¨ë‘ ì²´í¬
        is_valid = validation.get("is_valid", False)

        if consensus_reached and is_valid:
            next_action = "end"  # í•©ì˜ ì„±ê³µ + ìœ íš¨ì„± í™•ì¸ â†’ ì¢…ë£Œ
        else:
            if retry_count < 3:
                next_action = "retry"  # ì¬ì‹œë„
            else:
                next_action = "human_review"  # ì‚¬ëŒ ê°œì…

            # ì‹¤íŒ¨ ì›ì¸ ë¡œê¹…
            if not consensus_reached:
                logger.warning(f"[Validation] Retry reason: Low consensus (score={consensus_score:.2f})")
            elif not is_valid:
                logger.warning(f"[Validation] Retry reason: Invalid selectors (is_valid=False)")

        # 6. State ì—…ë°ì´íŠ¸
        # FIX Bug #3: retryí•  ë•Œë§Œ retry_count ì¦ê°€ (consensus ì—¬ë¶€ì™€ ë¬´ê´€)
        should_increment = (next_action == "retry")

        return {
            **state,
            "gpt_validation": validation,
            "consensus_reached": consensus_reached,
            "retry_count": retry_count + (1 if should_increment else 0),
            "final_selectors": gpt_proposal if (consensus_reached and is_valid) else None,
            "next_action": next_action,
        }

    except Exception as gpt_error:
        logger.error(f"[GPT-4o Validate Node] âŒ GPT-4o validation failed: {gpt_error}")
        logger.warning("[GPT-4o Validate Node] ğŸ”„ Falling back to GPT-4o-mini for validation")

        # Fallback: GPT-4o-minië¡œ ê²€ì¦ ì‹œë„
        try:
            import time

            from langchain_openai import ChatOpenAI

            from src.exceptions import OpenAIAPIError, format_error_for_user

            # GPT ì œì•ˆ ê°€ì ¸ì˜¤ê¸°
            gpt_proposal = state.get("gpt_proposal")
            if not gpt_proposal:
                raise ValueError("No GPT proposal found in state")

            # CSS Selectorë¡œ ì‹¤ì œ ë°ì´í„° ì¶”ì¶œ ì‹œë„ (Geminiì—ì„œ í–ˆë˜ ê²ƒê³¼ ë™ì¼)
            html_content = state.get("html_content", "")
            soup = BeautifulSoup(html_content, "html.parser")

            extracted_data = {}
            extraction_success = {}

            for field in ["title", "body", "date"]:
                selector_key = f"{field}_selector"
                selector = gpt_proposal.get(selector_key, "")

                try:
                    elements = soup.select(selector)
                    if elements:
                        text = elements[0].get_text(strip=True)
                        extracted_data[field] = text[:200]
                        extraction_success[field] = True
                    else:
                        extracted_data[field] = None
                        extraction_success[field] = False
                except Exception as e:
                    logger.warning(f"[Fallback Validate] Extraction failed for {field}: {e}")
                    extracted_data[field] = None
                    extraction_success[field] = False

            # GPT-4o-mini ê²€ì¦ ìš”ì²­
            validation_prompt = f"""
You are a web scraping validator. Evaluate the following CSS selector proposal.

URL: {state['url']}

GPT Proposal:
- Title Selector: {gpt_proposal.get('title_selector')}
- Body Selector: {gpt_proposal.get('body_selector')}
- Date Selector: {gpt_proposal.get('date_selector')}
- GPT Confidence: {gpt_proposal.get('confidence')}

Extraction Results:
- Title: {"SUCCESS" if extraction_success.get('title') else "FAILED"}
  Extracted: {(extracted_data.get('title') or 'N/A')[:100]}
- Body: {"SUCCESS" if extraction_success.get('body') else "FAILED"}
  Extracted: {(extracted_data.get('body') or 'N/A')[:100]}
- Date: {"SUCCESS" if extraction_success.get('date') else "FAILED"}
  Extracted: {(extracted_data.get('date') or 'N/A')[:100]}

Task: Validate whether these selectors are good quality.

Return ONLY a JSON object:
{{
    "is_valid": true/false,
    "confidence": 0.0-1.0,
    "feedback": "brief explanation",
    "suggested_changes": {{"field": "new selector or null"}}
}}

Criteria:
- is_valid: true if at least 2/3 fields extracted successfully
- confidence: based on extraction quality
- feedback: explain validation result
"""

            # GPT-4o-mini í˜¸ì¶œ (ìµœëŒ€ 2íšŒ ì¬ì‹œë„)
            for attempt in range(2):
                try:
                    fallback_llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.2, timeout=30.0)
                    response = fallback_llm.invoke([{"role": "user", "content": validation_prompt}])
                    fallback_output = json.loads(response.content)

                    logger.info(
                        f"[Fallback Validate] âœ… GPT-4o-mini validation succeeded (attempt {attempt+1})"
                    )

                    # Consensus ê³„ì‚°
                    extraction_quality = calculate_extraction_quality(
                        extracted_data, extraction_success
                    )
                    gpt_confidence = gpt_proposal.get("confidence", 0.0)
                    gpt4o_confidence = fallback_output.get("confidence", 0.0)  # GPT-4o-miniê°€ ëŒ€ì²´
                    consensus_score = calculate_consensus_score(
                        gpt_confidence, gpt4o_confidence, extraction_quality
                    )

                    # Consensus íŒë‹¨
                    if consensus_score >= 0.7:
                        consensus_reached = True
                        logger.info(
                            f"[Consensus Fallback] âœ… AUTO-APPROVED (score={consensus_score:.2f})"
                        )
                    elif consensus_score >= 0.5:
                        consensus_reached = True
                        logger.warning(
                            f"[Consensus Fallback] âš ï¸ CONDITIONAL APPROVAL (score={consensus_score:.2f})"
                        )
                    else:
                        consensus_reached = False
                        logger.warning(
                            f"[Consensus Fallback] âŒ REJECTED (score={consensus_score:.2f})"
                        )

                    # next_action ê²°ì • (is_validë„ ì²´í¬)
                    retry_count = state.get("retry_count", 0)
                    is_valid = fallback_output.get("is_valid", False)

                    if consensus_reached and is_valid:
                        next_action = "end"
                    else:
                        if retry_count < 3:
                            next_action = "retry"
                        else:
                            next_action = "human_review"

                        # ì‹¤íŒ¨ ì›ì¸ ë¡œê¹…
                        if not consensus_reached:
                            logger.warning(f"[Fallback] Retry reason: Low consensus (score={consensus_score:.2f})")
                        elif not is_valid:
                            logger.warning(f"[Fallback] Retry reason: Invalid selectors (is_valid=False)")

                    # retryí•  ë•Œë§Œ retry_count ì¦ê°€
                    should_increment = (next_action == "retry")

                    return {
                        **state,
                        "gpt_validation": fallback_output,
                        "consensus_reached": consensus_reached,
                        "retry_count": retry_count + (1 if should_increment else 0),
                        "final_selectors": gpt_proposal if (consensus_reached and is_valid) else None,
                        "next_action": next_action,
                        "fallback_used": "gpt-4o-mini",  # ë©”íƒ€ë°ì´í„°
                    }

                except Exception as retry_error:
                    if attempt < 1:  # 1íšŒ ë” ì‹œë„
                        wait_time = 2**attempt
                        logger.warning(
                            f"[Fallback Validate] âš ï¸ Retry after {wait_time}s: {retry_error}"
                        )
                        time.sleep(wait_time)
                        continue
                    else:
                        logger.error(
                            f"[Fallback Validate] âŒ GPT-4o-mini also failed: {retry_error}"
                        )
                        raise

        except Exception as fallback_error:
            # GPT-4oì™€ GPT-4o-mini ëª¨ë‘ ì‹¤íŒ¨
            logger.error(f"[GPT-4o Validate Node] âŒ Both GPT-4o and fallback failed")
            logger.error(f"  - GPT-4o error: {gpt_error}")
            logger.error(f"  - Fallback error: {fallback_error}")

            from src.exceptions import OpenAIAPIError, format_error_for_user

            user_message = format_error_for_user(OpenAIAPIError(str(gpt_error)))

            # FIX Bug #2 & #3: None ëŒ€ì‹  ë¹ˆ validation dict ë°˜í™˜
            retry_count = state.get("retry_count", 0)

            return {
                **state,
                "error_message": f"Validation failed: {user_message} (Fallback also failed)",
                "gpt_validation": {
                    "is_valid": False,
                    "confidence": 0.0,
                    "feedback": "Both GPT-4o and GPT-4o-mini validation failed",
                    "suggested_changes": {},
                },  # ë¹ˆ dict ëŒ€ì‹  ìœ íš¨í•œ validation object
                "consensus_reached": False,
                "consensus_score": 0.0,
                "retry_count": retry_count + 1,
                "next_action": "human_review" if retry_count < 3 else "end",
            }


# ============================================================================
# Human Review Node (HITL)
# ============================================================================


def human_review_node(state: HITLState) -> HITLState:
    """
    ì™„ì „ ìë™í™” Node (Human Review ì œê±°)

    3íšŒ ì¬ì‹œë„ í›„ì—ë„ í•©ì˜ ì‹¤íŒ¨ ì‹œ, **ì´ì „ Selector ìœ ì§€** (ì‚¬ëŒ ê°œì… X)

    ë™ì‘:
    1. í•©ì˜ ì‹¤íŒ¨ ê¸°ë¡ (DecisionLog)
    2. ì´ì „ Selector ìœ ì§€ (DB ì—…ë°ì´íŠ¸ ì•ˆ í•¨)
    3. ì›Œí¬í”Œë¡œìš° ì¢…ë£Œ (next_action = "end")

    PoC í•µì‹¬: ì™„ì „ ìë™í™” - Agentê°€ ììœ¨ì ìœ¼ë¡œ ê²°ì •, ì‚¬ëŒ ê°œì… ì—†ìŒ
    """
    logger.warning(
        f"[Auto-Decision Node] 3íšŒ ì¬ì‹œë„ ì‹¤íŒ¨ â†’ ì´ì „ Selector ìœ ì§€ (URL: {state['url']})"
    )

    gpt_proposal = state.get("gpt_proposal")
    gpt_validation = state.get("gpt_validation")

    # Consensus ì‹¤íŒ¨ ì •ë³´ ê¸°ë¡
    logger.info(
        f"[Auto-Decision] GPT proposal: {gpt_proposal}\n"
        f"[Auto-Decision] GPT-4o validation: {gpt_validation}\n"
        f"[Auto-Decision] Decision: ì´ì „ Selector ìœ ì§€ (ë³€ê²½ ì—†ìŒ)"
    )

    return {
        **state,
        "consensus_reached": False,  # í•©ì˜ ì‹¤íŒ¨ ëª…ì‹œ
        "final_selectors": None,  # Selector ì—…ë°ì´íŠ¸ ì•ˆ í•¨
        "error_message": "3íšŒ ì¬ì‹œë„ ì‹¤íŒ¨ - ì´ì „ Selector ìœ ì§€",
        "next_action": "end",
    }


# ============================================================================
# Routing Function (ì¡°ê±´ë¶€ Edgeë¥¼ ìœ„í•œ ë¼ìš°íŒ…)
# ============================================================================


def route_after_validation(state: HITLState) -> str:
    """
    Gemini Validate Node ì´í›„ì˜ ë¼ìš°íŒ… ê²°ì •

    ë°˜í™˜ê°’:
    - "end": í•©ì˜ ì„±ê³µ â†’ ì›Œí¬í”Œë¡œìš° ì¢…ë£Œ
    - "retry": ì¬ì‹œë„ í•„ìš” â†’ GPT Proposeë¡œ ëŒì•„ê°
    - "human_review": HITL ë°œë™ â†’ Human Review Nodeë¡œ ì´ë™
    """
    next_action = state.get("next_action", "end")

    logger.info(f"[Router] After validation, next_action: {next_action}")

    return next_action


# ============================================================================
# StateGraph êµ¬ì„±
# ============================================================================

from langgraph.graph import END, StateGraph


def build_uc2_graph():
    """
    UC2 HITL ì›Œí¬í”Œë¡œìš°ì˜ StateGraphë¥¼ ìƒì„±í•˜ê³  compile

    ë°˜í™˜ê°’: Compiled LangGraph app

    ê·¸ë˜í”„ êµ¬ì¡°:

        START
          â†“
      gpt_propose (GPT-4o-mini)
          â†“
      gpt_validate (GPT-4o)
          â†“
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ route_after_  â”‚
      â”‚  validation   â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“    â†“    â†“
       END  retry  human_review
              â†“         â†“
        gpt_propose   END
    """
    logger.info("[build_uc2_graph] Building LangGraph StateGraph...")

    # 1. StateGraph ìƒì„±
    workflow = StateGraph(HITLState)

    # 2. Node ì¶”ê°€
    workflow.add_node("gpt_propose", gpt_propose_node)
    workflow.add_node("gpt_validate", gpt_validate_node)
    workflow.add_node("human_review", human_review_node)

    # 3. Entry Point ì„¤ì •
    workflow.set_entry_point("gpt_propose")

    # 4. Edge ì¶”ê°€
    # GPT â†’ GPT-4o (í•­ìƒ ì‹¤í–‰)
    workflow.add_edge("gpt_propose", "gpt_validate")

    # GPT-4o â†’ ì¡°ê±´ë¶€ ë¶„ê¸°
    workflow.add_conditional_edges(
        "gpt_validate",
        route_after_validation,
        {
            "end": END,  # í•©ì˜ ì„±ê³µ â†’ ì¢…ë£Œ
            "retry": "gpt_propose",  # ì¬ì‹œë„ â†’ GPT ë‹¤ì‹œ ì‹¤í–‰
            "human_review": "human_review",  # HITL ë°œë™
        },
    )

    # Human Review â†’ ì¢…ë£Œ (í•­ìƒ)
    workflow.add_edge("human_review", END)

    # 5. Compile
    app = workflow.compile()

    logger.info("[build_uc2_graph] StateGraph compiled successfully")

    return app


# ============================================================================
# ë‹¤ìŒ ë‹¨ê³„: í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
# ============================================================================

# TODO: í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± (test_uc2_hitl.py)

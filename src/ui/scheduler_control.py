"""
CrawlAgent - UI Scheduler Control Module
Created: 2025-11-17

UIì—ì„œ APSchedulerë¥¼ ì œì–´í•˜ê¸° ìœ„í•œ ë°±ì—”ë“œ ëª¨ë“ˆ
- ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘/ì¤‘ì§€
- ìƒíƒœ ì¡°íšŒ
- ë¡œê·¸ ì¡°íšŒ
- í†µê³„ ì¡°íšŒ
"""

import os
import subprocess
from datetime import date, datetime, timedelta
from pathlib import Path
from typing import Dict, List, Tuple

from apscheduler.schedulers.background import BackgroundScheduler
from loguru import logger

from src.storage.database import get_db
from src.storage.models import CrawlResult

# í”„ë¡œì íŠ¸ ë£¨íŠ¸
PROJECT_ROOT = Path(__file__).parent.parent.parent

# Global scheduler instance
_scheduler: BackgroundScheduler = None
_scheduler_running = False


def get_scheduler() -> BackgroundScheduler:
    """Get or create global scheduler instance"""
    global _scheduler
    if _scheduler is None:
        _scheduler = BackgroundScheduler()
    return _scheduler


def is_scheduler_running() -> bool:
    """Check if scheduler is running"""
    global _scheduler_running
    return _scheduler_running


def start_scheduler(schedule_time: str = "00:30") -> Tuple[str, str]:
    """
    ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘

    Args:
        schedule_time: ì‹¤í–‰ ì‹œê° (HH:MM í˜•ì‹)

    Returns:
        (status_message, log_message)

    Example:
        >>> start_scheduler("00:30")
        ("âœ… ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ë¨", "ë§¤ì¼ 00:30ì— ìë™ í¬ë¡¤ë§ ì‹¤í–‰")
    """
    global _scheduler_running

    try:
        # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
        if _scheduler_running:
            return "âš ï¸ ì´ë¯¸ ì‹¤í–‰ ì¤‘", "ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤"

        # ì‹œê° íŒŒì‹±
        try:
            hour, minute = schedule_time.split(":")
            hour, minute = int(hour), int(minute)
        except ValueError:
            return "âŒ ì˜ëª»ëœ ì‹œê°„ í˜•ì‹", "ì‹œê°„ì€ HH:MM í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤ (ì˜ˆ: 00:30)"

        # ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
        scheduler = get_scheduler()

        # daily_crawler.pyì˜ run_daily_crawl í•¨ìˆ˜ ì„í¬íŠ¸
        from src.scheduler.daily_crawler import run_daily_crawl

        # ì‘ì—… ì¶”ê°€ (ê¸°ì¡´ ì‘ì—… ì œê±° í›„)
        if scheduler.get_job("daily_crawl"):
            scheduler.remove_job("daily_crawl")

        scheduler.add_job(
            run_daily_crawl,
            trigger="cron",
            hour=hour,
            minute=minute,
            timezone="Asia/Seoul",
            id="daily_crawl",
            name="ì—°í•©ë‰´ìŠ¤ ì¼ì¼ í¬ë¡¤ë§",
            replace_existing=True,
        )

        # ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘
        if not scheduler.running:
            scheduler.start()

        _scheduler_running = True

        log_msg = f"""
âœ… ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ ì™„ë£Œ

â° ì‹¤í–‰ ì‹œê°: ë§¤ì¼ {schedule_time} (í•œêµ­ ì‹œê°„)
ğŸ“… ë‹¤ìŒ ì‹¤í–‰: {get_next_run_time()}
ğŸ”„ ìˆ˜ì§‘ ëŒ€ìƒ: ì–´ì œ ë‚ ì§œ ë‰´ìŠ¤ (4ê°œ ì¹´í…Œê³ ë¦¬)
        """

        logger.info(f"[UI Scheduler] ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘: {schedule_time}")

        return "âœ… ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ë¨", log_msg.strip()

    except Exception as e:
        logger.error(f"[UI Scheduler] ì‹œì‘ ì‹¤íŒ¨: {e}")
        return f"âŒ ì‹œì‘ ì‹¤íŒ¨", f"ì˜¤ë¥˜: {str(e)}"


def stop_scheduler() -> Tuple[str, str]:
    """
    ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€

    Returns:
        (status_message, log_message)
    """
    global _scheduler_running

    try:
        if not _scheduler_running:
            return "âš ï¸ ì‹¤í–‰ ì¤‘ ì•„ë‹˜", "ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì‹¤í–‰ ì¤‘ì´ì§€ ì•ŠìŠµë‹ˆë‹¤"

        scheduler = get_scheduler()

        # ì‘ì—… ì œê±°
        if scheduler.get_job("daily_crawl"):
            scheduler.remove_job("daily_crawl")

        # ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œ (ë‹¤ë¥¸ ì‘ì—…ì´ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì¡°ê±´ë¶€)
        if scheduler.running and len(scheduler.get_jobs()) == 0:
            scheduler.shutdown(wait=False)

        _scheduler_running = False

        log_msg = "âœ… ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€ ì™„ë£Œ"

        logger.info("[UI Scheduler] ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€")

        return "â¹ï¸ ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€ë¨", log_msg

    except Exception as e:
        logger.error(f"[UI Scheduler] ì¤‘ì§€ ì‹¤íŒ¨: {e}")
        return f"âŒ ì¤‘ì§€ ì‹¤íŒ¨", f"ì˜¤ë¥˜: {str(e)}"


def get_scheduler_status() -> str:
    """
    ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ ì¡°íšŒ

    Returns:
        ìƒíƒœ ë©”ì‹œì§€
    """
    global _scheduler_running

    if not _scheduler_running:
        return "â¹ï¸ ì¤‘ì§€ë¨"

    scheduler = get_scheduler()
    job = scheduler.get_job("daily_crawl")

    if job is None:
        return "âš ï¸ ì‘ì—… ì—†ìŒ"

    next_run = job.next_run_time
    if next_run:
        next_run_str = next_run.strftime("%Y-%m-%d %H:%M:%S")
        return f"ğŸŸ¢ ì‹¤í–‰ ì¤‘ (ë‹¤ìŒ: {next_run_str})"

    return "ğŸŸ¢ ì‹¤í–‰ ì¤‘"


def get_next_run_time() -> str:
    """
    ë‹¤ìŒ ì‹¤í–‰ ì‹œê° ì¡°íšŒ

    Returns:
        ë‹¤ìŒ ì‹¤í–‰ ì‹œê° ë¬¸ìì—´
    """
    scheduler = get_scheduler()
    job = scheduler.get_job("daily_crawl")

    if job is None:
        return "ìŠ¤ì¼€ì¤„ ì—†ìŒ"

    next_run = job.next_run_time
    if next_run:
        return next_run.strftime("%Y-%m-%d %H:%M:%S")

    return "ì•Œ ìˆ˜ ì—†ìŒ"


def run_manual_crawl() -> Tuple[str, str]:
    """
    ìˆ˜ë™ í¬ë¡¤ë§ ì‹¤í–‰ (ì¦‰ì‹œ ì‹¤í–‰) - Legacy ë‹¨ì¼ ì‚¬ì´íŠ¸

    Returns:
        (status_message, log_message)
    """
    try:
        logger.info("[UI Scheduler] ìˆ˜ë™ í¬ë¡¤ë§ ì‹œì‘")

        # daily_crawler.py --test ì‹¤í–‰
        cmd = ["poetry", "run", "python", "src/scheduler/daily_crawler.py", "--test"]

        process = subprocess.Popen(
            cmd,
            cwd=PROJECT_ROOT,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )

        # ë¹„ë™ê¸° ì‹¤í–‰ (ë°±ê·¸ë¼ìš´ë“œ)
        # ê²°ê³¼ëŠ” ë¡œê·¸ íŒŒì¼ì—ì„œ í™•ì¸

        log_msg = f"""
ğŸš€ ìˆ˜ë™ í¬ë¡¤ë§ ì‹œì‘ë¨ (ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰)

ğŸ“… ìˆ˜ì§‘ ëŒ€ìƒ: ì–´ì œ ë‚ ì§œ ë‰´ìŠ¤
ğŸ“Š ì§„í–‰ ìƒí™©: ì•„ë˜ ë¡œê·¸ì—ì„œ í™•ì¸

ë¡œê·¸ëŠ” ê³„ì† ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤...
        """

        return "ğŸš€ ì‹¤í–‰ ì¤‘", log_msg.strip()

    except Exception as e:
        logger.error(f"[UI Scheduler] ìˆ˜ë™ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
        return f"âŒ ì‹¤í–‰ ì‹¤íŒ¨", f"ì˜¤ë¥˜: {str(e)}"


def run_multi_site_manual_crawl(
    sites: List[str],
    categories_per_site: Dict[str, List[str]],
    scope: str = "selected",
    date_list: List[str] = None
) -> Tuple[str, str]:
    """
    ë‹¤ì¤‘ ì‚¬ì´íŠ¸ ìˆ˜ë™ í¬ë¡¤ë§ ì‹¤í–‰ (ì¦‰ì‹œ ì‹¤í–‰)

    Args:
        sites: ì‚¬ì´íŠ¸ ë¦¬ìŠ¤íŠ¸ (["yonhap", "naver"])
        categories_per_site: ì‚¬ì´íŠ¸ë³„ ì¹´í…Œê³ ë¦¬ {"yonhap": ["politics"], "naver": ["economy"]}
        scope: "selected" or "all"
        date_list: í¬ë¡¤ë§í•  ë‚ ì§œ ë¦¬ìŠ¤íŠ¸ (["2025-11-16", "2025-11-17"]). Noneì´ë©´ ì–´ì œ ë‚ ì§œ

    Returns:
        (status_message, log_message)
    """
    try:
        logger.info(f"[UI Scheduler] ë‹¤ì¤‘ ì‚¬ì´íŠ¸ ìˆ˜ë™ í¬ë¡¤ë§: sites={sites}, scope={scope}, dates={date_list}")

        # multi_site_crawler ì„í¬íŠ¸
        from src.scheduler.multi_site_crawler import run_multi_site_crawl

        # ë‚ ì§œ ë¦¬ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ì–´ì œ ë‚ ì§œë§Œ
        if not date_list:
            date_list = [None]  # Noneì€ ì–´ì œ ë‚ ì§œë¥¼ ì˜ë¯¸

        # ê° ë‚ ì§œë³„ë¡œ í¬ë¡¤ë§ ì‹¤í–‰
        all_logs = []
        total_crawled = 0

        for target_date in date_list:
            status, log, stats = run_multi_site_crawl(
                sites=sites,
                categories_per_site=categories_per_site,
                target_date=target_date,
                scope=scope
            )
            all_logs.append(f"ğŸ“… {target_date or 'ì–´ì œ'}: {log}")
            if stats:
                total_crawled += stats.get('total_crawled', 0)

        combined_log = "\n\n".join(all_logs)
        status_msg = f"âœ… ì™„ë£Œ: ì´ {total_crawled}ê°œ ê¸°ì‚¬ ìˆ˜ì§‘ ({len(date_list)}ì¼ì¹˜)"

        return status_msg, combined_log

    except Exception as e:
        logger.error(f"[UI Scheduler] ë‹¤ì¤‘ ì‚¬ì´íŠ¸ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
        return f"âŒ ì‹¤í–‰ ì‹¤íŒ¨", f"ì˜¤ë¥˜: {str(e)}"


def start_multi_site_scheduler(
    sites: List[str],
    categories_per_site: Dict[str, List[str]],
    scope: str = "selected",
    schedule_time: str = "00:30",
    frequency: str = "daily"
) -> Tuple[str, str]:
    """
    ë‹¤ì¤‘ ì‚¬ì´íŠ¸ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘

    Args:
        sites: ì‚¬ì´íŠ¸ ë¦¬ìŠ¤íŠ¸
        categories_per_site: ì‚¬ì´íŠ¸ë³„ ì¹´í…Œê³ ë¦¬
        scope: "selected" or "all"
        schedule_time: ì‹¤í–‰ ì‹œê° (HH:MM)
        frequency: "daily", "weekly", "monthly"

    Returns:
        (status_message, log_message)
    """
    global _scheduler_running

    try:
        # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
        if _scheduler_running:
            return "âš ï¸ ì´ë¯¸ ì‹¤í–‰ ì¤‘", "ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤. ë¨¼ì € ì¤‘ì§€í•˜ì„¸ìš”."

        # ì‹œê° íŒŒì‹±
        try:
            hour, minute = schedule_time.split(":")
            hour, minute = int(hour), int(minute)
        except ValueError:
            return "âŒ ì˜ëª»ëœ ì‹œê°„ í˜•ì‹", "ì‹œê°„ì€ HH:MM í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤ (ì˜ˆ: 00:30)"

        # ì‚¬ì´íŠ¸ ê²€ì¦
        if not sites:
            return "âŒ ì‚¬ì´íŠ¸ ì„ íƒ í•„ìš”", "ìµœì†Œ 1ê°œ ì´ìƒì˜ ì‚¬ì´íŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”."

        # ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
        scheduler = get_scheduler()

        # multi_site_crawler ì„í¬íŠ¸
        from src.scheduler.multi_site_crawler import run_multi_site_crawl

        # ì‘ì—… í•¨ìˆ˜ ì •ì˜ (í´ë¡œì €ë¡œ íŒŒë¼ë¯¸í„° ìº¡ì²˜)
        def scheduled_multi_site_crawl():
            logger.info(f"[ìŠ¤ì¼€ì¤„ ì‹¤í–‰] ë‹¤ì¤‘ ì‚¬ì´íŠ¸ í¬ë¡¤ë§: {sites}")
            run_multi_site_crawl(
                sites=sites,
                categories_per_site=categories_per_site,
                target_date=None,  # ì–´ì œ ë‚ ì§œ
                scope=scope
            )

        # ê¸°ì¡´ ì‘ì—… ì œê±°
        if scheduler.get_job("multi_site_crawl"):
            scheduler.remove_job("multi_site_crawl")

        # ë¹ˆë„ì— ë”°ë¥¸ íŠ¸ë¦¬ê±° ì„¤ì •
        if frequency == "daily":
            trigger_kwargs = {
                "trigger": "cron",
                "hour": hour,
                "minute": minute,
                "timezone": "Asia/Seoul"
            }
            frequency_text = f"ë§¤ì¼ {schedule_time}"

        elif frequency == "weekly":
            # ë§¤ì£¼ ì›”ìš”ì¼
            trigger_kwargs = {
                "trigger": "cron",
                "day_of_week": "mon",
                "hour": hour,
                "minute": minute,
                "timezone": "Asia/Seoul"
            }
            frequency_text = f"ë§¤ì£¼ ì›”ìš”ì¼ {schedule_time}"

        elif frequency == "monthly":
            # ë§¤ì›” 1ì¼
            trigger_kwargs = {
                "trigger": "cron",
                "day": 1,
                "hour": hour,
                "minute": minute,
                "timezone": "Asia/Seoul"
            }
            frequency_text = f"ë§¤ì›” 1ì¼ {schedule_time}"

        else:
            return "âŒ ì˜ëª»ëœ ë¹ˆë„", f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¹ˆë„: {frequency}"

        # ì‘ì—… ì¶”ê°€
        scheduler.add_job(
            scheduled_multi_site_crawl,
            **trigger_kwargs,
            id="multi_site_crawl",
            name="ë‹¤ì¤‘ ì‚¬ì´íŠ¸ ìë™ í¬ë¡¤ë§",
            replace_existing=True
        )

        # ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘
        if not scheduler.running:
            scheduler.start()

        _scheduler_running = True

        # ì‹¤í–‰ ê³„íš ìš”ì•½
        from src.scheduler.multi_site_crawler import get_crawl_plan_summary
        plan_summary = get_crawl_plan_summary(sites, categories_per_site, scope)

        log_msg = f"""
âœ… ë‹¤ì¤‘ ì‚¬ì´íŠ¸ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ ì™„ë£Œ

â° ì‹¤í–‰ ë¹ˆë„: {frequency_text}
ğŸ“… ë‹¤ìŒ ì‹¤í–‰: {get_next_run_time()}

{plan_summary}

ğŸ”„ ìˆ˜ì§‘ ëŒ€ìƒ: ì–´ì œ ë‚ ì§œ ë‰´ìŠ¤
        """

        logger.info(f"[UI Scheduler] ë‹¤ì¤‘ ì‚¬ì´íŠ¸ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘: {sites}, {frequency_text}")

        return "âœ… ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ë¨", log_msg.strip()

    except Exception as e:
        logger.error(f"[UI Scheduler] ë‹¤ì¤‘ ì‚¬ì´íŠ¸ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ ì‹¤íŒ¨: {e}")
        return f"âŒ ì‹œì‘ ì‹¤íŒ¨", f"ì˜¤ë¥˜: {str(e)}"


def get_recent_crawl_stats(days: int = 7) -> Dict:
    """
    ìµœê·¼ Nì¼ê°„ í¬ë¡¤ë§ í†µê³„ ì¡°íšŒ

    Args:
        days: ì¡°íšŒ ê¸°ê°„ (ì¼)

    Returns:
        í†µê³„ ë”•ì…”ë„ˆë¦¬
    """
    try:
        db = next(get_db())

        # ë‚ ì§œ ë²”ìœ„
        start_date = date.today() - timedelta(days=days)

        # ì „ì²´ í¬ë¡¤ë§ ìˆ˜
        total_count = db.query(CrawlResult)\
            .filter(CrawlResult.created_at >= start_date)\
            .count()

        # ì„±ê³µ í¬ë¡¤ë§ ìˆ˜ (quality >= 80)
        success_count = db.query(CrawlResult)\
            .filter(CrawlResult.created_at >= start_date)\
            .filter(CrawlResult.quality_score >= 80)\
            .count()

        # ì„±ê³µë¥ 
        success_rate = (success_count / total_count * 100) if total_count > 0 else 0

        # ì¼ë³„ í†µê³„
        daily_stats = []
        for i in range(days):
            target_date = date.today() - timedelta(days=i)

            count = db.query(CrawlResult)\
                .filter(CrawlResult.created_at >= target_date)\
                .filter(CrawlResult.created_at < target_date + timedelta(days=1))\
                .count()

            daily_stats.append({
                "date": target_date.strftime("%Y-%m-%d"),
                "count": count
            })

        return {
            "total_count": total_count,
            "success_count": success_count,
            "success_rate": round(success_rate, 1),
            "daily_stats": daily_stats
        }

    except Exception as e:
        logger.error(f"[UI Scheduler] í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {
            "total_count": 0,
            "success_count": 0,
            "success_rate": 0,
            "daily_stats": []
        }


def get_scheduler_logs(lines: int = 50) -> str:
    """
    ìŠ¤ì¼€ì¤„ëŸ¬ ë¡œê·¸ ì¡°íšŒ

    Args:
        lines: ì¡°íšŒí•  ë¼ì¸ ìˆ˜

    Returns:
        ë¡œê·¸ ë¬¸ìì—´
    """
    try:
        log_file = PROJECT_ROOT / "logs" / "crawlagent.log"

        if not log_file.exists():
            return "ë¡œê·¸ íŒŒì¼ ì—†ìŒ"

        # ë§ˆì§€ë§‰ Nì¤„ ì½ê¸°
        with open(log_file, "r", encoding="utf-8") as f:
            all_lines = f.readlines()
            recent_lines = all_lines[-lines:]
            return "".join(recent_lines)

    except Exception as e:
        logger.error(f"[UI Scheduler] ë¡œê·¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return f"ë¡œê·¸ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"
